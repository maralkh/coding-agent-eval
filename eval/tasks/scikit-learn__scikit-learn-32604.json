{
  "id": "scikit-learn__scikit-learn-32604",
  "repo": "scikit-learn/scikit-learn",
  "base_commit": "560ba4fbf167b1627ba0420b5ee0fa5dda0032d6",
  "issue_number": 1234,
  "issue_title": "MRG fix bincount mess I made in kmeans.",
  "issue_body": "This should clean up the stuff I pushed earlier.\ncc @ogrisel @gaelvaroquaux Could you have a brief look? What I pushed earlier is buggy but I didn't dare push again after so many failed fixes.\n",
  "pr_number": 32604,
  "pr_title": "FEA Add array API support for `balanced_accuracy_score`",
  "gold_patch": "diff --git a/doc/modules/array_api.rst b/doc/modules/array_api.rst\nindex 5ae5f99f23b68..35a041a2bc660 100644\n--- a/doc/modules/array_api.rst\n+++ b/doc/modules/array_api.rst\n@@ -146,6 +146,7 @@ Metrics\n -------\n \n - :func:`sklearn.metrics.accuracy_score`\n+- :func:`sklearn.metrics.balanced_accuracy_score`\n - :func:`sklearn.metrics.brier_score_loss`\n - :func:`sklearn.metrics.confusion_matrix`\n - :func:`sklearn.metrics.d2_brier_score`\ndiff --git a/doc/whats_new/upcoming_changes/array-api/32604.feature.rst b/doc/whats_new/upcoming_changes/array-api/32604.feature.rst\nnew file mode 100644\nindex 0000000000000..752ea5b9cb3b5\n--- /dev/null\n+++ b/doc/whats_new/upcoming_changes/array-api/32604.feature.rst\n@@ -0,0 +1,2 @@\n+- :func:`sklearn.metrics.balanced_accuracy_score` now supports array API compatible inputs.\n+  By :user:`Omar Salman <OmarManzoor>`.\ndiff --git a/sklearn/metrics/_classification.py b/sklearn/metrics/_classification.py\nindex 2fb7349089b1e..d1c1cd6af127f 100644\n--- a/sklearn/metrics/_classification.py\n+++ b/sklearn/metrics/_classification.py\n@@ -11,6 +11,7 @@\n # SPDX-License-Identifier: BSD-3-Clause\n \n import warnings\n+from contextlib import nullcontext\n from math import sqrt\n from numbers import Integral, Real\n \n@@ -34,6 +35,7 @@\n     _count_nonzero,\n     _find_matching_floating_dtype,\n     _is_numpy_namespace,\n+    _is_xp_namespace,\n     _max_precision_float_dtype,\n     _tolist,\n     _union1d,\n@@ -2904,14 +2906,25 @@ def balanced_accuracy_score(y_true, y_pred, *, sample_weight=None, adjusted=Fals\n     0.625\n     \"\"\"\n     C = confusion_matrix(y_true, y_pred, sample_weight=sample_weight)\n-    with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n-        per_class = np.diag(C) / C.sum(axis=1)\n-    if np.any(np.isnan(per_class)):\n+    xp, _, device_ = get_namespace_and_device(y_pred, y_true)\n+    if _is_xp_namespace(xp, \"array_api_strict\"):\n+        # array_api_strict only supports floating point dtypes for __truediv__\n+        # which is used below to compute `per_class`.\n+        C = xp.astype(C, _max_precision_float_dtype(xp, device=device_), copy=False)\n+\n+    context_manager = (\n+        np.errstate(divide=\"ignore\", invalid=\"ignore\")\n+        if _is_numpy_namespace(xp)\n+        else nullcontext()\n+    )\n+    with context_manager:\n+        per_class = xp.linalg.diagonal(C) / xp.sum(C, axis=1)\n+    if xp.any(xp.isnan(per_class)):\n         warnings.warn(\"y_pred contains classes not in y_true\")\n-        per_class = per_class[~np.isnan(per_class)]\n-    score = np.mean(per_class)\n+        per_class = per_class[~xp.isnan(per_class)]\n+    score = xp.mean(per_class)\n     if adjusted:\n-        n_classes = len(per_class)\n+        n_classes = per_class.shape[0]\n         chance = 1 / n_classes\n         score -= chance\n         score /= 1 - chance\ndiff --git a/sklearn/metrics/tests/test_common.py b/sklearn/metrics/tests/test_common.py\nindex ca92cc09c8660..5954b891afbb7 100644\n--- a/sklearn/metrics/tests/test_common.py\n+++ b/sklearn/metrics/tests/test_common.py\n@@ -2052,6 +2052,7 @@ def check_array_api_multiclass_classification_metric(\n     additional_params = {\n         \"average\": (\"micro\", \"macro\", \"weighted\"),\n         \"beta\": (0.2, 0.5, 0.8),\n+        \"adjusted\": (False, True),\n     }\n     metric_kwargs_combinations = _get_metric_kwargs_for_array_api_testing(\n         metric=metric,\n@@ -2249,6 +2250,10 @@ def check_array_api_metric_pairwise(metric, array_namespace, device, dtype_name)\n         check_array_api_multiclass_classification_metric,\n         check_array_api_multilabel_classification_metric,\n     ],\n+    balanced_accuracy_score: [\n+        check_array_api_binary_classification_metric,\n+        check_array_api_multiclass_classification_metric,\n+    ],\n     confusion_matrix: [\n         check_array_api_binary_classification_metric,\n         check_array_api_multiclass_classification_metric,\n",
  "fail_to_pass": [],
  "pass_to_pass": [],
  "relevant_files": [
    "sklearn/metrics/_classification.py",
    "sklearn/metrics/tests/test_common.py"
  ],
  "difficulty": "hard",
  "created_at": "2025-10-29T08:18:24Z",
  "pr_url": "https://github.com/scikit-learn/scikit-learn/pull/32604",
  "issue_url": "https://github.com/scikit-learn/scikit-learn/pull/1234"
}