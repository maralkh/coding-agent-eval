{
  "id": "scikit-learn__scikit-learn-29978",
  "repo": "scikit-learn/scikit-learn",
  "base_commit": "fba028b07ed2b4e52dd3719dad0d990837bde28c",
  "issue_number": 1234,
  "issue_title": "MRG fix bincount mess I made in kmeans.",
  "issue_body": "This should clean up the stuff I pushed earlier.\ncc @ogrisel @gaelvaroquaux Could you have a brief look? What I pushed earlier is buggy but I didn't dare push again after so many failed fixes.\n",
  "pr_number": 29978,
  "pr_title": "ENH add support for Array API to `mean_pinball_loss` and `explained_variance_score`",
  "gold_patch": "diff --git a/doc/modules/array_api.rst b/doc/modules/array_api.rst\nindex 2fb57a64118f7..2997cce3e8cf1 100644\n--- a/doc/modules/array_api.rst\n+++ b/doc/modules/array_api.rst\n@@ -116,11 +116,13 @@ Metrics\n - :func:`sklearn.metrics.cluster.entropy`\n - :func:`sklearn.metrics.accuracy_score`\n - :func:`sklearn.metrics.d2_tweedie_score`\n+- :func:`sklearn.metrics.explained_variance_score`\n - :func:`sklearn.metrics.f1_score`\n - :func:`sklearn.metrics.max_error`\n - :func:`sklearn.metrics.mean_absolute_error`\n - :func:`sklearn.metrics.mean_absolute_percentage_error`\n - :func:`sklearn.metrics.mean_gamma_deviance`\n+- :func:`sklearn.metrics.mean_pinball_loss`\n - :func:`sklearn.metrics.mean_poisson_deviance` (requires `enabling array API support for SciPy <https://docs.scipy.org/doc/scipy/dev/api-dev/array_api.html#using-array-api-standard-support>`_)\n - :func:`sklearn.metrics.mean_squared_error`\n - :func:`sklearn.metrics.mean_squared_log_error`\ndiff --git a/doc/whats_new/upcoming_changes/array-api/29978.feature.rst b/doc/whats_new/upcoming_changes/array-api/29978.feature.rst\nnew file mode 100644\nindex 0000000000000..5c7bc3c61111d\n--- /dev/null\n+++ b/doc/whats_new/upcoming_changes/array-api/29978.feature.rst\n@@ -0,0 +1,3 @@\n+- :func:`sklearn.metrics.explained_variance_score` and\n+  :func:`sklearn.metrics.mean_pinball_loss` now support Array API compatible inputs.\n+  by :user:`Virgil Chan <virchan>`\n\\ No newline at end of file\ndiff --git a/sklearn/metrics/_regression.py b/sklearn/metrics/_regression.py\nindex c5ebe67e34a2e..feab48e482c5b 100644\n--- a/sklearn/metrics/_regression.py\n+++ b/sklearn/metrics/_regression.py\n@@ -288,7 +288,7 @@ def mean_absolute_error(\n         if multioutput == \"raw_values\":\n             return output_errors\n         elif multioutput == \"uniform_average\":\n-            # pass None as weights to np.average: uniform mean\n+            # pass None as weights to _average: uniform mean\n             multioutput = None\n \n     # Average across the outputs (if needed).\n@@ -360,35 +360,45 @@ def mean_pinball_loss(\n     >>> from sklearn.metrics import mean_pinball_loss\n     >>> y_true = [1, 2, 3]\n     >>> mean_pinball_loss(y_true, [0, 2, 3], alpha=0.1)\n-    np.float64(0.03...)\n+    0.03...\n     >>> mean_pinball_loss(y_true, [1, 2, 4], alpha=0.1)\n-    np.float64(0.3...)\n+    0.3...\n     >>> mean_pinball_loss(y_true, [0, 2, 3], alpha=0.9)\n-    np.float64(0.3...)\n+    0.3...\n     >>> mean_pinball_loss(y_true, [1, 2, 4], alpha=0.9)\n-    np.float64(0.03...)\n+    0.03...\n     >>> mean_pinball_loss(y_true, y_true, alpha=0.1)\n-    np.float64(0.0)\n+    0.0\n     >>> mean_pinball_loss(y_true, y_true, alpha=0.9)\n-    np.float64(0.0)\n+    0.0\n     \"\"\"\n-    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n-        y_true, y_pred, multioutput\n+    xp, _ = get_namespace(y_true, y_pred, sample_weight, multioutput)\n+\n+    _, y_true, y_pred, sample_weight, multioutput = (\n+        _check_reg_targets_with_floating_dtype(\n+            y_true, y_pred, sample_weight, multioutput, xp=xp\n+        )\n     )\n+\n     check_consistent_length(y_true, y_pred, sample_weight)\n     diff = y_true - y_pred\n-    sign = (diff >= 0).astype(diff.dtype)\n+    sign = xp.astype(diff >= 0, diff.dtype)\n     loss = alpha * sign * diff - (1 - alpha) * (1 - sign) * diff\n-    output_errors = np.average(loss, weights=sample_weight, axis=0)\n+    output_errors = _average(loss, weights=sample_weight, axis=0)\n \n     if isinstance(multioutput, str) and multioutput == \"raw_values\":\n         return output_errors\n \n     if isinstance(multioutput, str) and multioutput == \"uniform_average\":\n-        # pass None as weights to np.average: uniform mean\n+        # pass None as weights to _average: uniform mean\n         multioutput = None\n \n-    return np.average(output_errors, weights=multioutput)\n+    # Average across the outputs (if needed).\n+    # The second call to `_average` should always return\n+    # a scalar array that we convert to a Python float to\n+    # consistently return the same eager evaluated value.\n+    # Therefore, `axis=None`.\n+    return float(_average(output_errors, weights=multioutput))\n \n \n @validate_params(\n@@ -949,12 +959,12 @@ def _assemble_r2_explained_variance(\n             # return scores individually\n             return output_scores\n         elif multioutput == \"uniform_average\":\n-            # Passing None as weights to np.average results is uniform mean\n+            # pass None as weights to _average: uniform mean\n             avg_weights = None\n         elif multioutput == \"variance_weighted\":\n             avg_weights = denominator\n             if not xp.any(nonzero_denominator):\n-                # All weights are zero, np.average would raise a ZeroDiv error.\n+                # All weights are zero, _average would raise a ZeroDiv error.\n                 # This only happens when all y are constant (or 1-element long)\n                 # Since weights are all equal, fall back to uniform weights.\n                 avg_weights = None\n@@ -1083,18 +1093,23 @@ def explained_variance_score(\n     >>> explained_variance_score(y_true, y_pred, force_finite=False)\n     -inf\n     \"\"\"\n-    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n-        y_true, y_pred, multioutput\n+    xp, _, device = get_namespace_and_device(y_true, y_pred, sample_weight, multioutput)\n+\n+    _, y_true, y_pred, sample_weight, multioutput = (\n+        _check_reg_targets_with_floating_dtype(\n+            y_true, y_pred, sample_weight, multioutput, xp=xp\n+        )\n     )\n+\n     check_consistent_length(y_true, y_pred, sample_weight)\n \n-    y_diff_avg = np.average(y_true - y_pred, weights=sample_weight, axis=0)\n-    numerator = np.average(\n+    y_diff_avg = _average(y_true - y_pred, weights=sample_weight, axis=0)\n+    numerator = _average(\n         (y_true - y_pred - y_diff_avg) ** 2, weights=sample_weight, axis=0\n     )\n \n-    y_true_avg = np.average(y_true, weights=sample_weight, axis=0)\n-    denominator = np.average((y_true - y_true_avg) ** 2, weights=sample_weight, axis=0)\n+    y_true_avg = _average(y_true, weights=sample_weight, axis=0)\n+    denominator = _average((y_true - y_true_avg) ** 2, weights=sample_weight, axis=0)\n \n     return _assemble_r2_explained_variance(\n         numerator=numerator,\n@@ -1102,9 +1117,8 @@ def explained_variance_score(\n         n_outputs=y_true.shape[1],\n         multioutput=multioutput,\n         force_finite=force_finite,\n-        xp=get_namespace(y_true)[0],\n-        # TODO: update once Array API support is added to explained_variance_score.\n-        device=None,\n+        xp=xp,\n+        device=device,\n     )\n \n \ndiff --git a/sklearn/metrics/tests/test_common.py b/sklearn/metrics/tests/test_common.py\nindex fa13426c7a68a..0b7a47b0f12da 100644\n--- a/sklearn/metrics/tests/test_common.py\n+++ b/sklearn/metrics/tests/test_common.py\n@@ -2084,10 +2084,18 @@ def check_array_api_metric_pairwise(metric, array_namespace, device, dtype_name)\n         check_array_api_regression_metric_multioutput,\n     ],\n     cosine_similarity: [check_array_api_metric_pairwise],\n+    explained_variance_score: [\n+        check_array_api_regression_metric,\n+        check_array_api_regression_metric_multioutput,\n+    ],\n     mean_absolute_error: [\n         check_array_api_regression_metric,\n         check_array_api_regression_metric_multioutput,\n     ],\n+    mean_pinball_loss: [\n+        check_array_api_regression_metric,\n+        check_array_api_regression_metric_multioutput,\n+    ],\n     mean_squared_error: [\n         check_array_api_regression_metric,\n         check_array_api_regression_metric_multioutput,\ndiff --git a/sklearn/metrics/tests/test_regression.py b/sklearn/metrics/tests/test_regression.py\nindex 9df64aa8babf3..ea8412d53c247 100644\n--- a/sklearn/metrics/tests/test_regression.py\n+++ b/sklearn/metrics/tests/test_regression.py\n@@ -566,7 +566,7 @@ def test_mean_pinball_loss_on_constant_predictions(distribution, target_quantile\n         # Check that the loss of this constant predictor is greater or equal\n         # than the loss of using the optimal quantile (up to machine\n         # precision):\n-        assert pbl >= best_pbl - np.finfo(best_pbl.dtype).eps\n+        assert pbl >= best_pbl - np.finfo(np.float64).eps\n \n         # Check that the value of the pinball loss matches the analytical\n         # formula.\n",
  "fail_to_pass": [],
  "pass_to_pass": [],
  "relevant_files": [
    "sklearn/metrics/_regression.py",
    "sklearn/metrics/tests/test_common.py",
    "sklearn/metrics/tests/test_regression.py"
  ],
  "difficulty": "hard",
  "created_at": "2024-09-30T22:55:36Z",
  "pr_url": "https://github.com/scikit-learn/scikit-learn/pull/29978",
  "issue_url": "https://github.com/scikit-learn/scikit-learn/pull/1234"
}