{
  "id": "scikit-learn__scikit-learn-31331",
  "repo": "scikit-learn/scikit-learn",
  "base_commit": "f44350d45750a63969411534ecd8c6e7be21010f",
  "issue_number": 29048,
  "issue_title": "Make `zero_division` parameter consistent in the different metric",
  "issue_body": "This is an issue to report the step to actually take over the work of @marctorsoc in https://github.com/scikit-learn/scikit-learn/pull/23183 and split the PR into smaller one to facilitate the review process.\n\nThe intend is to make the `zero_division` parameter consistent across different metrics in scikit-learn. In this regards, we have the following TODO list:\n\n- [x] Introduce the `zero_division` parameter to the `accuracy_score` function when `y_true` and `y_pred` are empty.\n    - https://github.com/scikit-learn/scikit-learn/pull/29213\n- [x] Introduce the `zero_division` parameter to the `class_likelihood_ratios` and remove `raise_warning`.\n    - https://github.com/scikit-learn/scikit-learn/pull/31331\n- [x] Introduce the `zero_division` parameter to the `cohen_kappa_score` function\n  - https://github.com/scikit-learn/scikit-learn/pull/29210\n- [x] Introduce the `zero_division` parameter to the `matthew_corr_coeff` function\n  - #23183\n  - #28509\n- [ ] <del>Open a PR to make sure the empty input lead to `np.nan` in `classification_report` function.</del> `classification_report` should raise an error instead: see https://github.com/scikit-learn/scikit-learn/issues/29048#issuecomment-2857931743\n\nAll those items have been addressed in #23183 and can be extracted in individual PRs. The changelog presenting the changes should acknowledge @marctorsoc.\n\nIn addition, we should investigate #27047 and check if we should add the `zero_division` parameter to the `precision_recall_curve` and `roc_curve` as well. This might add two additional items to the list above.",
  "pr_number": 31331,
  "pr_title": "MNT remove default behaviour deprecation from class_likelihood_ratios",
  "gold_patch": "diff --git a/doc/whats_new/upcoming_changes/sklearn.metrics/29288.api.rst b/doc/whats_new/upcoming_changes/sklearn.metrics/29288.api.rst\nnew file mode 100644\nindex 0000000000000..1c8e15d714391\n--- /dev/null\n+++ b/doc/whats_new/upcoming_changes/sklearn.metrics/29288.api.rst\n@@ -0,0 +1,4 @@\n+- The `raise_warning` parameter of :func:`metrics.class_likelihood_ratios` is deprecated\n+  and will be removed in 1.9. An `UndefinedMetricWarning` will always be raised in case\n+  of a division by zero.\n+  By :user:`Stefanie Senger <StefanieSenger>`.\ndiff --git a/sklearn/metrics/_classification.py b/sklearn/metrics/_classification.py\nindex cae227ac7edb8..65cbfbad6f01f 100644\n--- a/sklearn/metrics/_classification.py\n+++ b/sklearn/metrics/_classification.py\n@@ -2052,7 +2052,6 @@ def precision_recall_fscore_support(\n         \"sample_weight\": [\"array-like\", None],\n         \"raise_warning\": [\"boolean\", Hidden(StrOptions({\"deprecated\"}))],\n         \"replace_undefined_by\": [\n-            Hidden(StrOptions({\"default\"})),\n             Options(Real, {1.0, np.nan}),\n             dict,\n         ],\n@@ -2066,7 +2065,7 @@ def class_likelihood_ratios(\n     labels=None,\n     sample_weight=None,\n     raise_warning=\"deprecated\",\n-    replace_undefined_by=\"default\",\n+    replace_undefined_by=np.nan,\n ):\n     \"\"\"Compute binary classification positive and negative likelihood ratios.\n \n@@ -2178,16 +2177,15 @@ class are present in `y_true`): both likelihood ratios are undefined.\n     --------\n     >>> import numpy as np\n     >>> from sklearn.metrics import class_likelihood_ratios\n-    >>> class_likelihood_ratios([0, 1, 0, 1, 0], [1, 1, 0, 0, 0],\n-    ...                          replace_undefined_by=1.0)\n+    >>> class_likelihood_ratios([0, 1, 0, 1, 0], [1, 1, 0, 0, 0])\n     (1.5, 0.75)\n     >>> y_true = np.array([\"non-cat\", \"cat\", \"non-cat\", \"cat\", \"non-cat\"])\n     >>> y_pred = np.array([\"cat\", \"cat\", \"non-cat\", \"non-cat\", \"non-cat\"])\n-    >>> class_likelihood_ratios(y_true, y_pred, replace_undefined_by=1.0)\n+    >>> class_likelihood_ratios(y_true, y_pred)\n     (1.33, 0.66)\n     >>> y_true = np.array([\"non-zebra\", \"zebra\", \"non-zebra\", \"zebra\", \"non-zebra\"])\n     >>> y_pred = np.array([\"zebra\", \"zebra\", \"non-zebra\", \"non-zebra\", \"non-zebra\"])\n-    >>> class_likelihood_ratios(y_true, y_pred, replace_undefined_by=1.0)\n+    >>> class_likelihood_ratios(y_true, y_pred)\n     (1.5, 0.75)\n \n     To avoid ambiguities, use the notation `labels=[negative_class,\n@@ -2195,18 +2193,13 @@ class are present in `y_true`): both likelihood ratios are undefined.\n \n     >>> y_true = np.array([\"non-cat\", \"cat\", \"non-cat\", \"cat\", \"non-cat\"])\n     >>> y_pred = np.array([\"cat\", \"cat\", \"non-cat\", \"non-cat\", \"non-cat\"])\n-    >>> class_likelihood_ratios(y_true, y_pred, labels=[\"non-cat\", \"cat\"],\n-    ...                          replace_undefined_by=1.0)\n+    >>> class_likelihood_ratios(y_true, y_pred, labels=[\"non-cat\", \"cat\"])\n     (1.5, 0.75)\n     \"\"\"\n     # TODO(1.9): When `raise_warning` is removed, the following changes need to be made:\n     # The checks for `raise_warning==True` need to be removed and we will always warn,\n-    # the default return value of `replace_undefined_by` should be updated from `np.nan`\n-    # (which was kept for backwards compatibility) to `1.0`, its hidden option\n-    # (\"default\") is not used anymore, some warning messages can be removed, the Warns\n-    # section in the docstring should not mention `raise_warning` anymore and the\n-    # \"Mathematical divergences\" section in model_evaluation.rst needs to be updated on\n-    # the new default behaviour of `replace_undefined_by`.\n+    # remove `FutureWarning`, and the Warns section in the docstring should not mention\n+    # `raise_warning` anymore.\n     y_true, y_pred = attach_unique(y_true, y_pred)\n     y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n     if y_type != \"binary\":\n@@ -2220,28 +2213,11 @@ class are present in `y_true`): both likelihood ratios are undefined.\n         \"`UndefinedMetricWarning` will always be raised in case of a division by zero \"\n         \"and the value set with the `replace_undefined_by` param will be returned.\"\n     )\n-    mgs_changed_default = (\n-        \"The default return value of `class_likelihood_ratios` in case of a division \"\n-        \"by zero has been deprecated in 1.7 and will be changed to the worst scores \"\n-        \"(`(1.0, 1.0)`) in version 1.9. Set `replace_undefined_by=1.0` to use the new\"\n-        \"default and to silence this Warning.\"\n-    )\n     if raise_warning != \"deprecated\":\n-        warnings.warn(\n-            \" \".join((msg_deprecated_param, mgs_changed_default)), FutureWarning\n-        )\n+        warnings.warn(msg_deprecated_param, FutureWarning)\n     else:\n-        if replace_undefined_by == \"default\":\n-            # TODO(1.9): Remove. If users don't set any return values in case of a\n-            # division by zero (`raise_warning=\"deprecated\"` and\n-            # `replace_undefined_by=\"default\"`) they still get a FutureWarning about\n-            # changing default return values:\n-            warnings.warn(mgs_changed_default, FutureWarning)\n         raise_warning = True\n \n-    if replace_undefined_by == \"default\":\n-        replace_undefined_by = np.nan\n-\n     if replace_undefined_by == 1.0:\n         replace_undefined_by = {\"LR+\": 1.0, \"LR-\": 1.0}\n \n@@ -2293,12 +2269,12 @@ class are present in `y_true`): both likelihood ratios are undefined.\n \n     # if `support_pos == 0`a division by zero will occur\n     if support_pos == 0:\n-        # TODO(1.9): Change return values in warning message to new default: the worst\n-        # possible scores: `(1.0, 1.0)`\n         msg = (\n             \"No samples of the positive class are present in `y_true`. \"\n             \"`positive_likelihood_ratio` and `negative_likelihood_ratio` are both set \"\n-            \"to `np.nan`.\"\n+            \"to `np.nan`. Use the `replace_undefined_by` param to control this \"\n+            \"behavior. To suppress this warning or turn it into an error, see Python's \"\n+            \"`warnings` module and `warnings.catch_warnings()`.\"\n         )\n         warnings.warn(msg, UndefinedMetricWarning, stacklevel=2)\n         positive_likelihood_ratio = np.nan\n@@ -2315,9 +2291,8 @@ class are present in `y_true`): both likelihood ratios are undefined.\n             else:\n                 msg_beginning = \"`positive_likelihood_ratio` is ill-defined and \"\n             msg_end = \"set to `np.nan`. Use the `replace_undefined_by` param to \"\n-            \"control this behavior.\"\n-            # TODO(1.9): Change return value in warning message to new default: `1.0`,\n-            # which is the worst possible score for \"LR+\"\n+            \"control this behavior. To suppress this warning or turn it into an error, \"\n+            \"see Python's `warnings` module and `warnings.catch_warnings()`.\"\n             warnings.warn(msg_beginning + msg_end, UndefinedMetricWarning, stacklevel=2)\n         if isinstance(replace_undefined_by, float) and np.isnan(replace_undefined_by):\n             positive_likelihood_ratio = replace_undefined_by\n@@ -2332,11 +2307,11 @@ class are present in `y_true`): both likelihood ratios are undefined.\n     # if `tn == 0`a division by zero will occur\n     if tn == 0:\n         if raise_warning:\n-            # TODO(1.9): Change return value in warning message to new default: `1.0`,\n-            # which is the worst possible score for \"LR-\"\n             msg = (\n                 \"`negative_likelihood_ratio` is ill-defined and set to `np.nan`. \"\n-                \"Use the `replace_undefined_by` param to control this behavior.\"\n+                \"Use the `replace_undefined_by` param to control this behavior. To \"\n+                \"suppress this warning or turn it into an error, see Python's \"\n+                \"`warnings` module and `warnings.catch_warnings()`.\"\n             )\n             warnings.warn(msg, UndefinedMetricWarning, stacklevel=2)\n         if isinstance(replace_undefined_by, float) and np.isnan(replace_undefined_by):\ndiff --git a/sklearn/metrics/tests/test_classification.py b/sklearn/metrics/tests/test_classification.py\nindex 19a326ff184f8..b66353e5ecfab 100644\n--- a/sklearn/metrics/tests/test_classification.py\n+++ b/sklearn/metrics/tests/test_classification.py\n@@ -709,9 +709,7 @@ def test_likelihood_ratios_warnings(params, warn_msg):\n     # least one of the ratios is ill-defined.\n \n     with pytest.warns(UserWarning, match=warn_msg):\n-        # TODO(1.9): remove setting `replace_undefined_by` since this will be set by\n-        # default\n-        class_likelihood_ratios(replace_undefined_by=1.0, **params)\n+        class_likelihood_ratios(**params)\n \n \n @pytest.mark.parametrize(\n@@ -736,7 +734,6 @@ def test_likelihood_ratios_errors(params, err_msg):\n         class_likelihood_ratios(**params)\n \n \n-# TODO(1.9): remove setting `replace_undefined_by` since this will be set by default\n def test_likelihood_ratios():\n     # Build confusion matrix with tn=9, fp=8, fn=1, tp=2,\n     # sensitivity=2/3, specificity=9/17, prevalence=3/20,\n@@ -744,14 +741,12 @@ def test_likelihood_ratios():\n     y_true = np.array([1] * 3 + [0] * 17)\n     y_pred = np.array([1] * 2 + [0] * 10 + [1] * 8)\n \n-    pos, neg = class_likelihood_ratios(y_true, y_pred, replace_undefined_by=np.nan)\n+    pos, neg = class_likelihood_ratios(y_true, y_pred)\n     assert_allclose(pos, 34 / 24)\n     assert_allclose(neg, 17 / 27)\n \n     # Build limit case with y_pred = y_true\n-    pos, neg = class_likelihood_ratios(y_true, y_true, replace_undefined_by=np.nan)\n-    # TODO(1.9): replace next line with `assert_array_equal(pos, 1.0)`, since\n-    # `replace_undefined_by` has a new default:\n+    pos, neg = class_likelihood_ratios(y_true, y_true)\n     assert_array_equal(pos, np.nan * 2)\n     assert_allclose(neg, np.zeros(2), rtol=1e-12)\n \n@@ -759,9 +754,7 @@ def test_likelihood_ratios():\n     # sensitivity=2/3, specificity=9/12, prevalence=3/20,\n     # LR+=24/9, LR-=12/27\n     sample_weight = np.array([1.0] * 15 + [0.0] * 5)\n-    pos, neg = class_likelihood_ratios(\n-        y_true, y_pred, sample_weight=sample_weight, replace_undefined_by=np.nan\n-    )\n+    pos, neg = class_likelihood_ratios(y_true, y_pred, sample_weight=sample_weight)\n     assert_allclose(pos, 24 / 9)\n     assert_allclose(neg, 12 / 27)\n \n@@ -779,18 +772,6 @@ def test_likelihood_ratios_raise_warning_deprecation(raise_warning):\n         class_likelihood_ratios(y_true, y_pred, raise_warning=raise_warning)\n \n \n-# TODO(1.9): remove test\n-def test_likelihood_ratios_raise_default_deprecation():\n-    \"\"\"Test that class_likelihood_ratios raises a `FutureWarning` when `raise_warning`\n-    and `replace_undefined_by` are both default.\"\"\"\n-    y_true = np.array([1, 0])\n-    y_pred = np.array([1, 0])\n-\n-    msg = \"The default return value of `class_likelihood_ratios` in case of a\"\n-    with pytest.warns(FutureWarning, match=msg):\n-        class_likelihood_ratios(y_true, y_pred)\n-\n-\n def test_likelihood_ratios_replace_undefined_by_worst():\n     \"\"\"Test that class_likelihood_ratios returns the worst scores `1.0` for both LR+ and\n     LR- when `replace_undefined_by=1` is set.\"\"\"\n",
  "fail_to_pass": [],
  "pass_to_pass": [],
  "relevant_files": [
    "sklearn/metrics/_classification.py",
    "sklearn/metrics/tests/test_classification.py"
  ],
  "difficulty": "medium",
  "created_at": "2025-05-07T11:18:24Z",
  "pr_url": "https://github.com/scikit-learn/scikit-learn/pull/31331",
  "issue_url": "https://github.com/scikit-learn/scikit-learn/issues/29048"
}