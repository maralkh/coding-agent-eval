{
  "id": "scikit-learn__scikit-learn-31362",
  "repo": "scikit-learn/scikit-learn",
  "base_commit": "13c7ce8c6b4dc146b45d38f423c8c99c7efacaf3",
  "issue_number": 1234,
  "issue_title": "MRG fix bincount mess I made in kmeans.",
  "issue_body": "This should clean up the stuff I pushed earlier.\ncc @ogrisel @gaelvaroquaux Could you have a brief look? What I pushed earlier is buggy but I didn't dare push again after so many failed fixes.\n",
  "pr_number": 31362,
  "pr_title": "TST use global_random_seed in `sklearn/linear_model/tests/test_logistic.py`",
  "gold_patch": "diff --git a/sklearn/linear_model/tests/test_logistic.py b/sklearn/linear_model/tests/test_logistic.py\nindex e8e41a25c6e2b..fdfe83889e475 100644\n--- a/sklearn/linear_model/tests/test_logistic.py\n+++ b/sklearn/linear_model/tests/test_logistic.py\n@@ -1,7 +1,6 @@\n import itertools\n import os\n import warnings\n-from functools import partial\n \n import numpy as np\n import pytest\n@@ -19,13 +18,7 @@\n from sklearn.base import clone\n from sklearn.datasets import load_iris, make_classification, make_low_rank_matrix\n from sklearn.exceptions import ConvergenceWarning\n-from sklearn.linear_model import SGDClassifier\n-from sklearn.linear_model._logistic import (\n-    LogisticRegression as LogisticRegressionDefault,\n-)\n-from sklearn.linear_model._logistic import (\n-    LogisticRegressionCV as LogisticRegressionCVDefault,\n-)\n+from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, SGDClassifier\n from sklearn.linear_model._logistic import (\n     _log_reg_scoring_path,\n     _logistic_regression_path,\n@@ -48,9 +41,6 @@\n pytestmark = pytest.mark.filterwarnings(\n     \"error::sklearn.exceptions.ConvergenceWarning:sklearn.*\"\n )\n-# Fixing random_state helps prevent ConvergenceWarnings\n-LogisticRegression = partial(LogisticRegressionDefault, random_state=0)\n-LogisticRegressionCV = partial(LogisticRegressionCVDefault, random_state=0)\n \n \n SOLVERS = (\"lbfgs\", \"liblinear\", \"newton-cg\", \"newton-cholesky\", \"sag\", \"saga\")\n@@ -82,19 +72,19 @@ def check_predictions(clf, X, y):\n def test_predict_2_classes(csr_container):\n     # Simple sanity check on a 2 classes dataset\n     # Make sure it predicts the correct result on simple datasets.\n-    check_predictions(LogisticRegression(random_state=0), X, Y1)\n-    check_predictions(LogisticRegression(random_state=0), csr_container(X), Y1)\n+    check_predictions(LogisticRegression(), X, Y1)\n+    check_predictions(LogisticRegression(), csr_container(X), Y1)\n \n-    check_predictions(LogisticRegression(C=100, random_state=0), X, Y1)\n-    check_predictions(LogisticRegression(C=100, random_state=0), csr_container(X), Y1)\n+    check_predictions(LogisticRegression(C=100), X, Y1)\n+    check_predictions(LogisticRegression(C=100), csr_container(X), Y1)\n \n-    check_predictions(LogisticRegression(fit_intercept=False, random_state=0), X, Y1)\n-    check_predictions(\n-        LogisticRegression(fit_intercept=False, random_state=0), csr_container(X), Y1\n-    )\n+    check_predictions(LogisticRegression(fit_intercept=False), X, Y1)\n+    check_predictions(LogisticRegression(fit_intercept=False), csr_container(X), Y1)\n \n \n def test_logistic_cv_mock_scorer():\n+    \"\"\"Test that LogisticRegressionCV calls the scorer.\"\"\"\n+\n     class MockScorer:\n         def __init__(self):\n             self.calls = 0\n@@ -156,37 +146,35 @@ def test_predict_3_classes(csr_container):\n     \"clf\",\n     [\n         LogisticRegression(C=len(iris.data), solver=\"liblinear\", multi_class=\"ovr\"),\n-        LogisticRegression(C=len(iris.data), solver=\"lbfgs\"),\n+        LogisticRegression(C=len(iris.data), solver=\"lbfgs\", max_iter=200),\n         LogisticRegression(C=len(iris.data), solver=\"newton-cg\"),\n         LogisticRegression(\n-            C=len(iris.data), solver=\"sag\", tol=1e-2, multi_class=\"ovr\", random_state=42\n+            C=len(iris.data),\n+            solver=\"sag\",\n+            tol=1e-2,\n+            multi_class=\"ovr\",\n         ),\n         LogisticRegression(\n             C=len(iris.data),\n             solver=\"saga\",\n             tol=1e-2,\n             multi_class=\"ovr\",\n-            random_state=42,\n         ),\n         LogisticRegression(C=len(iris.data), solver=\"newton-cholesky\"),\n     ],\n )\n-def test_predict_iris(clf):\n+def test_predict_iris(clf, global_random_seed):\n     \"\"\"Test logistic regression with the iris dataset.\n \n     Test that both multinomial and OvR solvers handle multiclass data correctly and\n     give good accuracy score (>0.95) for the training data.\n     \"\"\"\n-    n_samples, n_features = iris.data.shape\n+    n_samples, _ = iris.data.shape\n     target = iris.target_names[iris.target]\n \n-    if clf.solver == \"lbfgs\":\n-        # lbfgs has convergence issues on the iris data with its default max_iter=100\n-        with warnings.catch_warnings():\n-            warnings.simplefilter(\"ignore\", ConvergenceWarning)\n-            clf.fit(iris.data, target)\n-    else:\n-        clf.fit(iris.data, target)\n+    if clf.solver in (\"sag\", \"saga\", \"liblinear\"):\n+        clf.set_params(random_state=global_random_seed)\n+    clf.fit(iris.data, target)\n     assert_array_equal(np.unique(target), clf.classes_)\n \n     pred = clf.predict(iris.data)\n@@ -307,7 +295,7 @@ def test_sparsify(coo_container):\n     n_samples, n_features = iris.data.shape\n     target = iris.target_names[iris.target]\n     X = scale(iris.data)\n-    clf = LogisticRegression(random_state=0).fit(X, target)\n+    clf = LogisticRegression().fit(X, target)\n \n     pred_d_d = clf.decision_function(X)\n \n@@ -348,7 +336,7 @@ def test_inconsistent_input():\n \n def test_write_parameters():\n     # Test that we can write to coef_ and intercept_\n-    clf = LogisticRegression(random_state=0)\n+    clf = LogisticRegression()\n     clf.fit(X, Y1)\n     clf.coef_[:] = 0\n     clf.intercept_[:] = 0\n@@ -360,15 +348,15 @@ def test_nan():\n     # Regression test for Issue #252: fit used to go into an infinite loop.\n     Xnan = np.array(X, dtype=np.float64)\n     Xnan[0, 1] = np.nan\n-    logistic = LogisticRegression(random_state=0)\n+    logistic = LogisticRegression()\n \n     with pytest.raises(ValueError):\n         logistic.fit(Xnan, Y1)\n \n \n-def test_consistency_path():\n+def test_consistency_path(global_random_seed):\n     # Test that the path algorithm is consistent\n-    rng = np.random.RandomState(0)\n+    rng = np.random.RandomState(global_random_seed)\n     X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))\n     y = [1] * 100 + [-1] * 100\n     Cs = np.logspace(0, 4, 10)\n@@ -385,7 +373,7 @@ def test_consistency_path():\n             tol=1e-5,\n             solver=solver,\n             max_iter=1000,\n-            random_state=0,\n+            random_state=global_random_seed,\n         )\n         for i, C in enumerate(Cs):\n             lr = LogisticRegression(\n@@ -393,7 +381,7 @@ def test_consistency_path():\n                 fit_intercept=False,\n                 tol=1e-5,\n                 solver=solver,\n-                random_state=0,\n+                random_state=global_random_seed,\n                 max_iter=1000,\n             )\n             lr.fit(X, y)\n@@ -412,13 +400,13 @@ def test_consistency_path():\n             tol=1e-6,\n             solver=solver,\n             intercept_scaling=10000.0,\n-            random_state=0,\n+            random_state=global_random_seed,\n         )\n         lr = LogisticRegression(\n             C=Cs[0],\n             tol=1e-6,\n             intercept_scaling=10000.0,\n-            random_state=0,\n+            random_state=global_random_seed,\n             solver=solver,\n         )\n         lr.fit(X, y)\n@@ -450,25 +438,25 @@ def test_logistic_regression_path_convergence_fail():\n     assert \"linear_model.html#logistic-regression\" in warn_msg\n \n \n-def test_liblinear_dual_random_state():\n+def test_liblinear_dual_random_state(global_random_seed):\n     # random_state is relevant for liblinear solver only if dual=True\n-    X, y = make_classification(n_samples=20, random_state=0)\n+    X, y = make_classification(n_samples=20, random_state=global_random_seed)\n     lr1 = LogisticRegression(\n-        random_state=0,\n+        random_state=global_random_seed,\n         dual=True,\n         tol=1e-3,\n         solver=\"liblinear\",\n     )\n     lr1.fit(X, y)\n     lr2 = LogisticRegression(\n-        random_state=0,\n+        random_state=global_random_seed,\n         dual=True,\n         tol=1e-3,\n         solver=\"liblinear\",\n     )\n     lr2.fit(X, y)\n     lr3 = LogisticRegression(\n-        random_state=8,\n+        random_state=global_random_seed + 1,\n         dual=True,\n         tol=1e-3,\n         solver=\"liblinear\",\n@@ -483,19 +471,25 @@ def test_liblinear_dual_random_state():\n         assert_array_almost_equal(lr1.coef_, lr3.coef_)\n \n \n-def test_logistic_cv():\n+def test_logistic_cv(global_random_seed):\n     # test for LogisticRegressionCV object\n     n_samples, n_features = 50, 5\n-    rng = np.random.RandomState(0)\n+    rng = np.random.RandomState(global_random_seed)\n     X_ref = rng.randn(n_samples, n_features)\n     y = np.sign(X_ref.dot(5 * rng.randn(n_features)))\n     X_ref -= X_ref.mean()\n     X_ref /= X_ref.std()\n     lr_cv = LogisticRegressionCV(\n-        Cs=[1.0], fit_intercept=False, solver=\"liblinear\", cv=3\n+        Cs=[1.0],\n+        fit_intercept=False,\n+        random_state=global_random_seed,\n+        solver=\"liblinear\",\n+        cv=3,\n     )\n     lr_cv.fit(X_ref, y)\n-    lr = LogisticRegression(C=1.0, fit_intercept=False, solver=\"liblinear\")\n+    lr = LogisticRegression(\n+        C=1.0, fit_intercept=False, random_state=global_random_seed, solver=\"liblinear\"\n+    )\n     lr.fit(X_ref, y)\n     assert_array_almost_equal(lr.coef_, lr_cv.coef_)\n \n@@ -525,12 +519,14 @@ def test_logistic_cv():\n         (\"recall\", [\"_macro\", \"_weighted\"]),\n     ],\n )\n-def test_logistic_cv_multinomial_score(scoring, multiclass_agg_list):\n+def test_logistic_cv_multinomial_score(\n+    global_random_seed, scoring, multiclass_agg_list\n+):\n     # test that LogisticRegressionCV uses the right score to compute its\n     # cross-validation scores when using a multinomial scoring\n     # see https://github.com/scikit-learn/scikit-learn/issues/8720\n     X, y = make_classification(\n-        n_samples=100, random_state=0, n_classes=3, n_informative=6\n+        n_samples=100, random_state=global_random_seed, n_classes=3, n_informative=6\n     )\n     train, test = np.arange(80), np.arange(80, 100)\n     lr = LogisticRegression(C=1.0)\n@@ -561,7 +557,7 @@ def test_logistic_cv_multinomial_score(scoring, multiclass_agg_list):\n \n \n def test_multinomial_logistic_regression_string_inputs():\n-    # Test with string labels for LogisticRegression(CV)\n+    \"\"\"Test internally encode labels\"\"\"\n     n_samples, n_features, n_classes = 50, 5, 3\n     X_ref, y = make_classification(\n         n_samples=n_samples,\n@@ -598,12 +594,15 @@ def test_multinomial_logistic_regression_string_inputs():\n     lr_cv_str = LogisticRegression(class_weight={\"bar\": 1, \"baz\": 2, \"foo\": 0}).fit(\n         X_ref, y_str\n     )\n+\n     assert sorted(np.unique(lr_cv_str.predict(X_ref))) == [\"bar\", \"baz\"]\n \n \n @pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\n-def test_logistic_cv_sparse(csr_container):\n-    X, y = make_classification(n_samples=50, n_features=5, random_state=0)\n+def test_logistic_cv_sparse(global_random_seed, csr_container):\n+    X, y = make_classification(\n+        n_samples=100, n_features=5, random_state=global_random_seed\n+    )\n     X[X < 1.0] = 0.0\n     csr = csr_container(X)\n \n@@ -685,30 +684,39 @@ def test_ovr_multinomial_iris():\n         assert scores.shape == (3, n_cv, 10)\n \n \n-def test_logistic_regression_solvers():\n+def test_logistic_regression_solvers(global_random_seed):\n     \"\"\"Test solvers converge to the same result.\"\"\"\n-    X, y = make_classification(n_features=10, n_informative=5, random_state=0)\n+    X, y = make_classification(\n+        n_samples=200, n_features=10, n_informative=5, random_state=global_random_seed\n+    )\n \n-    params = dict(fit_intercept=False, random_state=42)\n+    params = dict(C=0.1, fit_intercept=False, random_state=global_random_seed)\n \n-    regressors = {\n+    classifiers = {\n         solver: LogisticRegression(solver=solver, **params).fit(X, y)\n         for solver in SOLVERS\n     }\n \n-    for solver_1, solver_2 in itertools.combinations(regressors, r=2):\n+    for solver_1, solver_2 in itertools.combinations(classifiers, r=2):\n         assert_array_almost_equal(\n-            regressors[solver_1].coef_, regressors[solver_2].coef_, decimal=3\n+            classifiers[solver_1].coef_, classifiers[solver_2].coef_, decimal=3\n         )\n \n \n # TODO(1.8): remove filterwarnings after the deprecation of multi_class\n+# FIXME: the random state is fixed in the following test because SAG fails\n+# to converge to the same results as BFGS for 20% of the cases. Usually it\n+# means that there is one coefficient that is slightly different.\n @pytest.mark.filterwarnings(\"ignore:.*'multi_class' was deprecated.*:FutureWarning\")\n @pytest.mark.parametrize(\"fit_intercept\", [False, True])\n def test_logistic_regression_solvers_multiclass(fit_intercept):\n     \"\"\"Test solvers converge to the same result for multiclass problems.\"\"\"\n     X, y = make_classification(\n-        n_samples=20, n_features=20, n_informative=10, n_classes=3, random_state=0\n+        n_samples=20,\n+        n_features=20,\n+        n_informative=10,\n+        n_classes=3,\n+        random_state=0,\n     )\n     tol = 1e-8\n     params = dict(fit_intercept=fit_intercept, tol=tol, random_state=42)\n@@ -717,24 +725,24 @@ def test_logistic_regression_solvers_multiclass(fit_intercept):\n     # proper convergence.\n     solver_max_iter = {\"lbfgs\": 200, \"sag\": 10_000, \"saga\": 10_000}\n \n-    regressors = {\n+    classifiers = {\n         solver: LogisticRegression(\n             solver=solver, max_iter=solver_max_iter.get(solver, 100), **params\n         ).fit(X, y)\n         for solver in set(SOLVERS) - set([\"liblinear\"])\n     }\n \n-    for solver_1, solver_2 in itertools.combinations(regressors, r=2):\n+    for solver_1, solver_2 in itertools.combinations(classifiers, r=2):\n         assert_allclose(\n-            regressors[solver_1].coef_,\n-            regressors[solver_2].coef_,\n+            classifiers[solver_1].coef_,\n+            classifiers[solver_2].coef_,\n             rtol=5e-3 if (solver_1 == \"saga\" or solver_2 == \"saga\") else 1e-3,\n             err_msg=f\"{solver_1} vs {solver_2}\",\n         )\n         if fit_intercept:\n             assert_allclose(\n-                regressors[solver_1].intercept_,\n-                regressors[solver_2].intercept_,\n+                classifiers[solver_1].intercept_,\n+                classifiers[solver_2].intercept_,\n                 rtol=5e-3 if (solver_1 == \"saga\" or solver_2 == \"saga\") else 1e-3,\n                 err_msg=f\"{solver_1} vs {solver_2}\",\n             )\n@@ -775,7 +783,7 @@ def test_logistic_regression_solvers_multiclass_unpenalized(\n         y[i] = np.argwhere(rng.multinomial(n=1, pvals=proba[i, :]))[0, 0]\n \n     tol = 1e-9\n-    params = dict(fit_intercept=fit_intercept, random_state=42)\n+    params = dict(fit_intercept=fit_intercept, random_state=global_random_seed)\n     solver_max_iter = {\"lbfgs\": 200, \"sag\": 10_000, \"saga\": 10_000}\n     solver_tol = {\"sag\": 1e-8, \"saga\": 1e-8}\n     regressors = {\n@@ -1030,7 +1038,7 @@ def _compute_class_weight_dictionary(y):\n \n \n @pytest.mark.parametrize(\"csr_container\", [lambda x: x] + CSR_CONTAINERS)\n-def test_logistic_regression_class_weights(csr_container):\n+def test_logistic_regression_class_weights(global_random_seed, csr_container):\n     # Scale data to avoid convergence warnings with the lbfgs solver\n     X_iris = scale(iris.data)\n     # Multinomial case: remove 90% of class 0\n@@ -1040,7 +1048,7 @@ def test_logistic_regression_class_weights(csr_container):\n     class_weight_dict = _compute_class_weight_dictionary(y)\n \n     for solver in set(SOLVERS) - set([\"liblinear\", \"newton-cholesky\"]):\n-        params = dict(solver=solver, max_iter=1000)\n+        params = dict(solver=solver, max_iter=2000, random_state=global_random_seed)\n         clf1 = LogisticRegression(class_weight=\"balanced\", **params)\n         clf2 = LogisticRegression(class_weight=class_weight_dict, **params)\n         clf1.fit(X, y)\n@@ -1060,7 +1068,8 @@ def test_logistic_regression_class_weights(csr_container):\n     class_weight_dict = _compute_class_weight_dictionary(y)\n \n     for solver in SOLVERS:\n-        params = dict(solver=solver, max_iter=1000)\n+        params = dict(solver=solver, max_iter=1000, random_state=global_random_seed)\n+\n         clf1 = LogisticRegression(class_weight=\"balanced\", **params)\n         clf2 = LogisticRegression(class_weight=class_weight_dict, **params)\n         clf1.fit(X, y)\n@@ -1068,25 +1077,24 @@ def test_logistic_regression_class_weights(csr_container):\n         assert_array_almost_equal(clf1.coef_, clf2.coef_, decimal=6)\n \n \n-def test_logistic_regression_multinomial():\n+def test_logistic_regression_multinomial(global_random_seed):\n     # Tests for the multinomial option in logistic regression\n \n     # Some basic attributes of Logistic Regression\n-    n_samples, n_features, n_classes = 50, 20, 3\n+    n_samples, n_features, n_classes = 200, 20, 3\n     X, y = make_classification(\n         n_samples=n_samples,\n         n_features=n_features,\n         n_informative=10,\n         n_classes=n_classes,\n-        random_state=0,\n+        random_state=global_random_seed,\n     )\n \n     X = StandardScaler(with_mean=False).fit_transform(X)\n \n-    # 'lbfgs' is used as a referenced\n-    solver = \"lbfgs\"\n-    ref_i = LogisticRegression(solver=solver, tol=1e-6)\n-    ref_w = LogisticRegression(solver=solver, fit_intercept=False, tol=1e-6)\n+    # 'lbfgs' solver is used as a reference - it's the default\n+    ref_i = LogisticRegression(tol=1e-10)\n+    ref_w = LogisticRegression(fit_intercept=False, tol=1e-10)\n     ref_i.fit(X, y)\n     ref_w.fit(X, y)\n     assert ref_i.coef_.shape == (n_classes, n_features)\n@@ -1094,15 +1102,15 @@ def test_logistic_regression_multinomial():\n     for solver in [\"sag\", \"saga\", \"newton-cg\"]:\n         clf_i = LogisticRegression(\n             solver=solver,\n-            random_state=42,\n+            random_state=global_random_seed,\n             max_iter=2000,\n-            tol=1e-7,\n+            tol=1e-10,\n         )\n         clf_w = LogisticRegression(\n             solver=solver,\n-            random_state=42,\n+            random_state=global_random_seed,\n             max_iter=2000,\n-            tol=1e-7,\n+            tol=1e-10,\n             fit_intercept=False,\n         )\n         clf_i.fit(X, y)\n@@ -1111,7 +1119,7 @@ def test_logistic_regression_multinomial():\n         assert clf_w.coef_.shape == (n_classes, n_features)\n \n         # Compare solutions between lbfgs and the other solvers\n-        assert_allclose(ref_i.coef_, clf_i.coef_, rtol=1e-3)\n+        assert_allclose(ref_i.coef_, clf_i.coef_, rtol=3e-3)\n         assert_allclose(ref_w.coef_, clf_w.coef_, rtol=1e-2)\n         assert_allclose(ref_i.intercept_, clf_i.intercept_, rtol=1e-3)\n \n@@ -1120,21 +1128,29 @@ def test_logistic_regression_multinomial():\n     # folds, it need not be exactly the same.\n     for solver in [\"lbfgs\", \"newton-cg\", \"sag\", \"saga\"]:\n         clf_path = LogisticRegressionCV(\n-            solver=solver, max_iter=2000, tol=1e-6, Cs=[1.0]\n+            solver=solver,\n+            random_state=global_random_seed,\n+            max_iter=2000,\n+            tol=1e-10,\n+            Cs=[1.0],\n         )\n         clf_path.fit(X, y)\n         assert_allclose(clf_path.coef_, ref_i.coef_, rtol=1e-2)\n         assert_allclose(clf_path.intercept_, ref_i.intercept_, rtol=1e-2)\n \n \n-def test_liblinear_decision_function_zero():\n+def test_liblinear_decision_function_zero(global_random_seed):\n     # Test negative prediction when decision_function values are zero.\n     # Liblinear predicts the positive class when decision_function values\n     # are zero. This is a test to verify that we do not do the same.\n     # See Issue: https://github.com/scikit-learn/scikit-learn/issues/3600\n     # and the PR https://github.com/scikit-learn/scikit-learn/pull/3623\n-    X, y = make_classification(n_samples=5, n_features=5, random_state=0)\n-    clf = LogisticRegression(fit_intercept=False, solver=\"liblinear\")\n+    X, y = make_classification(\n+        n_samples=5, n_features=5, random_state=global_random_seed\n+    )\n+    clf = LogisticRegression(\n+        fit_intercept=False, solver=\"liblinear\", random_state=global_random_seed\n+    )\n     clf.fit(X, y)\n \n     # Dummy data such that the decision function becomes zero.\n@@ -1143,20 +1159,24 @@ def test_liblinear_decision_function_zero():\n \n \n @pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\n-def test_liblinear_logregcv_sparse(csr_container):\n+def test_liblinear_logregcv_sparse(csr_container, global_random_seed):\n     # Test LogRegCV with solver='liblinear' works for sparse matrices\n \n-    X, y = make_classification(n_samples=10, n_features=5, random_state=0)\n+    X, y = make_classification(\n+        n_samples=10, n_features=5, random_state=global_random_seed\n+    )\n     clf = LogisticRegressionCV(solver=\"liblinear\")\n     clf.fit(csr_container(X), y)\n \n \n @pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\n-def test_saga_sparse(csr_container):\n+def test_saga_sparse(csr_container, global_random_seed):\n     # Test LogRegCV with solver='liblinear' works for sparse matrices\n \n-    X, y = make_classification(n_samples=10, n_features=5, random_state=0)\n-    clf = LogisticRegressionCV(solver=\"saga\", tol=1e-2)\n+    X, y = make_classification(\n+        n_samples=10, n_features=5, random_state=global_random_seed\n+    )\n+    clf = LogisticRegressionCV(solver=\"saga\", tol=1e-2, random_state=global_random_seed)\n     clf.fit(csr_container(X), y)\n \n \n@@ -1168,13 +1188,15 @@ def test_logreg_intercept_scaling_zero():\n     assert clf.intercept_ == 0.0\n \n \n-def test_logreg_l1():\n+def test_logreg_l1(global_random_seed):\n     # Because liblinear penalizes the intercept and saga does not, we do not\n     # fit the intercept to make it possible to compare the coefficients of\n     # the two models at convergence.\n-    rng = np.random.RandomState(42)\n-    n_samples = 50\n-    X, y = make_classification(n_samples=n_samples, n_features=20, random_state=0)\n+    rng = np.random.RandomState(global_random_seed)\n+    n_samples = 100\n+    X, y = make_classification(\n+        n_samples=n_samples, n_features=20, random_state=global_random_seed\n+    )\n     X_noise = rng.normal(size=(n_samples, 3))\n     X_constant = np.ones(shape=(n_samples, 2))\n     X = np.concatenate((X, X_noise, X_constant), axis=1)\n@@ -1183,7 +1205,9 @@ def test_logreg_l1():\n         C=1.0,\n         solver=\"liblinear\",\n         fit_intercept=False,\n+        max_iter=10000,\n         tol=1e-10,\n+        random_state=global_random_seed,\n     )\n     lr_liblinear.fit(X, y)\n \n@@ -1192,26 +1216,25 @@ def test_logreg_l1():\n         C=1.0,\n         solver=\"saga\",\n         fit_intercept=False,\n-        max_iter=1000,\n+        max_iter=10000,\n         tol=1e-10,\n+        random_state=global_random_seed,\n     )\n     lr_saga.fit(X, y)\n-    assert_array_almost_equal(lr_saga.coef_, lr_liblinear.coef_)\n \n-    # Noise and constant features should be regularized to zero by the l1\n-    # penalty\n-    assert_array_almost_equal(lr_liblinear.coef_[0, -5:], np.zeros(5))\n-    assert_array_almost_equal(lr_saga.coef_[0, -5:], np.zeros(5))\n+    assert_allclose(lr_saga.coef_, lr_liblinear.coef_, atol=0.3)\n \n \n @pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\n-def test_logreg_l1_sparse_data(csr_container):\n+def test_logreg_l1_sparse_data(global_random_seed, csr_container):\n     # Because liblinear penalizes the intercept and saga does not, we do not\n     # fit the intercept to make it possible to compare the coefficients of\n     # the two models at convergence.\n-    rng = np.random.RandomState(42)\n+    rng = np.random.RandomState(global_random_seed)\n     n_samples = 50\n-    X, y = make_classification(n_samples=n_samples, n_features=20, random_state=0)\n+    X, y = make_classification(\n+        n_samples=n_samples, n_features=20, random_state=global_random_seed\n+    )\n     X_noise = rng.normal(scale=0.1, size=(n_samples, 3))\n     X_constant = np.zeros(shape=(n_samples, 2))\n     X = np.concatenate((X, X_noise, X_constant), axis=1)\n@@ -1224,6 +1247,8 @@ def test_logreg_l1_sparse_data(csr_container):\n         solver=\"liblinear\",\n         fit_intercept=False,\n         tol=1e-10,\n+        max_iter=10000,\n+        random_state=global_random_seed,\n     )\n     lr_liblinear.fit(X, y)\n \n@@ -1232,8 +1257,9 @@ def test_logreg_l1_sparse_data(csr_container):\n         C=1.0,\n         solver=\"saga\",\n         fit_intercept=False,\n-        max_iter=1000,\n+        max_iter=10000,\n         tol=1e-10,\n+        random_state=global_random_seed,\n     )\n     lr_saga.fit(X, y)\n     assert_array_almost_equal(lr_saga.coef_, lr_liblinear.coef_)\n@@ -1248,16 +1274,16 @@ def test_logreg_l1_sparse_data(csr_container):\n         C=1.0,\n         solver=\"saga\",\n         fit_intercept=False,\n-        max_iter=1000,\n+        max_iter=10000,\n         tol=1e-10,\n+        random_state=global_random_seed,\n     )\n     lr_saga_dense.fit(X.toarray(), y)\n     assert_array_almost_equal(lr_saga.coef_, lr_saga_dense.coef_)\n \n \n-@pytest.mark.parametrize(\"random_seed\", [42])\n @pytest.mark.parametrize(\"penalty\", [\"l1\", \"l2\"])\n-def test_logistic_regression_cv_refit(random_seed, penalty):\n+def test_logistic_regression_cv_refit(global_random_seed, penalty):\n     # Test that when refit=True, logistic regression cv with the saga solver\n     # converges to the same solution as logistic regression with a fixed\n     # regularization parameter.\n@@ -1266,12 +1292,14 @@ def test_logistic_regression_cv_refit(random_seed, penalty):\n     # logistic regression loss is convex, we should still recover exactly\n     # the same solution as long as the stopping criterion is strict enough (and\n     # that there are no exactly duplicated features when penalty='l1').\n-    X, y = make_classification(n_samples=100, n_features=20, random_state=random_seed)\n+    X, y = make_classification(\n+        n_samples=100, n_features=20, random_state=global_random_seed\n+    )\n     common_params = dict(\n         solver=\"saga\",\n         penalty=penalty,\n-        random_state=random_seed,\n-        max_iter=1000,\n+        random_state=global_random_seed,\n+        max_iter=10000,\n         tol=1e-12,\n     )\n     lr_cv = LogisticRegressionCV(Cs=[1.0], refit=True, **common_params)\n@@ -1281,17 +1309,21 @@ def test_logistic_regression_cv_refit(random_seed, penalty):\n     assert_array_almost_equal(lr_cv.coef_, lr.coef_)\n \n \n-def test_logreg_predict_proba_multinomial():\n+def test_logreg_predict_proba_multinomial(global_random_seed):\n     X, y = make_classification(\n-        n_samples=10, n_features=20, random_state=0, n_classes=3, n_informative=10\n+        n_samples=10,\n+        n_features=20,\n+        random_state=global_random_seed,\n+        n_classes=3,\n+        n_informative=10,\n     )\n \n     # Predicted probabilities using the true-entropy loss should give a\n     # smaller loss than those using the ovr method.\n-    clf_multi = LogisticRegression(solver=\"lbfgs\")\n+    clf_multi = LogisticRegression()\n     clf_multi.fit(X, y)\n     clf_multi_loss = log_loss(y, clf_multi.predict_proba(X))\n-    clf_ovr = OneVsRestClassifier(LogisticRegression(solver=\"lbfgs\"))\n+    clf_ovr = OneVsRestClassifier(LogisticRegression())\n     clf_ovr.fit(X, y)\n     clf_ovr_loss = log_loss(y, clf_ovr.predict_proba(X))\n     assert clf_ovr_loss > clf_multi_loss\n@@ -1324,21 +1356,21 @@ def test_logreg_predict_proba_multinomial():\n         (\"newton-cholesky\", \"Newton solver did not converge after [0-9]* iterations\"),\n     ],\n )\n-def test_max_iter(max_iter, multi_class, solver, message):\n+def test_max_iter(global_random_seed, max_iter, multi_class, solver, message):\n     # Test that the maximum number of iteration is reached\n     X, y_bin = iris.data, iris.target.copy()\n     y_bin[y_bin == 2] = 0\n \n     if solver in (\"liblinear\",) and multi_class == \"multinomial\":\n         pytest.skip(\"'multinomial' is not supported by liblinear\")\n+\n     if solver == \"newton-cholesky\" and max_iter > 1:\n         pytest.skip(\"solver newton-cholesky might converge very fast\")\n \n     lr = LogisticRegression(\n         max_iter=max_iter,\n         tol=1e-15,\n-        multi_class=multi_class,\n-        random_state=0,\n+        random_state=global_random_seed,\n         solver=solver,\n     )\n     with pytest.warns(ConvergenceWarning, match=message):\n@@ -1407,7 +1439,7 @@ def test_n_iter(solver):\n )\n @pytest.mark.parametrize(\"warm_start\", (True, False))\n @pytest.mark.parametrize(\"fit_intercept\", (True, False))\n-def test_warm_start(solver, warm_start, fit_intercept):\n+def test_warm_start(global_random_seed, solver, warm_start, fit_intercept):\n     # A 1-iteration second fit on same data should give almost same result\n     # with warm starting, and quite different result without warm starting.\n     # Warm starting does not work with liblinear solver.\n@@ -1417,7 +1449,7 @@ def test_warm_start(solver, warm_start, fit_intercept):\n         tol=1e-4,\n         warm_start=warm_start,\n         solver=solver,\n-        random_state=42,\n+        random_state=global_random_seed,\n         fit_intercept=fit_intercept,\n     )\n     with ignore_warnings(category=ConvergenceWarning):\n@@ -1438,7 +1470,7 @@ def test_warm_start(solver, warm_start, fit_intercept):\n \n \n @pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\n-def test_saga_vs_liblinear(csr_container):\n+def test_saga_vs_liblinear(global_random_seed, csr_container):\n     iris = load_iris()\n     X, y = iris.data, iris.target\n     X = np.concatenate([X] * 3)\n@@ -1448,7 +1480,7 @@ def test_saga_vs_liblinear(csr_container):\n     y_bin = y[y <= 1] * 2 - 1\n \n     X_sparse, y_sparse = make_classification(\n-        n_samples=50, n_features=20, random_state=0\n+        n_samples=50, n_features=20, random_state=global_random_seed\n     )\n     X_sparse = csr_container(X_sparse)\n \n@@ -1460,20 +1492,20 @@ def test_saga_vs_liblinear(csr_container):\n                 saga = LogisticRegression(\n                     C=1.0 / (n_samples * alpha),\n                     solver=\"saga\",\n-                    max_iter=200,\n+                    max_iter=500,\n                     fit_intercept=False,\n                     penalty=penalty,\n-                    random_state=0,\n+                    random_state=global_random_seed,\n                     tol=1e-6,\n                 )\n \n                 liblinear = LogisticRegression(\n                     C=1.0 / (n_samples * alpha),\n                     solver=\"liblinear\",\n-                    max_iter=200,\n+                    max_iter=500,\n                     fit_intercept=False,\n                     penalty=penalty,\n-                    random_state=0,\n+                    random_state=global_random_seed,\n                     tol=1e-6,\n                 )\n \n@@ -1510,7 +1542,6 @@ def test_dtype_match(solver, multi_class, fit_intercept, csr_container):\n \n     lr_templ = LogisticRegression(\n         solver=solver,\n-        multi_class=multi_class,\n         random_state=42,\n         tol=solver_tol,\n         fit_intercept=fit_intercept,\n@@ -1563,15 +1594,19 @@ def test_dtype_match(solver, multi_class, fit_intercept, csr_container):\n     assert_allclose(lr_64.coef_, lr_64_sparse.coef_, atol=atol)\n \n \n-def test_warm_start_converge_LR():\n+def test_warm_start_converge_LR(global_random_seed):\n     # Test to see that the logistic regression converges on warm start,\n     # with multi_class='multinomial'. Non-regressive test for #10836\n \n-    rng = np.random.RandomState(0)\n+    rng = np.random.RandomState(global_random_seed)\n     X = np.concatenate((rng.randn(100, 2) + [1, 1], rng.randn(100, 2)))\n     y = np.array([1] * 100 + [-1] * 100)\n-    lr_no_ws = LogisticRegression(solver=\"sag\", warm_start=False, random_state=0)\n-    lr_ws = LogisticRegression(solver=\"sag\", warm_start=True, random_state=0)\n+    lr_no_ws = LogisticRegression(\n+        solver=\"sag\", warm_start=False, tol=1e-6, random_state=global_random_seed\n+    )\n+    lr_ws = LogisticRegression(\n+        solver=\"sag\", warm_start=True, tol=1e-6, random_state=global_random_seed\n+    )\n \n     lr_no_ws_loss = log_loss(y, lr_no_ws.fit(X, y).predict_proba(X))\n     for i in range(5):\n@@ -1580,10 +1615,10 @@ def test_warm_start_converge_LR():\n     assert_allclose(lr_no_ws_loss, lr_ws_loss, rtol=1e-5)\n \n \n-def test_elastic_net_coeffs():\n+def test_elastic_net_coeffs(global_random_seed):\n     # make sure elasticnet penalty gives different coefficients from l1 and l2\n     # with saga solver (l1_ratio different from 0 or 1)\n-    X, y = make_classification(random_state=0)\n+    X, y = make_classification(random_state=global_random_seed)\n \n     C = 2.0\n     l1_ratio = 0.5\n@@ -1593,38 +1628,39 @@ def test_elastic_net_coeffs():\n             penalty=penalty,\n             C=C,\n             solver=\"saga\",\n-            random_state=0,\n+            random_state=global_random_seed,\n             l1_ratio=ratio,\n             tol=1e-3,\n-            max_iter=200,\n+            max_iter=500,\n         )\n         lr.fit(X, y)\n         coeffs.append(lr.coef_)\n \n     elastic_net_coeffs, l1_coeffs, l2_coeffs = coeffs\n+\n     # make sure coeffs differ by at least .1\n-    assert not np.allclose(elastic_net_coeffs, l1_coeffs, rtol=0, atol=0.1)\n-    assert not np.allclose(elastic_net_coeffs, l2_coeffs, rtol=0, atol=0.1)\n-    assert not np.allclose(l2_coeffs, l1_coeffs, rtol=0, atol=0.1)\n+    assert not np.allclose(elastic_net_coeffs, l1_coeffs, rtol=0, atol=1e-3)\n+    assert not np.allclose(elastic_net_coeffs, l2_coeffs, rtol=0, atol=1e-3)\n+    assert not np.allclose(l2_coeffs, l1_coeffs, rtol=0, atol=1e-3)\n \n \n @pytest.mark.parametrize(\"C\", [0.001, 0.1, 1, 10, 100, 1000, 1e6])\n @pytest.mark.parametrize(\"penalty, l1_ratio\", [(\"l1\", 1), (\"l2\", 0)])\n-def test_elastic_net_l1_l2_equivalence(C, penalty, l1_ratio):\n+def test_elastic_net_l1_l2_equivalence(global_random_seed, C, penalty, l1_ratio):\n     # Make sure elasticnet is equivalent to l1 when l1_ratio=1 and to l2 when\n     # l1_ratio=0.\n-    X, y = make_classification(random_state=0)\n+    X, y = make_classification(random_state=global_random_seed)\n \n     lr_enet = LogisticRegression(\n         penalty=\"elasticnet\",\n         C=C,\n         l1_ratio=l1_ratio,\n         solver=\"saga\",\n-        random_state=0,\n+        random_state=global_random_seed,\n         tol=1e-2,\n     )\n     lr_expected = LogisticRegression(\n-        penalty=penalty, C=C, solver=\"saga\", random_state=0, tol=1e-2\n+        penalty=penalty, C=C, solver=\"saga\", random_state=global_random_seed, tol=1e-2\n     )\n     lr_enet.fit(X, y)\n     lr_expected.fit(X, y)\n@@ -1632,6 +1668,7 @@ def test_elastic_net_l1_l2_equivalence(C, penalty, l1_ratio):\n     assert_array_almost_equal(lr_enet.coef_, lr_expected.coef_)\n \n \n+# FIXME: Random state is fixed in order to make the test pass\n @pytest.mark.parametrize(\"C\", [0.001, 1, 100, 1e6])\n def test_elastic_net_vs_l1_l2(C):\n     # Make sure that elasticnet with grid search on l1_ratio gives same or\n@@ -1643,7 +1680,11 @@ def test_elastic_net_vs_l1_l2(C):\n     param_grid = {\"l1_ratio\": np.linspace(0, 1, 5)}\n \n     enet_clf = LogisticRegression(\n-        penalty=\"elasticnet\", C=C, solver=\"saga\", random_state=0, tol=1e-2\n+        penalty=\"elasticnet\",\n+        C=C,\n+        solver=\"saga\",\n+        random_state=0,\n+        tol=1e-2,\n     )\n     gs = GridSearchCV(enet_clf, param_grid, refit=True)\n \n@@ -1661,6 +1702,7 @@ def test_elastic_net_vs_l1_l2(C):\n     assert gs.score(X_test, y_test) >= l2_clf.score(X_test, y_test)\n \n \n+##FIXME: Random state is fixed in order to make the test pass\n @pytest.mark.parametrize(\"C\", np.logspace(-3, 2, 4))\n @pytest.mark.parametrize(\"l1_ratio\", [0.1, 0.5, 0.9])\n def test_LogisticRegression_elastic_net_objective(C, l1_ratio):\n@@ -1704,13 +1746,17 @@ def enet_objective(lr):\n     assert enet_objective(lr_enet) < enet_objective(lr_l2)\n \n \n+# FIXME: Random state is fixed in order to make the test pass\n @pytest.mark.parametrize(\"n_classes\", (2, 3))\n def test_LogisticRegressionCV_GridSearchCV_elastic_net(n_classes):\n     # make sure LogisticRegressionCV gives same best params (l1 and C) as\n     # GridSearchCV when penalty is elasticnet\n \n     X, y = make_classification(\n-        n_samples=100, n_classes=n_classes, n_informative=3, random_state=0\n+        n_samples=100,\n+        n_classes=n_classes,\n+        n_informative=3,\n+        random_state=0,\n     )\n \n     cv = StratifiedKFold(5)\n@@ -1888,7 +1934,7 @@ def test_l1_ratio_non_elasticnet():\n \n @pytest.mark.parametrize(\"C\", np.logspace(-3, 2, 4))\n @pytest.mark.parametrize(\"l1_ratio\", [0.1, 0.5, 0.9])\n-def test_elastic_net_versus_sgd(C, l1_ratio):\n+def test_elastic_net_versus_sgd(global_random_seed, C, l1_ratio):\n     # Compare elasticnet penalty in LogisticRegression() and SGD(loss='log')\n     n_samples = 500\n     X, y = make_classification(\n@@ -1898,13 +1944,13 @@ def test_elastic_net_versus_sgd(C, l1_ratio):\n         n_informative=5,\n         n_redundant=0,\n         n_repeated=0,\n-        random_state=1,\n+        random_state=global_random_seed,\n     )\n     X = scale(X)\n \n     sgd = SGDClassifier(\n         penalty=\"elasticnet\",\n-        random_state=1,\n+        random_state=global_random_seed,\n         fit_intercept=False,\n         tol=None,\n         max_iter=2000,\n@@ -1914,7 +1960,7 @@ def test_elastic_net_versus_sgd(C, l1_ratio):\n     )\n     log = LogisticRegression(\n         penalty=\"elasticnet\",\n-        random_state=1,\n+        random_state=global_random_seed,\n         fit_intercept=False,\n         tol=1e-5,\n         max_iter=1000,\n@@ -1925,7 +1971,8 @@ def test_elastic_net_versus_sgd(C, l1_ratio):\n \n     sgd.fit(X, y)\n     log.fit(X, y)\n-    assert_array_almost_equal(sgd.coef_, log.coef_, decimal=1)\n+\n+    assert_allclose(sgd.coef_, log.coef_, atol=0.35)\n \n \n def test_logistic_regression_path_coefs_multinomial():\n@@ -2017,21 +2064,29 @@ def fit(X, y, **kw):\n \n \n @pytest.mark.parametrize(\"solver\", sorted(set(SOLVERS) - set([\"liblinear\"])))\n-def test_penalty_none(solver):\n+def test_penalty_none(global_random_seed, solver):\n     # - Make sure warning is raised if penalty=None and C is set to a\n     #   non-default value.\n     # - Make sure setting penalty=None is equivalent to setting C=np.inf with\n     #   l2 penalty.\n-    X, y = make_classification(n_samples=1000, n_redundant=0, random_state=0)\n+    X, y = make_classification(\n+        n_samples=1000, n_redundant=0, random_state=global_random_seed\n+    )\n \n     msg = \"Setting penalty=None will ignore the C\"\n     lr = LogisticRegression(penalty=None, solver=solver, C=4)\n     with pytest.warns(UserWarning, match=msg):\n         lr.fit(X, y)\n \n-    lr_none = LogisticRegression(penalty=None, solver=solver, random_state=0)\n+    lr_none = LogisticRegression(\n+        penalty=None, solver=solver, max_iter=300, random_state=global_random_seed\n+    )\n     lr_l2_C_inf = LogisticRegression(\n-        penalty=\"l2\", C=np.inf, solver=solver, random_state=0\n+        penalty=\"l2\",\n+        C=np.inf,\n+        solver=solver,\n+        max_iter=300,\n+        random_state=global_random_seed,\n     )\n     pred_none = lr_none.fit(X, y).predict(X)\n     pred_l2_C_inf = lr_l2_C_inf.fit(X, y).predict(X)\n@@ -2046,7 +2101,7 @@ def test_penalty_none(solver):\n         {\"penalty\": \"l2\", \"dual\": False, \"tol\": 1e-12, \"max_iter\": 1000},\n     ],\n )\n-def test_logisticregression_liblinear_sample_weight(params):\n+def test_logisticregression_liblinear_sample_weight(global_random_seed, params):\n     # check that we support sample_weight with liblinear in all possible cases:\n     # l1-primal, l2-primal, l2-dual\n     X = np.array(\n@@ -2078,9 +2133,11 @@ def test_logisticregression_liblinear_sample_weight(params):\n     y2 = np.hstack([y, 3 - y])\n     sample_weight = np.ones(shape=len(y) * 2)\n     sample_weight[len(y) :] = 0\n-    X2, y2, sample_weight = shuffle(X2, y2, sample_weight, random_state=0)\n+    X2, y2, sample_weight = shuffle(\n+        X2, y2, sample_weight, random_state=global_random_seed\n+    )\n \n-    base_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\n+    base_clf = LogisticRegression(solver=\"liblinear\", random_state=global_random_seed)\n     base_clf.set_params(**params)\n     clf_no_weight = clone(base_clf).fit(X, y)\n     clf_with_weight = clone(base_clf).fit(X2, y2, sample_weight=sample_weight)\n@@ -2138,7 +2195,7 @@ def test_scores_attribute_layout_elasticnet():\n @pytest.mark.filterwarnings(\"ignore:.*'multi_class' was deprecated.*:FutureWarning\")\n @pytest.mark.parametrize(\"solver\", [\"lbfgs\", \"newton-cg\", \"newton-cholesky\"])\n @pytest.mark.parametrize(\"fit_intercept\", [False, True])\n-def test_multinomial_identifiability_on_iris(solver, fit_intercept):\n+def test_multinomial_identifiability_on_iris(global_random_seed, solver, fit_intercept):\n     \"\"\"Test that the multinomial classification is identifiable.\n \n     A multinomial with c classes can be modeled with\n@@ -2168,6 +2225,7 @@ def test_multinomial_identifiability_on_iris(solver, fit_intercept):\n         C=len(iris.data),\n         solver=\"lbfgs\",\n         fit_intercept=fit_intercept,\n+        random_state=global_random_seed,\n     )\n     # Scaling X to ease convergence.\n     X_scaled = scale(iris.data)\n@@ -2183,7 +2241,7 @@ def test_multinomial_identifiability_on_iris(solver, fit_intercept):\n @pytest.mark.filterwarnings(\"ignore:.*'multi_class' was deprecated.*:FutureWarning\")\n @pytest.mark.parametrize(\"multi_class\", [\"ovr\", \"multinomial\", \"auto\"])\n @pytest.mark.parametrize(\"class_weight\", [{0: 1.0, 1: 10.0, 2: 1.0}, \"balanced\"])\n-def test_sample_weight_not_modified(multi_class, class_weight):\n+def test_sample_weight_not_modified(global_random_seed, multi_class, class_weight):\n     X, y = load_iris(return_X_y=True)\n     n_features = len(X)\n     W = np.ones(n_features)\n@@ -2192,7 +2250,10 @@ def test_sample_weight_not_modified(multi_class, class_weight):\n     expected = W.copy()\n \n     clf = LogisticRegression(\n-        random_state=0, class_weight=class_weight, max_iter=200, multi_class=multi_class\n+        random_state=global_random_seed,\n+        class_weight=class_weight,\n+        max_iter=200,\n+        multi_class=multi_class,\n     )\n     clf.fit(X, y, sample_weight=W)\n     assert_allclose(expected, W)\n@@ -2229,7 +2290,7 @@ def test_single_feature_newton_cg():\n     LogisticRegression(solver=\"newton-cg\", fit_intercept=True).fit(X, y)\n \n \n-def test_liblinear_not_stuck():\n+def test_liblinear_not_stuck(global_random_seed):\n     # Non-regression https://github.com/scikit-learn/scikit-learn/issues/18264\n     X = iris.data.copy()\n     y = iris.target.copy()\n@@ -2244,7 +2305,7 @@ def test_liblinear_not_stuck():\n         tol=1e-6,\n         max_iter=100,\n         intercept_scaling=10000.0,\n-        random_state=0,\n+        random_state=global_random_seed,\n         C=C,\n     )\n \n@@ -2255,26 +2316,26 @@ def test_liblinear_not_stuck():\n \n \n @config_context(enable_metadata_routing=True)\n-def test_lr_cv_scores_differ_when_sample_weight_is_requested():\n+def test_lr_cv_scores_differ_when_sample_weight_is_requested(global_random_seed):\n     \"\"\"Test that `sample_weight` is correctly passed to the scorer in\n     `LogisticRegressionCV.fit` and `LogisticRegressionCV.score` by\n     checking the difference in scores with the case when `sample_weight`\n     is not requested.\n     \"\"\"\n-    rng = np.random.RandomState(10)\n-    X, y = make_classification(n_samples=10, random_state=rng)\n-    X_t, y_t = make_classification(n_samples=10, random_state=rng)\n+    rng = np.random.RandomState(global_random_seed)\n+    X, y = make_classification(n_samples=2000, random_state=rng)\n+    X_t, y_t = make_classification(n_samples=2000, random_state=rng)\n     sample_weight = np.ones(len(y))\n     sample_weight[: len(y) // 2] = 2\n     kwargs = {\"sample_weight\": sample_weight}\n \n     scorer1 = get_scorer(\"accuracy\")\n-    lr_cv1 = LogisticRegressionCV(scoring=scorer1)\n+    lr_cv1 = LogisticRegressionCV(scoring=scorer1, tol=3e-6)\n     lr_cv1.fit(X, y, **kwargs)\n \n     scorer2 = get_scorer(\"accuracy\")\n     scorer2.set_score_request(sample_weight=True)\n-    lr_cv2 = LogisticRegressionCV(scoring=scorer2)\n+    lr_cv2 = LogisticRegressionCV(scoring=scorer2, tol=3e-6)\n     lr_cv2.fit(X, y, **kwargs)\n \n     assert not np.allclose(lr_cv1.scores_[1], lr_cv2.scores_[1])\n",
  "fail_to_pass": [
    "test_predict_iris",
    "test_consistency_path",
    "test_liblinear_dual_random_state",
    "test_logistic_cv",
    "test_logistic_cv_multinomial_score",
    "test_logistic_cv_sparse",
    "test_logistic_regression_solvers",
    "test_logistic_regression_class_weights",
    "test_logistic_regression_multinomial",
    "test_liblinear_decision_function_zero",
    "test_liblinear_logregcv_sparse",
    "test_saga_sparse",
    "test_logreg_l1",
    "test_logreg_l1_sparse_data",
    "test_logistic_regression_cv_refit",
    "test_logreg_predict_proba_multinomial",
    "test_max_iter",
    "test_warm_start",
    "test_saga_vs_liblinear",
    "test_warm_start_converge_LR",
    "test_elastic_net_coeffs",
    "test_elastic_net_l1_l2_equivalence",
    "test_elastic_net_versus_sgd",
    "test_penalty_none",
    "test_logisticregression_liblinear_sample_weight",
    "test_multinomial_identifiability_on_iris",
    "test_sample_weight_not_modified",
    "test_liblinear_not_stuck",
    "test_lr_cv_scores_differ_when_sample_weight_is_requested"
  ],
  "pass_to_pass": [],
  "relevant_files": [
    "sklearn/linear_model/tests/test_logistic.py"
  ],
  "difficulty": "hard",
  "created_at": "2025-05-13T14:02:32Z",
  "pr_url": "https://github.com/scikit-learn/scikit-learn/pull/31362",
  "issue_url": "https://github.com/scikit-learn/scikit-learn/pull/1234"
}