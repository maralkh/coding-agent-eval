{
  "id": "scikit-learn__scikit-learn-32310",
  "repo": "scikit-learn/scikit-learn",
  "base_commit": "4ba9a8a3b20e2b1ad94e15a7f10bd3b2ef66517a",
  "issue_number": 30508,
  "issue_title": "ENH add `from_cv_results` in `PrecisionRecallDisplay` (single Display)",
  "issue_body": "#### Reference Issues/PRs\r\nFollows on from  #30399\r\n\r\n#### What does this implement/fix? Explain your changes.\r\nProof of concept of adding multi displays to `PrecisionRecallDisplay`\r\n\r\n* A lot of the code is similar to that in #30399, so we can definitely factorize out, though small intricacies may make it complex \r\n* The `plot` method is complex due to handling both single and multi curve and doing a lot more checking, as user is able to use it outside of the `from_estimator` and `from_predictions` methods.\r\n\r\nDetailed discussions of problems in review comments.\r\n\r\n#### Any other comments?\r\n\r\ncc @glemaitre @jeremiedbb \r\n\r\n",
  "pr_number": 32310,
  "pr_title": "MNT Deprecate `estimator_name` in favour of `name` in `PrecisionRecallDisplay`",
  "gold_patch": "diff --git a/doc/whats_new/upcoming_changes/sklearn.metrics/32310.api.rst b/doc/whats_new/upcoming_changes/sklearn.metrics/32310.api.rst\nnew file mode 100644\nindex 0000000000000..ae7fc385b3bcc\n--- /dev/null\n+++ b/doc/whats_new/upcoming_changes/sklearn.metrics/32310.api.rst\n@@ -0,0 +1,3 @@\n+- The `estimator_name` parameter is deprecated in favour of `name` in\n+  :class:`metrics.PrecisionRecallDisplay` and will be removed in 1.10.\n+  By :user:`Lucy Liu <lucyleeow>`.\ndiff --git a/sklearn/metrics/_plot/precision_recall_curve.py b/sklearn/metrics/_plot/precision_recall_curve.py\nindex 3e64fd776ae16..43d24cac4d530 100644\n--- a/sklearn/metrics/_plot/precision_recall_curve.py\n+++ b/sklearn/metrics/_plot/precision_recall_curve.py\n@@ -6,6 +6,7 @@\n from sklearn.metrics._ranking import average_precision_score, precision_recall_curve\n from sklearn.utils._plotting import (\n     _BinaryClassifierCurveDisplayMixin,\n+    _deprecate_estimator_name,\n     _deprecate_y_pred_parameter,\n     _despine,\n     _validate_style_kwargs,\n@@ -37,9 +38,12 @@ class PrecisionRecallDisplay(_BinaryClassifierCurveDisplayMixin):\n     average_precision : float, default=None\n         Average precision. If None, the average precision is not shown.\n \n-    estimator_name : str, default=None\n+    name : str, default=None\n         Name of estimator. If None, then the estimator name is not shown.\n \n+        .. versionchanged:: 1.8\n+            `estimator_name` was deprecated in favor of `name`.\n+\n     pos_label : int, float, bool or str, default=None\n         The class considered the positive class when precision and recall metrics\n         computed. If not `None`, this value is displayed in the x- and y-axes labels.\n@@ -53,6 +57,13 @@ class PrecisionRecallDisplay(_BinaryClassifierCurveDisplayMixin):\n \n         .. versionadded:: 1.3\n \n+    estimator_name : str, default=None\n+        Name of estimator. If None, the estimator name is not shown.\n+\n+        .. deprecated:: 1.8\n+            `estimator_name` is deprecated and will be removed in 1.10. Use `name`\n+            instead.\n+\n     Attributes\n     ----------\n     line_ : matplotlib Artist\n@@ -118,11 +129,12 @@ def __init__(\n         recall,\n         *,\n         average_precision=None,\n-        estimator_name=None,\n+        name=None,\n         pos_label=None,\n         prevalence_pos_label=None,\n+        estimator_name=\"deprecated\",\n     ):\n-        self.estimator_name = estimator_name\n+        self.name = _deprecate_estimator_name(estimator_name, name, \"1.8\")\n         self.precision = precision\n         self.recall = recall\n         self.average_precision = average_precision\n@@ -151,7 +163,7 @@ def plot(\n \n         name : str, default=None\n             Name of precision recall curve for labeling. If `None`, use\n-            `estimator_name` if not `None`, otherwise no labeling is shown.\n+            `name` if not `None`, otherwise no labeling is shown.\n \n         plot_chance_level : bool, default=False\n             Whether to plot the chance level. The chance level is the prevalence\n@@ -555,7 +567,7 @@ def from_predictions(\n             precision=precision,\n             recall=recall,\n             average_precision=average_precision,\n-            estimator_name=name,\n+            name=name,\n             pos_label=pos_label,\n             prevalence_pos_label=prevalence_pos_label,\n         )\ndiff --git a/sklearn/metrics/_plot/tests/test_common_curve_display.py b/sklearn/metrics/_plot/tests/test_common_curve_display.py\nindex 753f2a1e7319d..675cb26e17fba 100644\n--- a/sklearn/metrics/_plot/tests/test_common_curve_display.py\n+++ b/sklearn/metrics/_plot/tests/test_common_curve_display.py\n@@ -132,7 +132,9 @@ def fit(self, X, y):\n         Display.from_estimator(clf, X, y, response_method=response_method)\n \n \n-@pytest.mark.parametrize(\"Display\", [DetCurveDisplay, PrecisionRecallDisplay])\n+@pytest.mark.parametrize(\n+    \"Display\", [DetCurveDisplay, PrecisionRecallDisplay, RocCurveDisplay]\n+)\n @pytest.mark.parametrize(\"constructor_name\", [\"from_estimator\", \"from_predictions\"])\n def test_display_curve_estimator_name_multiple_calls(\n     pyplot,\n@@ -154,7 +156,11 @@ def test_display_curve_estimator_name_multiple_calls(\n         disp = Display.from_estimator(clf, X, y, name=clf_name)\n     else:\n         disp = Display.from_predictions(y, y_pred, name=clf_name)\n-    assert disp.estimator_name == clf_name\n+    # TODO: Clean-up once `estimator_name` deprecated in all displays\n+    if Display in (PrecisionRecallDisplay, RocCurveDisplay):\n+        assert disp.name == clf_name\n+    else:\n+        assert disp.estimator_name == clf_name\n     pyplot.close(\"all\")\n     disp.plot()\n     assert clf_name in disp.line_.get_label()\n@@ -164,8 +170,6 @@ def test_display_curve_estimator_name_multiple_calls(\n     assert clf_name in disp.line_.get_label()\n \n \n-# TODO: remove this test once classes moved to using `name` instead of\n-# `estimator_name`\n @pytest.mark.parametrize(\n     \"clf\",\n     [\n@@ -176,7 +180,9 @@ def test_display_curve_estimator_name_multiple_calls(\n         ),\n     ],\n )\n-@pytest.mark.parametrize(\"Display\", [DetCurveDisplay, PrecisionRecallDisplay])\n+@pytest.mark.parametrize(\n+    \"Display\", [DetCurveDisplay, PrecisionRecallDisplay, RocCurveDisplay]\n+)\n def test_display_curve_not_fitted_errors_old_name(pyplot, data_binary, clf, Display):\n     \"\"\"Check that a proper error is raised when the classifier is not\n     fitted.\"\"\"\n@@ -189,7 +195,11 @@ def test_display_curve_not_fitted_errors_old_name(pyplot, data_binary, clf, Disp\n     model.fit(X, y)\n     disp = Display.from_estimator(model, X, y)\n     assert model.__class__.__name__ in disp.line_.get_label()\n-    assert disp.estimator_name == model.__class__.__name__\n+    # TODO: Clean-up once `estimator_name` deprecated in all displays\n+    if Display in (PrecisionRecallDisplay, RocCurveDisplay):\n+        assert disp.name == model.__class__.__name__\n+    else:\n+        assert disp.estimator_name == model.__class__.__name__\n \n \n @pytest.mark.parametrize(\n@@ -290,3 +300,22 @@ class SubclassOfDisplay(Display):\n         curve = SubclassOfDisplay.from_estimator(classifier, X, y)\n \n     assert isinstance(curve, SubclassOfDisplay)\n+\n+\n+# TODO(1.10): Remove once deprecated in all Displays\n+@pytest.mark.parametrize(\n+    \"Display, display_kwargs\",\n+    [\n+        # TODO(1.10): Remove\n+        (\n+            PrecisionRecallDisplay,\n+            {\"precision\": np.array([1, 0.5, 0]), \"recall\": np.array([0, 0.5, 1])},\n+        ),\n+        # TODO(1.9): Remove\n+        (RocCurveDisplay, {\"fpr\": np.array([0, 0.5, 1]), \"tpr\": np.array([0, 0.5, 1])}),\n+    ],\n+)\n+def test_display_estimator_name_deprecation(pyplot, Display, display_kwargs):\n+    \"\"\"Check deprecation of `estimator_name`.\"\"\"\n+    with pytest.warns(FutureWarning, match=\"`estimator_name` is deprecated in\"):\n+        Display(**display_kwargs, estimator_name=\"test\")\ndiff --git a/sklearn/metrics/_plot/tests/test_precision_recall_display.py b/sklearn/metrics/_plot/tests/test_precision_recall_display.py\nindex 2a25ecd1d737f..c89e80b88ca4c 100644\n--- a/sklearn/metrics/_plot/tests/test_precision_recall_display.py\n+++ b/sklearn/metrics/_plot/tests/test_precision_recall_display.py\n@@ -180,7 +180,7 @@ def test_precision_recall_display_pipeline(pyplot, clf):\n         PrecisionRecallDisplay.from_estimator(clf, X, y)\n     clf.fit(X, y)\n     display = PrecisionRecallDisplay.from_estimator(clf, X, y)\n-    assert display.estimator_name == clf.__class__.__name__\n+    assert display.name == clf.__class__.__name__\n \n \n def test_precision_recall_display_string_labels(pyplot):\n@@ -198,7 +198,7 @@ def test_precision_recall_display_string_labels(pyplot):\n     avg_prec = average_precision_score(y, y_score, pos_label=lr.classes_[1])\n \n     assert display.average_precision == pytest.approx(avg_prec)\n-    assert display.estimator_name == lr.__class__.__name__\n+    assert display.name == lr.__class__.__name__\n \n     err_msg = r\"y_true takes value in {'benign', 'malignant'}\"\n     with pytest.raises(ValueError, match=err_msg):\n@@ -211,14 +211,14 @@ def test_precision_recall_display_string_labels(pyplot):\n \n \n @pytest.mark.parametrize(\n-    \"average_precision, estimator_name, expected_label\",\n+    \"average_precision, name, expected_label\",\n     [\n         (0.9, None, \"AP = 0.90\"),\n         (None, \"my_est\", \"my_est\"),\n         (0.8, \"my_est2\", \"my_est2 (AP = 0.80)\"),\n     ],\n )\n-def test_default_labels(pyplot, average_precision, estimator_name, expected_label):\n+def test_default_labels(pyplot, average_precision, name, expected_label):\n     \"\"\"Check the default labels used in the display.\"\"\"\n     precision = np.array([1, 0.5, 0])\n     recall = np.array([0, 0.5, 1])\n@@ -226,7 +226,7 @@ def test_default_labels(pyplot, average_precision, estimator_name, expected_labe\n         precision,\n         recall,\n         average_precision=average_precision,\n-        estimator_name=estimator_name,\n+        name=name,\n     )\n     display.plot()\n     assert display.line_.get_label() == expected_label\ndiff --git a/sklearn/metrics/_plot/tests/test_roc_curve_display.py b/sklearn/metrics/_plot/tests/test_roc_curve_display.py\nindex 33461456d8e84..22ed1eb4cd557 100644\n--- a/sklearn/metrics/_plot/tests/test_roc_curve_display.py\n+++ b/sklearn/metrics/_plot/tests/test_roc_curve_display.py\n@@ -322,15 +322,6 @@ def test_roc_curve_display_from_cv_results_curve_kwargs(\n         )\n \n \n-# TODO(1.9): Remove in 1.9\n-def test_roc_curve_display_estimator_name_deprecation(pyplot):\n-    \"\"\"Check deprecation of `estimator_name`.\"\"\"\n-    fpr = np.array([0, 0.5, 1])\n-    tpr = np.array([0, 0.5, 1])\n-    with pytest.warns(FutureWarning, match=\"`estimator_name` is deprecated in\"):\n-        RocCurveDisplay(fpr=fpr, tpr=tpr, estimator_name=\"test\")\n-\n-\n # TODO(1.9): Remove in 1.9\n @pytest.mark.parametrize(\n     \"constructor_name\", [\"from_estimator\", \"from_predictions\", \"plot\"]\n",
  "fail_to_pass": [
    "test_display_estimator_name_deprecation",
    "test_default_labels"
  ],
  "pass_to_pass": [],
  "relevant_files": [
    "sklearn/metrics/_plot/precision_recall_curve.py",
    "sklearn/metrics/_plot/tests/test_common_curve_display.py",
    "sklearn/metrics/_plot/tests/test_precision_recall_display.py",
    "sklearn/metrics/_plot/tests/test_roc_curve_display.py"
  ],
  "difficulty": "hard",
  "created_at": "2025-10-01T13:24:49Z",
  "pr_url": "https://github.com/scikit-learn/scikit-learn/pull/32310",
  "issue_url": "https://github.com/scikit-learn/scikit-learn/pull/30508"
}