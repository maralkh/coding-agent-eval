{
  "id": "scikit-learn__scikit-learn-32351",
  "repo": "scikit-learn/scikit-learn",
  "base_commit": "b1b01a1611e1f5af939e12e070e8bfad17ce25b2",
  "issue_number": 1234,
  "issue_title": "MRG fix bincount mess I made in kmeans.",
  "issue_body": "This should clean up the stuff I pushed earlier.\ncc @ogrisel @gaelvaroquaux Could you have a brief look? What I pushed earlier is buggy but I didn't dare push again after so many failed fixes.\n",
  "pr_number": 32351,
  "pr_title": "FIX Fix `DecisionTree*` partitioning with missing values present",
  "gold_patch": "diff --git a/doc/whats_new/upcoming_changes/sklearn.tree/32351.fix.rst b/doc/whats_new/upcoming_changes/sklearn.tree/32351.fix.rst\nnew file mode 100644\nindex 0000000000000..0c422d7a9e14c\n--- /dev/null\n+++ b/doc/whats_new/upcoming_changes/sklearn.tree/32351.fix.rst\n@@ -0,0 +1,3 @@\n+- Fix decision tree splitting with missing values present in some features. In some cases the last\n+  non-missing sample would not be partitioned correctly.\n+  By :user:`Tim Head <betatim>` and :user:`Arthur Lacote <cakedev0>`.\ndiff --git a/sklearn/tree/_partitioner.pyx b/sklearn/tree/_partitioner.pyx\nindex 5cec6073d74f1..c8990dd717eb0 100644\n--- a/sklearn/tree/_partitioner.pyx\n+++ b/sklearn/tree/_partitioner.pyx\n@@ -235,7 +235,7 @@ cdef class DensePartitioner:\n         if best_n_missing != 0:\n             # Move samples with missing values to the end while partitioning the\n             # non-missing samples\n-            while p < partition_end:\n+            while p <= partition_end:\n                 # Keep samples with missing values at the end\n                 if isnan(X[samples[end], best_feature]):\n                     end -= 1\ndiff --git a/sklearn/tree/tests/test_tree.py b/sklearn/tree/tests/test_tree.py\nindex 3fac73abba546..4350a3a33f862 100644\n--- a/sklearn/tree/tests/test_tree.py\n+++ b/sklearn/tree/tests/test_tree.py\n@@ -2893,3 +2893,23 @@ def test_sort_log2_build():\n     ]\n     # fmt: on\n     assert_array_equal(samples, expected_samples)\n+\n+\n+def test_splitting_with_missing_values():\n+    # Non regression test for https://github.com/scikit-learn/scikit-learn/issues/32178\n+    X = (\n+        np.vstack([[0, 0, 0, 0, 1, 2, 3, 4], [1, 2, 1, 2, 1, 2, 1, 2]])\n+        .swapaxes(0, 1)\n+        .astype(float)\n+    )\n+    y = [0, 0, 0, 0, 1, 1, 1, 1]\n+    X[X == 0] = np.nan\n+\n+    # The important thing here is that we try several trees, where each one tries\n+    # one of the two features first. The resulting tree should be the same in all\n+    # cases. The way to control which feature is tried first is `random_state`.\n+    # Twenty trees is a good guess for how many we need to try to make sure we get\n+    # both orders of features at least once.\n+    for i in range(20):\n+        tree = DecisionTreeRegressor(max_depth=1, random_state=i).fit(X, y)\n+        assert_array_equal(tree.tree_.impurity, np.array([0.25, 0.0, 0.0]))\n",
  "fail_to_pass": [
    "test_splitting_with_missing_values"
  ],
  "pass_to_pass": [],
  "relevant_files": [
    "sklearn/tree/tests/test_tree.py"
  ],
  "difficulty": "medium",
  "created_at": "2025-10-03T07:53:50Z",
  "pr_url": "https://github.com/scikit-learn/scikit-learn/pull/32351",
  "issue_url": "https://github.com/scikit-learn/scikit-learn/pull/1234"
}