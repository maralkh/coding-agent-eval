{
  "id": "scikit-learn__scikit-learn-32760",
  "repo": "scikit-learn/scikit-learn",
  "base_commit": "ff9da6428aafc802b6d3afe8df6b5cb75b2d39b0",
  "issue_number": 32725,
  "issue_title": "Random-seed-dependent test failures in `macOS pylatest_conda_forge_arm` job",
  "issue_body": "> [!WARNING]\n> This is not a good first issue to contribute. Great if you are interested to contribute to scikit-learn \ud83d\ude4f. Please have a look at our [contributing doc](https://scikit-learn.org/dev/developers/contributing.html) and in particular the section [Issues for new contributors](https://scikit-learn.org/dev/developers/contributing.html#new-contributors). \n\nWhile using the `[all random seeds]` commit-message marker in #32582, I noticed that some tests can fail under certain seeds. The failures appear in the `macOS pylatest_conda_forge_arm` job.\n\nThe CI failure can be found here: https://github.com/scikit-learn/scikit-learn/actions/runs/19417674441/job/55549227614?pr=32582\n\nIn particular, the following tests are affected:\n\n<details>\n<summary>\n<code>affected_test[random_seed]</code>\n</summary>\n\n```bash\ncovariance/tests/test_graphical_lasso.py::test_graphical_lassos[95]\ncovariance/tests/test_robust_covariance.py::test_mcd\ncovariance/tests/test_robust_covariance.py::test_mincovdet_bias_on_normal[42-2000-10]\ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[6]\ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[14]\ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[19]\ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[23]\ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[30]\ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[32]\ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[37]\ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[47]\ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[50]\ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[55]\ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[61]\ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[64]\ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[67]\ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[72]\ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[79]\ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[80]\ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[88] \ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[93]\ntree/tests/test_tree.py::test_absolute_errors_precomputation_function[94]\n```\n</details>\n\nThis can be reproduced by:\n\n1. Using the `[all random seeds]` commit-message marker (see [here](https://scikit-learn.org/stable/developers/contributing.html#commit-message-markers)), or\n2. Setting the environment variable on macOS (see [here](https://scikit-learn.org/stable/computing/parallelism.html#sklearn-tests-global-random-seed)):\n\n```bash\n$ export SKLEARN_TESTS_GLOBAL_RANDOM_SEED=\"all\"\n```\n\nAt first glance, the failures come from `assert_allclose`, so tweaking the `rtol` or `atol` in those tests should address the issue. This will need to be verified by pushing a commit with the `[all random seeds]` marker and letting the CI run to completion, which usually takes about two hours.\n\nEdit: add more failed tests",
  "pr_number": 32760,
  "pr_title": "TST: fix `test_mincovdet_bias_on_normal` flakyness by using random seed",
  "gold_patch": "diff --git a/sklearn/covariance/tests/test_robust_covariance.py b/sklearn/covariance/tests/test_robust_covariance.py\nindex 4a7590ef2c18c..25fe4e0af2c35 100644\n--- a/sklearn/covariance/tests/test_robust_covariance.py\n+++ b/sklearn/covariance/tests/test_robust_covariance.py\n@@ -182,11 +182,17 @@ def test_mincovdet_bias_on_normal(n_samples, n_features, global_random_seed):\n     https://github.com/scikit-learn/scikit-learn/issues/23162\n     \"\"\"\n     threshold = 0.985  # threshold for variance underesitmation\n-    x = np.random.randn(n_features, n_samples)\n+    rng = np.random.default_rng(global_random_seed)\n+    x = rng.normal(size=(n_features, n_samples))\n     # Assume centered data, to reduce test complexity\n     var_emp = empirical_covariance(x.T, assume_centered=True).diagonal()\n     cov_mcd = (\n-        MinCovDet(support_fraction=1.0, store_precision=False, assume_centered=True)\n+        MinCovDet(\n+            support_fraction=1.0,\n+            store_precision=False,\n+            assume_centered=True,\n+            random_state=global_random_seed,\n+        )\n         .fit(x.T)\n         .covariance_\n     )\n",
  "fail_to_pass": [],
  "pass_to_pass": [],
  "relevant_files": [
    "sklearn/covariance/tests/test_robust_covariance.py"
  ],
  "difficulty": "easy",
  "created_at": "2025-11-21T12:03:21Z",
  "pr_url": "https://github.com/scikit-learn/scikit-learn/pull/32760",
  "issue_url": "https://github.com/scikit-learn/scikit-learn/issues/32725"
}