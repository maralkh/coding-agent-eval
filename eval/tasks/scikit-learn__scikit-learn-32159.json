{
  "id": "scikit-learn__scikit-learn-32159",
  "repo": "scikit-learn/scikit-learn",
  "base_commit": "2fef2875956e53959efe60dc9ca343cb1295562c",
  "issue_number": 29868,
  "issue_title": "FIX pipeline now checks if it's fitted",
  "issue_body": "Fixes https://github.com/scikit-learn/scikit-learn/issues/27014\r\n\r\nThis PR makes `Pipeline` to check if it's fitted in methods other than `fit*`, with a deprecation.\r\n\r\ncc @glemaitre @betatim @StefanieSenger ",
  "pr_number": 32159,
  "pr_title": "MNT Clean-up deprecation for 1.8: _raise_or_warn_if_not_fitted in Pipeline",
  "gold_patch": "diff --git a/sklearn/pipeline.py b/sklearn/pipeline.py\nindex 86ff423b5c4d8..8e84d540dad5a 100644\n--- a/sklearn/pipeline.py\n+++ b/sklearn/pipeline.py\n@@ -3,9 +3,7 @@\n # Authors: The scikit-learn developers\n # SPDX-License-Identifier: BSD-3-Clause\n \n-import warnings\n from collections import Counter, defaultdict\n-from contextlib import contextmanager\n from copy import deepcopy\n from itertools import chain, islice\n \n@@ -37,33 +35,6 @@\n __all__ = [\"FeatureUnion\", \"Pipeline\", \"make_pipeline\", \"make_union\"]\n \n \n-@contextmanager\n-def _raise_or_warn_if_not_fitted(estimator):\n-    \"\"\"A context manager to make sure a NotFittedError is raised, if a sub-estimator\n-    raises the error.\n-\n-    Otherwise, we raise a warning if the pipeline is not fitted, with the deprecation.\n-\n-    TODO(1.8): remove this context manager and replace with check_is_fitted.\n-    \"\"\"\n-    try:\n-        yield\n-    except NotFittedError as exc:\n-        raise NotFittedError(\"Pipeline is not fitted yet.\") from exc\n-\n-    # we only get here if the above didn't raise\n-    try:\n-        check_is_fitted(estimator)\n-    except NotFittedError:\n-        warnings.warn(\n-            \"This Pipeline instance is not fitted yet. Call 'fit' with \"\n-            \"appropriate arguments before using other methods such as transform, \"\n-            \"predict, etc. This will raise an error in 1.8 instead of the current \"\n-            \"warning.\",\n-            FutureWarning,\n-        )\n-\n-\n def _final_estimator_has(attr):\n     \"\"\"Check that final_estimator has `attr`.\n \n@@ -776,22 +747,19 @@ def predict(self, X, **params):\n         y_pred : ndarray\n             Result of calling `predict` on the final estimator.\n         \"\"\"\n-        # TODO(1.8): Remove the context manager and use check_is_fitted(self)\n-        with _raise_or_warn_if_not_fitted(self):\n-            Xt = X\n-\n-            if not _routing_enabled():\n-                for _, name, transform in self._iter(with_final=False):\n-                    Xt = transform.transform(Xt)\n-                return self.steps[-1][1].predict(Xt, **params)\n+        check_is_fitted(self)\n+        Xt = X\n \n-            # metadata routing enabled\n-            routed_params = process_routing(self, \"predict\", **params)\n+        if not _routing_enabled():\n             for _, name, transform in self._iter(with_final=False):\n-                Xt = transform.transform(Xt, **routed_params[name].transform)\n-            return self.steps[-1][1].predict(\n-                Xt, **routed_params[self.steps[-1][0]].predict\n-            )\n+                Xt = transform.transform(Xt)\n+            return self.steps[-1][1].predict(Xt, **params)\n+\n+        # metadata routing enabled\n+        routed_params = process_routing(self, \"predict\", **params)\n+        for _, name, transform in self._iter(with_final=False):\n+            Xt = transform.transform(Xt, **routed_params[name].transform)\n+        return self.steps[-1][1].predict(Xt, **routed_params[self.steps[-1][0]].predict)\n \n     @available_if(_final_estimator_has(\"fit_predict\"))\n     @_fit_context(\n@@ -892,22 +860,21 @@ def predict_proba(self, X, **params):\n         y_proba : ndarray of shape (n_samples, n_classes)\n             Result of calling `predict_proba` on the final estimator.\n         \"\"\"\n-        # TODO(1.8): Remove the context manager and use check_is_fitted(self)\n-        with _raise_or_warn_if_not_fitted(self):\n-            Xt = X\n+        check_is_fitted(self)\n+        Xt = X\n \n-            if not _routing_enabled():\n-                for _, name, transform in self._iter(with_final=False):\n-                    Xt = transform.transform(Xt)\n-                return self.steps[-1][1].predict_proba(Xt, **params)\n-\n-            # metadata routing enabled\n-            routed_params = process_routing(self, \"predict_proba\", **params)\n+        if not _routing_enabled():\n             for _, name, transform in self._iter(with_final=False):\n-                Xt = transform.transform(Xt, **routed_params[name].transform)\n-            return self.steps[-1][1].predict_proba(\n-                Xt, **routed_params[self.steps[-1][0]].predict_proba\n-            )\n+                Xt = transform.transform(Xt)\n+            return self.steps[-1][1].predict_proba(Xt, **params)\n+\n+        # metadata routing enabled\n+        routed_params = process_routing(self, \"predict_proba\", **params)\n+        for _, name, transform in self._iter(with_final=False):\n+            Xt = transform.transform(Xt, **routed_params[name].transform)\n+        return self.steps[-1][1].predict_proba(\n+            Xt, **routed_params[self.steps[-1][0]].predict_proba\n+        )\n \n     @available_if(_final_estimator_has(\"decision_function\"))\n     def decision_function(self, X, **params):\n@@ -939,23 +906,22 @@ def decision_function(self, X, **params):\n         y_score : ndarray of shape (n_samples, n_classes)\n             Result of calling `decision_function` on the final estimator.\n         \"\"\"\n-        # TODO(1.8): Remove the context manager and use check_is_fitted(self)\n-        with _raise_or_warn_if_not_fitted(self):\n-            _raise_for_params(params, self, \"decision_function\")\n+        check_is_fitted(self)\n+        _raise_for_params(params, self, \"decision_function\")\n \n-            # not branching here since params is only available if\n-            # enable_metadata_routing=True\n-            routed_params = process_routing(self, \"decision_function\", **params)\n+        # not branching here since params is only available if\n+        # enable_metadata_routing=True\n+        routed_params = process_routing(self, \"decision_function\", **params)\n \n-            Xt = X\n-            for _, name, transform in self._iter(with_final=False):\n-                Xt = transform.transform(\n-                    Xt, **routed_params.get(name, {}).get(\"transform\", {})\n-                )\n-            return self.steps[-1][1].decision_function(\n-                Xt,\n-                **routed_params.get(self.steps[-1][0], {}).get(\"decision_function\", {}),\n+        Xt = X\n+        for _, name, transform in self._iter(with_final=False):\n+            Xt = transform.transform(\n+                Xt, **routed_params.get(name, {}).get(\"transform\", {})\n             )\n+        return self.steps[-1][1].decision_function(\n+            Xt,\n+            **routed_params.get(self.steps[-1][0], {}).get(\"decision_function\", {}),\n+        )\n \n     @available_if(_final_estimator_has(\"score_samples\"))\n     def score_samples(self, X):\n@@ -977,12 +943,11 @@ def score_samples(self, X):\n         y_score : ndarray of shape (n_samples,)\n             Result of calling `score_samples` on the final estimator.\n         \"\"\"\n-        # TODO(1.8): Remove the context manager and use check_is_fitted(self)\n-        with _raise_or_warn_if_not_fitted(self):\n-            Xt = X\n-            for _, _, transformer in self._iter(with_final=False):\n-                Xt = transformer.transform(Xt)\n-            return self.steps[-1][1].score_samples(Xt)\n+        check_is_fitted(self)\n+        Xt = X\n+        for _, _, transformer in self._iter(with_final=False):\n+            Xt = transformer.transform(Xt)\n+        return self.steps[-1][1].score_samples(Xt)\n \n     @available_if(_final_estimator_has(\"predict_log_proba\"))\n     def predict_log_proba(self, X, **params):\n@@ -1023,22 +988,21 @@ def predict_log_proba(self, X, **params):\n         y_log_proba : ndarray of shape (n_samples, n_classes)\n             Result of calling `predict_log_proba` on the final estimator.\n         \"\"\"\n-        # TODO(1.8): Remove the context manager and use check_is_fitted(self)\n-        with _raise_or_warn_if_not_fitted(self):\n-            Xt = X\n-\n-            if not _routing_enabled():\n-                for _, name, transform in self._iter(with_final=False):\n-                    Xt = transform.transform(Xt)\n-                return self.steps[-1][1].predict_log_proba(Xt, **params)\n+        check_is_fitted(self)\n+        Xt = X\n \n-            # metadata routing enabled\n-            routed_params = process_routing(self, \"predict_log_proba\", **params)\n+        if not _routing_enabled():\n             for _, name, transform in self._iter(with_final=False):\n-                Xt = transform.transform(Xt, **routed_params[name].transform)\n-            return self.steps[-1][1].predict_log_proba(\n-                Xt, **routed_params[self.steps[-1][0]].predict_log_proba\n-            )\n+                Xt = transform.transform(Xt)\n+            return self.steps[-1][1].predict_log_proba(Xt, **params)\n+\n+        # metadata routing enabled\n+        routed_params = process_routing(self, \"predict_log_proba\", **params)\n+        for _, name, transform in self._iter(with_final=False):\n+            Xt = transform.transform(Xt, **routed_params[name].transform)\n+        return self.steps[-1][1].predict_log_proba(\n+            Xt, **routed_params[self.steps[-1][0]].predict_log_proba\n+        )\n \n     def _can_transform(self):\n         return self._final_estimator == \"passthrough\" or hasattr(\n@@ -1078,17 +1042,16 @@ def transform(self, X, **params):\n         Xt : ndarray of shape (n_samples, n_transformed_features)\n             Transformed data.\n         \"\"\"\n-        # TODO(1.8): Remove the context manager and use check_is_fitted(self)\n-        with _raise_or_warn_if_not_fitted(self):\n-            _raise_for_params(params, self, \"transform\")\n+        check_is_fitted(self)\n+        _raise_for_params(params, self, \"transform\")\n \n-            # not branching here since params is only available if\n-            # enable_metadata_routing=True\n-            routed_params = process_routing(self, \"transform\", **params)\n-            Xt = X\n-            for _, name, transform in self._iter():\n-                Xt = transform.transform(Xt, **routed_params[name].transform)\n-            return Xt\n+        # not branching here since params is only available if\n+        # enable_metadata_routing=True\n+        routed_params = process_routing(self, \"transform\", **params)\n+        Xt = X\n+        for _, name, transform in self._iter():\n+            Xt = transform.transform(Xt, **routed_params[name].transform)\n+        return Xt\n \n     def _can_inverse_transform(self):\n         return all(hasattr(t, \"inverse_transform\") for _, _, t in self._iter())\n@@ -1123,19 +1086,16 @@ def inverse_transform(self, X, **params):\n             Inverse transformed data, that is, data in the original feature\n             space.\n         \"\"\"\n-        # TODO(1.8): Remove the context manager and use check_is_fitted(self)\n-        with _raise_or_warn_if_not_fitted(self):\n-            _raise_for_params(params, self, \"inverse_transform\")\n-\n-            # we don't have to branch here, since params is only non-empty if\n-            # enable_metadata_routing=True.\n-            routed_params = process_routing(self, \"inverse_transform\", **params)\n-            reverse_iter = reversed(list(self._iter()))\n-            for _, name, transform in reverse_iter:\n-                X = transform.inverse_transform(\n-                    X, **routed_params[name].inverse_transform\n-                )\n-            return X\n+        check_is_fitted(self)\n+        _raise_for_params(params, self, \"inverse_transform\")\n+\n+        # we don't have to branch here, since params is only non-empty if\n+        # enable_metadata_routing=True.\n+        routed_params = process_routing(self, \"inverse_transform\", **params)\n+        reverse_iter = reversed(list(self._iter()))\n+        for _, name, transform in reverse_iter:\n+            X = transform.inverse_transform(X, **routed_params[name].inverse_transform)\n+        return X\n \n     @available_if(_final_estimator_has(\"score\"))\n     def score(self, X, y=None, sample_weight=None, **params):\n@@ -1174,28 +1134,25 @@ def score(self, X, y=None, sample_weight=None, **params):\n         score : float\n             Result of calling `score` on the final estimator.\n         \"\"\"\n-        # TODO(1.8): Remove the context manager and use check_is_fitted(self)\n-        with _raise_or_warn_if_not_fitted(self):\n-            Xt = X\n-            if not _routing_enabled():\n-                for _, name, transform in self._iter(with_final=False):\n-                    Xt = transform.transform(Xt)\n-                score_params = {}\n-                if sample_weight is not None:\n-                    score_params[\"sample_weight\"] = sample_weight\n-                return self.steps[-1][1].score(Xt, y, **score_params)\n-\n-            # metadata routing is enabled.\n-            routed_params = process_routing(\n-                self, \"score\", sample_weight=sample_weight, **params\n-            )\n-\n-            Xt = X\n+        check_is_fitted(self)\n+        Xt = X\n+        if not _routing_enabled():\n             for _, name, transform in self._iter(with_final=False):\n-                Xt = transform.transform(Xt, **routed_params[name].transform)\n-            return self.steps[-1][1].score(\n-                Xt, y, **routed_params[self.steps[-1][0]].score\n-            )\n+                Xt = transform.transform(Xt)\n+            score_params = {}\n+            if sample_weight is not None:\n+                score_params[\"sample_weight\"] = sample_weight\n+            return self.steps[-1][1].score(Xt, y, **score_params)\n+\n+        # metadata routing is enabled.\n+        routed_params = process_routing(\n+            self, \"score\", sample_weight=sample_weight, **params\n+        )\n+\n+        Xt = X\n+        for _, name, transform in self._iter(with_final=False):\n+            Xt = transform.transform(Xt, **routed_params[name].transform)\n+        return self.steps[-1][1].score(Xt, y, **routed_params[self.steps[-1][0]].score)\n \n     @property\n     def classes_(self):\ndiff --git a/sklearn/tests/test_pipeline.py b/sklearn/tests/test_pipeline.py\nindex ce6bba1a2ed85..ba7c475156e74 100644\n--- a/sklearn/tests/test_pipeline.py\n+++ b/sklearn/tests/test_pipeline.py\n@@ -2089,7 +2089,6 @@ def transform(self, X):\n # =============================\n \n \n-# TODO(1.8): change warning to checking for NotFittedError\n @pytest.mark.parametrize(\n     \"method\",\n     [\n@@ -2140,7 +2139,7 @@ def inverse_transform(self, X):\n             return X\n \n     pipe = Pipeline([(\"estimator\", StatelessEstimator())])\n-    with pytest.warns(FutureWarning, match=\"This Pipeline instance is not fitted yet.\"):\n+    with pytest.raises(NotFittedError):\n         getattr(pipe, method)([[1]])\n \n \n",
  "fail_to_pass": [],
  "pass_to_pass": [],
  "relevant_files": [
    "sklearn/pipeline.py",
    "sklearn/tests/test_pipeline.py"
  ],
  "difficulty": "hard",
  "created_at": "2025-09-11T13:17:52Z",
  "pr_url": "https://github.com/scikit-learn/scikit-learn/pull/32159",
  "issue_url": "https://github.com/scikit-learn/scikit-learn/pull/29868"
}