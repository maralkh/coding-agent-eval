{
  "id": "scikit-learn__scikit-learn-31474",
  "repo": "scikit-learn/scikit-learn",
  "base_commit": "34e46b049534450877584c358cc66b181a078a59",
  "issue_number": 22178,
  "issue_title": "power_t: does it make sense for this parameter to have negative values",
  "issue_body": "sklearn/linear_model/_stochastic_gradient.py\r\n\r\nRef #22115\r\n\r\n>I do not anticipate negative `power_t` to be mathematically meaningful but apparently our code accepts it without crashing... So ok with documenting it.\r\n\r\n_Originally posted by @ogrisel in https://github.com/scikit-learn/scikit-learn/pull/22115#r780109928_\r\n\r\n@thomasjpfan \r\n>I feel like this a case where documenting `-inf` will lead to more people trying out. If this is not mathematically meaningful, then we could be promoting a bad practice?\r\n\r\ncc:  @glemaitre",
  "pr_number": 31474,
  "pr_title": "FIX: Change limits of power_t param to [0, inf)",
  "gold_patch": "diff --git a/doc/whats_new/upcoming_changes/sklearn.linear_model/31474.api.rst b/doc/whats_new/upcoming_changes/sklearn.linear_model/31474.api.rst\nnew file mode 100644\nindex 0000000000000..845b9b502b9f1\n--- /dev/null\n+++ b/doc/whats_new/upcoming_changes/sklearn.linear_model/31474.api.rst\n@@ -0,0 +1,6 @@\n+- :class:`linear_model.SGDClassifier`, :class:`linear_model.SGDRegressor`, and\n+  :class:`linear_model.SGDOneClassSVM` now deprecate negative values for the\n+  `power_t` parameter. Using a negative value will raise a warning in version 1.8\n+  and will raise an error in version 1.10. A value in the range [0.0, inf) must be used\n+  instead.\n+  By :user:`Ritvi Alagusankar <ritvi-alagusankar>`\n\\ No newline at end of file\ndiff --git a/sklearn/linear_model/_stochastic_gradient.py b/sklearn/linear_model/_stochastic_gradient.py\nindex 8f7c814000614..859e527fb3c3b 100644\n--- a/sklearn/linear_model/_stochastic_gradient.py\n+++ b/sklearn/linear_model/_stochastic_gradient.py\n@@ -731,6 +731,15 @@ def _fit(\n                 ),\n                 ConvergenceWarning,\n             )\n+\n+        if self.power_t < 0:\n+            warnings.warn(\n+                \"Negative values for `power_t` are deprecated in version 1.8 \"\n+                \"and will raise an error in 1.10. \"\n+                \"Use values in the range [0.0, inf) instead.\",\n+                FutureWarning,\n+            )\n+\n         return self\n \n     def _fit_binary(self, X, y, alpha, C, sample_weight, learning_rate, max_iter):\n@@ -1082,7 +1091,11 @@ class SGDClassifier(BaseSGDClassifier):\n \n     power_t : float, default=0.5\n         The exponent for inverse scaling learning rate.\n-        Values must be in the range `(-inf, inf)`.\n+        Values must be in the range `[0.0, inf)`.\n+\n+        .. deprecated:: 1.8\n+            Negative values for `power_t` are deprecated in version 1.8 and will raise\n+            an error in 1.10. Use values in the range [0.0, inf) instead.\n \n     early_stopping : bool, default=False\n         Whether to use early stopping to terminate training when validation\n@@ -1585,6 +1598,14 @@ def _fit(\n                 ConvergenceWarning,\n             )\n \n+        if self.power_t < 0:\n+            warnings.warn(\n+                \"Negative values for `power_t` are deprecated in version 1.8 \"\n+                \"and will raise an error in 1.10. \"\n+                \"Use values in the range [0.0, inf) instead.\",\n+                FutureWarning,\n+            )\n+\n         return self\n \n     @_fit_context(prefer_skip_nested_validation=True)\n@@ -1880,7 +1901,11 @@ class SGDRegressor(BaseSGDRegressor):\n \n     power_t : float, default=0.25\n         The exponent for inverse scaling learning rate.\n-        Values must be in the range `(-inf, inf)`.\n+        Values must be in the range `[0.0, inf)`.\n+\n+        .. deprecated:: 1.8\n+            Negative values for `power_t` are deprecated in version 1.8 and will raise\n+            an error in 1.10. Use values in the range [0.0, inf) instead.\n \n     early_stopping : bool, default=False\n         Whether to use early stopping to terminate training when validation\n@@ -2118,7 +2143,11 @@ class SGDOneClassSVM(OutlierMixin, BaseSGD):\n \n     power_t : float, default=0.5\n         The exponent for inverse scaling learning rate.\n-        Values must be in the range `(-inf, inf)`.\n+        Values must be in the range `[0.0, inf)`.\n+\n+        .. deprecated:: 1.8\n+            Negative values for `power_t` are deprecated in version 1.8 and will raise\n+            an error in 1.10. Use values in the range [0.0, inf) instead.\n \n     warm_start : bool, default=False\n         When set to True, reuse the solution of the previous call to fit as\n@@ -2490,6 +2519,14 @@ def _fit(\n                 ConvergenceWarning,\n             )\n \n+        if self.power_t < 0:\n+            warnings.warn(\n+                \"Negative values for `power_t` are deprecated in version 1.8 \"\n+                \"and will raise an error in 1.10. \"\n+                \"Use values in the range [0.0, inf) instead.\",\n+                FutureWarning,\n+            )\n+\n         return self\n \n     @_fit_context(prefer_skip_nested_validation=True)\ndiff --git a/sklearn/linear_model/tests/test_sgd.py b/sklearn/linear_model/tests/test_sgd.py\nindex 26d138ae3649b..80b69adf99b99 100644\n--- a/sklearn/linear_model/tests/test_sgd.py\n+++ b/sklearn/linear_model/tests/test_sgd.py\n@@ -1,4 +1,5 @@\n import pickle\n+import warnings\n from unittest.mock import Mock\n \n import joblib\n@@ -507,6 +508,35 @@ def test_sgd_failing_penalty_validation(Estimator):\n         clf.fit(X, Y)\n \n \n+# TODO(1.10): remove this test\n+@pytest.mark.parametrize(\n+    \"klass\",\n+    [\n+        SGDClassifier,\n+        SparseSGDClassifier,\n+        SGDRegressor,\n+        SparseSGDRegressor,\n+        SGDOneClassSVM,\n+        SparseSGDOneClassSVM,\n+    ],\n+)\n+def test_power_t_limits(klass):\n+    \"\"\"Check that a warning is raised when `power_t` is negative.\"\"\"\n+\n+    # Check that negative values of `power_t` raise a warning\n+    clf = klass(power_t=-1.0)\n+    with pytest.warns(\n+        FutureWarning, match=\"Negative values for `power_t` are deprecated\"\n+    ):\n+        clf.fit(X, Y)\n+\n+    # Check that values of 'power_t in range [0, inf) do not raise a warning\n+    with warnings.catch_warnings(record=True) as w:\n+        clf = klass(power_t=0.5)\n+        clf.fit(X, Y)\n+    assert len(w) == 0\n+\n+\n ###############################################################################\n # Classification Test Case\n \n",
  "fail_to_pass": [
    "test_power_t_limits"
  ],
  "pass_to_pass": [],
  "relevant_files": [
    "sklearn/linear_model/_stochastic_gradient.py",
    "sklearn/linear_model/tests/test_sgd.py"
  ],
  "difficulty": "medium",
  "created_at": "2025-06-03T08:19:10Z",
  "pr_url": "https://github.com/scikit-learn/scikit-learn/pull/31474",
  "issue_url": "https://github.com/scikit-learn/scikit-learn/issues/22178"
}