{
  "id": "scikit-learn__scikit-learn-30443",
  "repo": "scikit-learn/scikit-learn",
  "base_commit": "7f0215f5bee45a5c74728a1aaf37b58b12d4f3e6",
  "issue_number": 1234,
  "issue_title": "MRG fix bincount mess I made in kmeans.",
  "issue_body": "This should clean up the stuff I pushed earlier.\ncc @ogrisel @gaelvaroquaux Could you have a brief look? What I pushed earlier is buggy but I didn't dare push again after so many failed fixes.\n",
  "pr_number": 30443,
  "pr_title": "ENH Implement `inverse_transform` in `DictionaryLearning`, `SparseCoder` and `MiniBatchDictionaryLearning`",
  "gold_patch": "diff --git a/doc/whats_new/upcoming_changes/sklearn.decomposition/30443.feature.rst b/doc/whats_new/upcoming_changes/sklearn.decomposition/30443.feature.rst\nnew file mode 100644\nindex 0000000000000..5678039b69065\n--- /dev/null\n+++ b/doc/whats_new/upcoming_changes/sklearn.decomposition/30443.feature.rst\n@@ -0,0 +1,4 @@\n+- :class:`~sklearn.decomposition.DictionaryLearning`,\n+  :class:`~sklearn.decomposition.SparseCoder`  and\n+  :class:`~sklearn.decomposition.MiniBatchDictionaryLearning` now have a\n+  ``inverse_transform`` method. By :user:`R\u00e9mi Flamary <rflamary>`\ndiff --git a/sklearn/decomposition/_dict_learning.py b/sklearn/decomposition/_dict_learning.py\nindex 7410eeb4405df..282376550de24 100644\n--- a/sklearn/decomposition/_dict_learning.py\n+++ b/sklearn/decomposition/_dict_learning.py\n@@ -1142,6 +1142,44 @@ def transform(self, X):\n         check_is_fitted(self)\n         return self._transform(X, self.components_)\n \n+    def _inverse_transform(self, code, dictionary):\n+        \"\"\"Private method allowing to accommodate both DictionaryLearning and\n+        SparseCoder.\"\"\"\n+        code = check_array(code)\n+        # compute number of expected features in code\n+        expected_n_components = dictionary.shape[0]\n+        if self.split_sign:\n+            expected_n_components += expected_n_components\n+        if not code.shape[1] == expected_n_components:\n+            raise ValueError(\n+                \"The number of components in the code is different from the \"\n+                \"number of components in the dictionary.\"\n+                f\"Expected {expected_n_components}, got {code.shape[1]}.\"\n+            )\n+        if self.split_sign:\n+            n_samples, n_features = code.shape\n+            n_features //= 2\n+            code = code[:, :n_features] - code[:, n_features:]\n+\n+        return code @ dictionary\n+\n+    def inverse_transform(self, X):\n+        \"\"\"Transform data back to its original space.\n+\n+        Parameters\n+        ----------\n+        X : array-like of shape (n_samples, n_components)\n+            Data to be transformed back. Must have the same number of\n+            components as the data used to train the model.\n+\n+        Returns\n+        -------\n+        X_new : ndarray of shape (n_samples, n_features)\n+            Transformed data.\n+        \"\"\"\n+        check_is_fitted(self)\n+        return self._inverse_transform(X, self.components_)\n+\n \n class SparseCoder(_BaseSparseCoding, BaseEstimator):\n     \"\"\"Sparse coding.\n@@ -1329,6 +1367,22 @@ def transform(self, X, y=None):\n         \"\"\"\n         return super()._transform(X, self.dictionary)\n \n+    def inverse_transform(self, X):\n+        \"\"\"Transform data back to its original space.\n+\n+        Parameters\n+        ----------\n+        X : array-like of shape (n_samples, n_components)\n+            Data to be transformed back. Must have the same number of\n+            components as the data used to train the model.\n+\n+        Returns\n+        -------\n+        X_new : ndarray of shape (n_samples, n_features)\n+            Transformed data.\n+        \"\"\"\n+        return self._inverse_transform(X, self.dictionary)\n+\n     def __sklearn_tags__(self):\n         tags = super().__sklearn_tags__()\n         tags.requires_fit = False\ndiff --git a/sklearn/decomposition/tests/test_dict_learning.py b/sklearn/decomposition/tests/test_dict_learning.py\nindex f52c851012481..717c56d0abdbe 100644\n--- a/sklearn/decomposition/tests/test_dict_learning.py\n+++ b/sklearn/decomposition/tests/test_dict_learning.py\n@@ -202,10 +202,16 @@ def test_dict_learning_reconstruction():\n     )\n     code = dico.fit(X).transform(X)\n     assert_array_almost_equal(np.dot(code, dico.components_), X)\n+    assert_array_almost_equal(dico.inverse_transform(code), X)\n \n     dico.set_params(transform_algorithm=\"lasso_lars\")\n     code = dico.transform(X)\n     assert_array_almost_equal(np.dot(code, dico.components_), X, decimal=2)\n+    assert_array_almost_equal(dico.inverse_transform(code), X, decimal=2)\n+\n+    # test error raised for wrong code size\n+    with pytest.raises(ValueError, match=\"Expected 12, got 11.\"):\n+        dico.inverse_transform(code[:, :-1])\n \n     # used to test lars here too, but there's no guarantee the number of\n     # nonzero atoms is right.\n@@ -268,6 +274,8 @@ def test_dict_learning_split():\n         n_components, transform_algorithm=\"threshold\", random_state=0\n     )\n     code = dico.fit(X).transform(X)\n+    Xr = dico.inverse_transform(code)\n+\n     dico.split_sign = True\n     split_code = dico.transform(X)\n \n@@ -275,6 +283,9 @@ def test_dict_learning_split():\n         split_code[:, :n_components] - split_code[:, n_components:], code\n     )\n \n+    Xr2 = dico.inverse_transform(split_code)\n+    assert_array_almost_equal(Xr, Xr2)\n+\n \n def test_dict_learning_online_shapes():\n     rng = np.random.RandomState(0)\n@@ -591,9 +602,12 @@ def test_sparse_coder_estimator():\n     V /= np.sum(V**2, axis=1)[:, np.newaxis]\n     coder = SparseCoder(\n         dictionary=V, transform_algorithm=\"lasso_lars\", transform_alpha=0.001\n-    ).transform(X)\n-    assert not np.all(coder == 0)\n-    assert np.sqrt(np.sum((np.dot(coder, V) - X) ** 2)) < 0.1\n+    )\n+    code = coder.fit_transform(X)\n+    Xr = coder.inverse_transform(code)\n+    assert not np.all(code == 0)\n+    assert np.sqrt(np.sum((np.dot(code, V) - X) ** 2)) < 0.1\n+    np.testing.assert_allclose(Xr, np.dot(code, V))\n \n \n def test_sparse_coder_estimator_clone():\n",
  "fail_to_pass": [],
  "pass_to_pass": [],
  "relevant_files": [
    "sklearn/decomposition/_dict_learning.py",
    "sklearn/decomposition/tests/test_dict_learning.py"
  ],
  "difficulty": "medium",
  "created_at": "2024-12-09T16:29:08Z",
  "pr_url": "https://github.com/scikit-learn/scikit-learn/pull/30443",
  "issue_url": "https://github.com/scikit-learn/scikit-learn/pull/1234"
}