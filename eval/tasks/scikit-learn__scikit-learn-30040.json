{
  "id": "scikit-learn__scikit-learn-30040",
  "repo": "scikit-learn/scikit-learn",
  "base_commit": "4c78d7cf2be10f5d711d32c61d2dfded5861daf0",
  "issue_number": 30030,
  "issue_title": "FIX LinearRegression sample weight bug (numpy solver)",
  "issue_body": "#### Reference Issues/PRs\r\n\r\n#29818  and #26164 revealed that LinearRegression was failing the sample weight consistency check (using weights should be equivalent to removing/repeating samples). \r\n\r\nRelated to #22947  #25948\r\n\r\n#### What does this implement/fix? Explain your changes.\r\n\r\nThe `scipy.linalg.lstsq` solver fails the sample weight consistency test for wide dataset (`n_features > n_samples`) after centering `X,y` (as done when `fit_intercept=True`).\r\n\r\nUsing the `numpy.linalg.lstsq` solver seems to solve the bug.\r\n\r\n`test_linear_regression_sample_weight_consistency` now uses `n_features > n_samples` to fail more consistently.\r\n",
  "pr_number": 30040,
  "pr_title": "Fix `LinearRegression`'s numerical stability on rank deficient data by setting the `cond` parameter in the call to `scipy.linalg.lstsq`",
  "gold_patch": "diff --git a/doc/whats_new/upcoming_changes/sklearn.linear_model/30040.fix.rst b/doc/whats_new/upcoming_changes/sklearn.linear_model/30040.fix.rst\nnew file mode 100644\nindex 0000000000000..f4a91911345e3\n--- /dev/null\n+++ b/doc/whats_new/upcoming_changes/sklearn.linear_model/30040.fix.rst\n@@ -0,0 +1,6 @@\n+- :class:`linear_model.LinearRegression` now sets the `cond` parameter when\n+  calling the `scipy.linalg.lstsq` solver on dense input data. This ensures\n+  more numerically robust results on rank-deficient data. In particular, it\n+  empirically fixes the expected equivalence property between fitting with\n+  reweighted or with repeated data points.\n+  :pr:`30040` by :user:`Antoine Baker <antoinebaker>`.\ndiff --git a/sklearn/linear_model/_base.py b/sklearn/linear_model/_base.py\nindex 6f86387a1c355..76b0ad746f9b9 100644\n--- a/sklearn/linear_model/_base.py\n+++ b/sklearn/linear_model/_base.py\n@@ -673,7 +673,9 @@ def rmatvec(b):\n                 )\n                 self.coef_ = np.vstack([out[0] for out in outs])\n         else:\n-            self.coef_, _, self.rank_, self.singular_ = linalg.lstsq(X, y)\n+            # cut-off ratio for small singular values\n+            cond = max(X.shape) * np.finfo(X.dtype).eps\n+            self.coef_, _, self.rank_, self.singular_ = linalg.lstsq(X, y, cond=cond)\n             self.coef_ = self.coef_.T\n \n         if y.ndim == 1:\n@@ -681,22 +683,6 @@ def rmatvec(b):\n         self._set_intercept(X_offset, y_offset, X_scale)\n         return self\n \n-    def __sklearn_tags__(self):\n-        tags = super().__sklearn_tags__()\n-        # TODO: investigate failure see meta-issue #16298\n-        #\n-        # Note: this model should converge to the minimum norm solution of the\n-        # least squares problem and as result be numerically stable enough when\n-        # running the equivalence check even if n_features > n_samples. Maybe\n-        # this is is not the case and a different choice of solver could fix\n-        # this problem.\n-        tags._xfail_checks = {\n-            \"check_sample_weight_equivalence\": (\n-                \"sample_weight is not equivalent to removing/repeating samples.\"\n-            ),\n-        }\n-        return tags\n-\n \n def _check_precomputed_gram_matrix(\n     X, precompute, X_offset, X_scale, rtol=None, atol=1e-5\ndiff --git a/sklearn/linear_model/tests/test_base.py b/sklearn/linear_model/tests/test_base.py\nindex f6bb0c975a973..be8e85b9703fa 100644\n--- a/sklearn/linear_model/tests/test_base.py\n+++ b/sklearn/linear_model/tests/test_base.py\n@@ -692,10 +692,23 @@ def test_fused_types_make_dataset(csr_container):\n     assert_array_equal(yi_64, yicsr_64)\n \n \n-@pytest.mark.parametrize(\"sparse_container\", [None] + CSR_CONTAINERS)\n+@pytest.mark.parametrize(\"X_shape\", [(10, 5), (10, 20), (100, 100)])\n+@pytest.mark.parametrize(\n+    \"sparse_container\",\n+    [None]\n+    + [\n+        pytest.param(\n+            container,\n+            marks=pytest.mark.xfail(\n+                reason=\"Known to fail for CSR arrays, see issue #30131.\"\n+            ),\n+        )\n+        for container in CSR_CONTAINERS\n+    ],\n+)\n @pytest.mark.parametrize(\"fit_intercept\", [False, True])\n def test_linear_regression_sample_weight_consistency(\n-    sparse_container, fit_intercept, global_random_seed\n+    X_shape, sparse_container, fit_intercept, global_random_seed\n ):\n     \"\"\"Test that the impact of sample_weight is consistent.\n \n@@ -704,7 +717,7 @@ def test_linear_regression_sample_weight_consistency(\n     It is very similar to test_enet_sample_weight_consistency.\n     \"\"\"\n     rng = np.random.RandomState(global_random_seed)\n-    n_samples, n_features = 10, 5\n+    n_samples, n_features = X_shape\n \n     X = rng.rand(n_samples, n_features)\n     y = rng.rand(n_samples)\n@@ -754,17 +767,9 @@ def test_linear_regression_sample_weight_consistency(\n     if fit_intercept:\n         intercept_0 = reg.intercept_\n     reg.fit(X[:-5], y[:-5], sample_weight=sample_weight[:-5])\n-    if fit_intercept and sparse_container is None:\n-        # FIXME: https://github.com/scikit-learn/scikit-learn/issues/26164\n-        # This often fails, e.g. when calling\n-        # SKLEARN_TESTS_GLOBAL_RANDOM_SEED=\"all\" pytest \\\n-        # sklearn/linear_model/tests/test_base.py\\\n-        # ::test_linear_regression_sample_weight_consistency\n-        pass\n-    else:\n-        assert_allclose(reg.coef_, coef_0, rtol=1e-5)\n-        if fit_intercept:\n-            assert_allclose(reg.intercept_, intercept_0)\n+    assert_allclose(reg.coef_, coef_0, rtol=1e-5)\n+    if fit_intercept:\n+        assert_allclose(reg.intercept_, intercept_0)\n \n     # 5) check that multiplying sample_weight by 2 is equivalent to repeating\n     # corresponding samples twice\n",
  "fail_to_pass": [],
  "pass_to_pass": [],
  "relevant_files": [
    "sklearn/linear_model/_base.py",
    "sklearn/linear_model/tests/test_base.py"
  ],
  "difficulty": "medium",
  "created_at": "2024-10-10T08:09:34Z",
  "pr_url": "https://github.com/scikit-learn/scikit-learn/pull/30040",
  "issue_url": "https://github.com/scikit-learn/scikit-learn/pull/30030"
}