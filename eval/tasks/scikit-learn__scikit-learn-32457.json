{
  "id": "scikit-learn__scikit-learn-32457",
  "repo": "scikit-learn/scikit-learn",
  "base_commit": "12468c57a94959ea853146a1043d6f2db4111a00",
  "issue_number": 1234,
  "issue_title": "MRG fix bincount mess I made in kmeans.",
  "issue_body": "This should clean up the stuff I pushed earlier.\ncc @ogrisel @gaelvaroquaux Could you have a brief look? What I pushed earlier is buggy but I didn't dare push again after so many failed fixes.\n",
  "pr_number": 32457,
  "pr_title": "MNT Clean-up deprecations for 1.8: Deprecation of response_method=None in make_scorer",
  "gold_patch": "diff --git a/sklearn/metrics/_scorer.py b/sklearn/metrics/_scorer.py\nindex a0cccd51db0b6..d8356ca54298d 100644\n--- a/sklearn/metrics/_scorer.py\n+++ b/sklearn/metrics/_scorer.py\n@@ -71,7 +71,6 @@\n from sklearn.utils import Bunch\n from sklearn.utils._param_validation import (\n     HasMethods,\n-    Hidden,\n     StrOptions,\n     validate_params,\n )\n@@ -612,18 +611,16 @@ def _get_response_method_name(response_method):\n     {\n         \"score_func\": [callable],\n         \"response_method\": [\n-            None,\n             list,\n             tuple,\n             StrOptions({\"predict\", \"predict_proba\", \"decision_function\"}),\n-            Hidden(StrOptions({\"default\"})),\n         ],\n         \"greater_is_better\": [\"boolean\"],\n     },\n     prefer_skip_nested_validation=True,\n )\n def make_scorer(\n-    score_func, *, response_method=\"default\", greater_is_better=True, **kwargs\n+    score_func, *, response_method=\"predict\", greater_is_better=True, **kwargs\n ):\n     \"\"\"Make a scorer from a performance metric or loss function.\n \n@@ -645,7 +642,7 @@ def make_scorer(\n         ``score_func(y, y_pred, **kwargs)``.\n \n     response_method : {\"predict_proba\", \"decision_function\", \"predict\"} or \\\n-            list/tuple of such str, default=None\n+            list/tuple of such str, default=\"predict\"\n \n         Specifies the response method to use get prediction from an estimator\n         (i.e. :term:`predict_proba`, :term:`decision_function` or\n@@ -655,14 +652,9 @@ def make_scorer(\n         - if a list or tuple of `str`, it provides the method names in order of\n           preference. The method returned corresponds to the first method in\n           the list and which is implemented by `estimator`.\n-        - if `None`, it is equivalent to `\"predict\"`.\n \n         .. versionadded:: 1.4\n \n-        .. deprecated:: 1.6\n-            None is equivalent to 'predict' and is deprecated. It will be removed in\n-            version 1.8.\n-\n     greater_is_better : bool, default=True\n         Whether `score_func` is a score function (default), meaning high is\n         good, or a loss function, meaning low is good. In the latter case, the\n@@ -689,16 +681,6 @@ def make_scorer(\n     \"\"\"\n     sign = 1 if greater_is_better else -1\n \n-    if response_method is None:\n-        warnings.warn(\n-            \"response_method=None is deprecated in version 1.6 and will be removed \"\n-            \"in version 1.8. Leave it to its default value to avoid this warning.\",\n-            FutureWarning,\n-        )\n-        response_method = \"predict\"\n-    elif response_method == \"default\":\n-        response_method = \"predict\"\n-\n     return _Scorer(score_func, sign, kwargs, response_method)\n \n \ndiff --git a/sklearn/metrics/tests/test_score_objects.py b/sklearn/metrics/tests/test_score_objects.py\nindex 9cf9fc8168465..278b6b9986a4f 100644\n--- a/sklearn/metrics/tests/test_score_objects.py\n+++ b/sklearn/metrics/tests/test_score_objects.py\n@@ -1,7 +1,6 @@\n import numbers\n import pickle\n import re\n-import warnings\n from copy import deepcopy\n from functools import partial\n \n@@ -1645,18 +1644,6 @@ def test_curve_scorer_pos_label(global_random_seed):\n     assert scores_pos_label_1.max() == pytest.approx(1.0)\n \n \n-# TODO(1.8): remove\n-def test_make_scorer_reponse_method_default_warning():\n-    with pytest.warns(FutureWarning, match=\"response_method=None is deprecated\"):\n-        make_scorer(accuracy_score, response_method=None)\n-\n-    # No warning is raised if response_method is left to its default value\n-    # because the future default value has the same effect as the current one.\n-    with warnings.catch_warnings():\n-        warnings.simplefilter(\"error\", FutureWarning)\n-        make_scorer(accuracy_score)\n-\n-\n @config_context(enable_metadata_routing=True)\n def test_Pipeline_in_PassthroughScorer():\n     \"\"\"Non-regression test for\n",
  "fail_to_pass": [],
  "pass_to_pass": [],
  "relevant_files": [
    "sklearn/metrics/_scorer.py",
    "sklearn/metrics/tests/test_score_objects.py"
  ],
  "difficulty": "medium",
  "created_at": "2025-10-09T13:34:53Z",
  "pr_url": "https://github.com/scikit-learn/scikit-learn/pull/32457",
  "issue_url": "https://github.com/scikit-learn/scikit-learn/pull/1234"
}