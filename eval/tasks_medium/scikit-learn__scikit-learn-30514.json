{
  "id": "scikit-learn__scikit-learn-30514",
  "repo": "scikit-learn/scikit-learn",
  "base_commit": "4f847f5ad881d46b1f8892ecf8d8adcd11e95d98",
  "issue_number": 16846,
  "issue_title": "In multifold.MDS  stress value doesn\u2019t correspond to returned coordinates",
  "issue_body": "<p><strong>Description</strong></p>\n<p>&nbsp;</p>\n<p>In multifold.MDS&nbsp; stress value doesn&rsquo;t correspond to returned coordinates.</p>\n<p>&nbsp;</p>\n<p><strong>How to reproduce:</strong></p>\n<p>&nbsp;</p>\n<p>Apply MDS to four points in 2d-plane:</p>\n<p>&nbsp;</p>\n<p>X &nbsp;&nbsp;Y</p>\n<p>1 &nbsp;&nbsp;5</p>\n<p>1 &nbsp;&nbsp;4</p>\n<p>1&nbsp; &nbsp;1</p>\n<p>3&nbsp; &nbsp;3</p>\n<p>&nbsp;</p>\n<p>If distances are Euclidean, then disparities matrix will be:</p>\n<p>&nbsp;</p>\n<p>disparities =</p>\n<p>&nbsp;[ 0.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 1.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;4.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 2.82842712&nbsp; ]</p>\n<p>&nbsp;[ 1.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 0.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;3.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 2.23606798&nbsp; ]</p>\n<p>&nbsp;[ 4.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 3.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;0.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 2.82842712&nbsp; ]</p>\n<p>&nbsp;[ 2.82842712&nbsp; &nbsp; &nbsp; 2.23606798&nbsp; &nbsp; &nbsp;2.82842712&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp;0.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ]</p>\n<p>&nbsp;</p>\n<p>Perform multidimensional scaling:</p>\n<p>&nbsp;</p>\n<p>mds = manifold.MDS(n_components=2, dissimilarity=\"precomputed\", random_state=42,  metric = True)</p>\n<p>results = mds.fit(disparities)</p>\n<p>coords = results.embedding_</p>\n<p>&nbsp;</p>\n<p>cords =</p>\n<p>&nbsp;[ -0.32503572&nbsp; &nbsp; &nbsp; 1.78399044 ]</p>\n<p>&nbsp;[&nbsp; 0.09843686&nbsp; &nbsp; &nbsp; 0.87890749 ]</p>\n<p>&nbsp;[&nbsp; 1.47842546&nbsp; &nbsp; &nbsp;-1.76761757 ]</p>\n<p>&nbsp;[ -1.2518266&nbsp; &nbsp; &nbsp; -0.89528037 ]</p>\n<p>&nbsp;</p>\n<p>stress = results.stress_</p>\n<p>0.0045113518633979315</p>\n<p>&nbsp;</p>\n<p>Now calculate stress by hand.</p>\n<p>&nbsp;</p>\n<p>First calculate Euclidian distances which correspond coordinates returned:</p>\n<p>&nbsp;</p>\n<p>dis = euclidean_distances(coords)</p>\n<p>&nbsp;[ 0.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;0.9992518&nbsp; &nbsp; &nbsp; &nbsp;3.98326395&nbsp; &nbsp; &nbsp; 2.83503675&nbsp; ]</p>\n<p>&nbsp;[ 0.9992518&nbsp; &nbsp;&nbsp;&nbsp;0.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;2.98470492&nbsp; &nbsp; &nbsp; 2.22956362&nbsp; ]</p>\n<p>&nbsp;[ 3.98326395&nbsp; &nbsp;2.98470492&nbsp; &nbsp; &nbsp;0.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 2.86622548&nbsp; ]</p>\n<p>&nbsp;[ 2.83503675&nbsp; &nbsp;2.22956362&nbsp; &nbsp; &nbsp;2.86622548&nbsp; &nbsp; &nbsp; 0.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; ]</p>\n<p>&nbsp;</p>\n<p>And now we can calculate stress value:</p>\n<p>&nbsp;</p>\n<p>stress =</p>\n<p>((dis.ravel() - disparities.ravel()) ** 2).sum() / 2</p>\n<p>0.0020293041020245147</p>\n<p>&nbsp;</p>\n<p>So, the real stress calculated using returned coordinates doesn&rsquo;t correspond to the stress value</p>\n<p>results.stress_ = 0.0045113518633979315</p>\n<p>&nbsp;</p>\n<p>After some debugging it is clear that MDS returns coordinates for the current iteration and stress for the previous iteration.</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p><strong>Here is the script to reproduce:</strong></p>\n<p>&nbsp;</p>\n<p>from sklearn import manifold</p>\n<p>from sklearn.metrics.pairwise import euclidean_distances</p>\n<p>import pandas as pd</p>\n<p>&nbsp;</p>\n<p>data = [['A',1,5],['B',1,4],['C',1,1],['D',3,3]]</p>\n<p>df = pd.DataFrame(data, columns = ['Name', 'X','Y'])</p>\n<p>&nbsp;</p>\n<p>#Distance matrix</p>\n<p>disparities = euclidean_distances(df[['X','Y']])</p>\n<p>mds = manifold.MDS(n_components=2, dissimilarity=\"precomputed\", random_state=42,&nbsp; metric = True)</p>\n<p>results = mds.fit(disparities)</p>\n<p>coords = results.embedding_</p>\n<p>stress = results.stress_</p>\n<p>print ('returned stress=',stress)</p>\n<p>&nbsp;</p>\n<p># Calculate Stress by hand</p>\n<p>dis = euclidean_distances(coords)</p>\n<p>real_stress = ((dis.ravel() - disparities.ravel()) ** 2).sum() / 2</p>\n<p>print('real stress =',real_stress)</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p><strong>Versions:</strong></p>\n<p>System:</p>\n<p>&nbsp;&nbsp;&nbsp; python: 3.7.6 (default, Dec 30 2019, 19:38:36)&nbsp; [Clang 10.0.0 (clang-1000.11.45.5)]</p>\n<p>executable: /usr/local/opt/python/bin/python3.7</p>\n<p>&nbsp;&nbsp; machine: Darwin-17.7.0-x86_64-i386-64bit</p>\n<p>&nbsp;</p>\n<p>Python deps:</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pip: 19.3.1</p>\n<p>setuptools: 42.0.2</p>\n<p>&nbsp;&nbsp; sklearn: 0.21.3</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp; numpy: 1.17.4</p>\n<p>&nbsp;&nbsp;&nbsp;&nbsp; scipy: 1.3.2</p>\n<p>&nbsp;&nbsp;&nbsp; Cython: 0.29.15</p>\n<p>&nbsp;&nbsp;&nbsp; pandas: 1.0.1</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n<p>&nbsp;</p>\n\n\nEDITED by @ogrisel to strip the HTML of the reproducer and use markdown fomatting instead:\n\n```python\nfrom sklearn import manifold\nfrom sklearn.metrics.pairwise import euclidean_distances\nimport pandas as pd\n\ndata = [['A',1,5],['B',1,4],['C',1,1],['D',3,3]]\ndf = pd.DataFrame(data, columns = ['Name', 'X','Y'])\n\n# Distance matrix\ndisparities = euclidean_distances(df[['X','Y']])\n\n# Fit MDS on precomputed distances\nmds = manifold.MDS(\n    n_components=2,\n    dissimilarity=\"precomputed\",\n    random_state=42,\n    metric=True,\n)\n\n# Print Stress computed by scikit-learn\nresults = mds.fit(disparities)\ncoords = results.embedding_\nstress = results.stress_\nprint ('returned stress=',stress)\n\n# Calculate Stress by hand\ndis = euclidean_distances(coords)\nreal_stress = ((dis.ravel() - disparities.ravel()) ** 2).sum() / 2\nprint('real stress =',real_stress)\n```",
  "pr_number": 30514,
  "pr_title": "FIX Fix multiple severe bugs in non-metric MDS",
  "gold_patch": "diff --git a/doc/modules/manifold.rst b/doc/modules/manifold.rst\nindex d9c65bcaf7bdb..19694ff0cb422 100644\n--- a/doc/modules/manifold.rst\n+++ b/doc/modules/manifold.rst\n@@ -418,20 +418,19 @@ Multi-dimensional Scaling (MDS)\n representation of the data in which the distances respect well the\n distances in the original high-dimensional space.\n \n-In general, :class:`MDS` is a technique used for analyzing similarity or\n-dissimilarity data. It attempts to model similarity or dissimilarity data as\n-distances in a geometric space. The data can be ratings of similarity between\n+In general, :class:`MDS` is a technique used for analyzing\n+dissimilarity data. It attempts to model dissimilarities as\n+distances in a Euclidean space. The data can be ratings of dissimilarity between\n objects, interaction frequencies of molecules, or trade indices between\n countries.\n \n There exist two types of MDS algorithm: metric and non-metric. In\n-scikit-learn, the class :class:`MDS` implements both. In Metric MDS, the input\n-similarity matrix arises from a metric (and thus respects the triangular\n-inequality), the distances between output two points are then set to be as\n-close as possible to the similarity or dissimilarity data. In the non-metric\n-version, the algorithms will try to preserve the order of the distances, and\n+scikit-learn, the class :class:`MDS` implements both. In metric MDS,\n+the distances in the embedding space are set as\n+close as possible to the dissimilarity data. In the non-metric\n+version, the algorithm will try to preserve the order of the distances, and\n hence seek for a monotonic relationship between the distances in the embedded\n-space and the similarities/dissimilarities.\n+space and the input dissimilarities.\n \n .. figure:: ../auto_examples/manifold/images/sphx_glr_plot_lle_digits_010.png\n    :target: ../auto_examples/manifold/plot_lle_digits.html\n@@ -439,46 +438,45 @@ space and the similarities/dissimilarities.\n    :scale: 50\n \n \n-Let :math:`S` be the similarity matrix, and :math:`X` the coordinates of the\n-:math:`n` input points. Disparities :math:`\\hat{d}_{ij}` are transformation of\n-the similarities chosen in some optimal ways. The objective, called the\n-stress, is then defined by :math:`\\sum_{i < j} d_{ij}(X) - \\hat{d}_{ij}(X)`\n+Let :math:`\\delta_{ij}` be the dissimilarity matrix between the\n+:math:`n` input points (possibly arising as some pairwise distances\n+:math:`d_{ij}(X)` between the coordinates :math:`X` of the input points).\n+Disparities :math:`\\hat{d}_{ij} = f(\\delta_{ij})` are some transformation of\n+the dissimilarities. The MDS objective, called the raw stress, is then\n+defined by :math:`\\sum_{i < j} (\\hat{d}_{ij} - d_{ij}(Z))^2`,\n+where :math:`d_{ij}(Z)` are the pairwise distances between the\n+coordinates :math:`Z` of the embedded points.\n \n \n .. dropdown:: Metric MDS\n \n-  The simplest metric :class:`MDS` model, called *absolute MDS*, disparities are defined by\n-  :math:`\\hat{d}_{ij} = S_{ij}`. With absolute MDS, the value :math:`S_{ij}`\n-  should then correspond exactly to the distance between point :math:`i` and\n-  :math:`j` in the embedding point.\n-\n-  Most commonly, disparities are set to :math:`\\hat{d}_{ij} = b S_{ij}`.\n+  In the metric :class:`MDS` model (sometimes also called *absolute MDS*),\n+  disparities are simply equal to the input dissimilarities\n+  :math:`\\hat{d}_{ij} = \\delta_{ij}`.\n \n .. dropdown:: Nonmetric MDS\n \n   Non metric :class:`MDS` focuses on the ordination of the data. If\n-  :math:`S_{ij} > S_{jk}`, then the embedding should enforce :math:`d_{ij} <\n-  d_{jk}`. For this reason, we discuss it in terms of dissimilarities\n-  (:math:`\\delta_{ij}`) instead of similarities (:math:`S_{ij}`). Note that\n-  dissimilarities can easily be obtained from similarities through a simple\n-  transform, e.g. :math:`\\delta_{ij}=c_1-c_2 S_{ij}` for some real constants\n-  :math:`c_1, c_2`. A simple algorithm to enforce proper ordination is to use a\n-  monotonic regression of :math:`d_{ij}` on :math:`\\delta_{ij}`, yielding\n-  disparities :math:`\\hat{d}_{ij}` in the same order as :math:`\\delta_{ij}`.\n-\n-  A trivial solution to this problem is to set all the points on the origin. In\n-  order to avoid that, the disparities :math:`\\hat{d}_{ij}` are normalized. Note\n-  that since we only care about relative ordering, our objective should be\n+  :math:`\\delta_{ij} > \\delta_{kl}`, then the embedding\n+  seeks to enforce :math:`d_{ij}(Z) > d_{kl}(Z)`. A simple algorithm\n+  to enforce proper ordination is to use an\n+  isotonic regression of :math:`d_{ij}(Z)` on :math:`\\delta_{ij}`, yielding\n+  disparities :math:`\\hat{d}_{ij}` that are a monotonic transformation\n+  of dissimilarities :math:`\\delta_{ij}` and hence having the same ordering.\n+  This is done repeatedly after every step of the optimization algorithm.\n+  In order to avoid the trivial solution where all embedding points are\n+  overlapping, the disparities :math:`\\hat{d}_{ij}` are normalized.\n+\n+  Note that since we only care about relative ordering, our objective should be\n   invariant to simple translation and scaling, however the stress used in metric\n-  MDS is sensitive to scaling. To address this, non-metric MDS may use a\n-  normalized stress, known as Stress-1 defined as\n+  MDS is sensitive to scaling. To address this, non-metric MDS returns\n+  normalized stress, also known as Stress-1, defined as\n \n   .. math::\n-      \\sqrt{\\frac{\\sum_{i < j} (d_{ij} - \\hat{d}_{ij})^2}{\\sum_{i < j} d_{ij}^2}}.\n+      \\sqrt{\\frac{\\sum_{i < j} (\\hat{d}_{ij} - d_{ij}(Z))^2}{\\sum_{i < j}\n+      d_{ij}(Z)^2}}.\n \n-  The use of normalized Stress-1 can be enabled by setting `normalized_stress=True`,\n-  however it is only compatible with the non-metric MDS problem and will be ignored\n-  in the metric case.\n+  Normalized Stress-1 is returned if `normalized_stress=True`.\n \n   .. figure:: ../auto_examples/manifold/images/sphx_glr_plot_mds_001.png\n     :target: ../auto_examples/manifold/plot_mds.html\n@@ -487,6 +485,10 @@ stress, is then defined by :math:`\\sum_{i < j} d_{ij}(X) - \\hat{d}_{ij}(X)`\n \n .. rubric:: References\n \n+* `\"More on Multidimensional Scaling and Unfolding in R: smacof Version 2\"\n+  <https://www.jstatsoft.org/article/view/v102i10>`_\n+  Mair P, Groenen P., de Leeuw J. Journal of Statistical Software (2022)\n+\n * `\"Modern Multidimensional Scaling - Theory and Applications\"\n   <https://www.springer.com/fr/book/9780387251509>`_\n   Borg, I.; Groenen P. Springer Series in Statistics (1997)\ndiff --git a/doc/whats_new/upcoming_changes/sklearn.manifold/30514.fix.rst b/doc/whats_new/upcoming_changes/sklearn.manifold/30514.fix.rst\nnew file mode 100644\nindex 0000000000000..7f4e4104446dc\n--- /dev/null\n+++ b/doc/whats_new/upcoming_changes/sklearn.manifold/30514.fix.rst\n@@ -0,0 +1,4 @@\n+- :class:`manifold.MDS` now correctly handles non-metric MDS. Furthermore,\n+  the returned stress value now corresponds to the returned embedding and\n+  normalized stress is now allowed for metric MDS.\n+  By :user:`Dmitry Kobak <dkobak>`\ndiff --git a/examples/manifold/plot_mds.py b/examples/manifold/plot_mds.py\nindex c572e792ac71b..afea676b245a8 100644\n--- a/examples/manifold/plot_mds.py\n+++ b/examples/manifold/plot_mds.py\n@@ -21,31 +21,34 @@\n from sklearn.decomposition import PCA\n from sklearn.metrics import euclidean_distances\n \n+# Generate the data\n EPSILON = np.finfo(np.float32).eps\n n_samples = 20\n-seed = np.random.RandomState(seed=3)\n-X_true = seed.randint(0, 20, 2 * n_samples).astype(float)\n+rng = np.random.RandomState(seed=3)\n+X_true = rng.randint(0, 20, 2 * n_samples).astype(float)\n X_true = X_true.reshape((n_samples, 2))\n+\n # Center the data\n X_true -= X_true.mean()\n \n-similarities = euclidean_distances(X_true)\n+# Compute pairwise Euclidean distances\n+distances = euclidean_distances(X_true)\n \n-# Add noise to the similarities\n-noise = np.random.rand(n_samples, n_samples)\n+# Add noise to the distances\n+noise = rng.rand(n_samples, n_samples)\n noise = noise + noise.T\n-noise[np.arange(noise.shape[0]), np.arange(noise.shape[0])] = 0\n-similarities += noise\n+np.fill_diagonal(noise, 0)\n+distances += noise\n \n mds = manifold.MDS(\n     n_components=2,\n     max_iter=3000,\n     eps=1e-9,\n-    random_state=seed,\n+    random_state=42,\n     dissimilarity=\"precomputed\",\n     n_jobs=1,\n )\n-pos = mds.fit(similarities).embedding_\n+X_mds = mds.fit(distances).embedding_\n \n nmds = manifold.MDS(\n     n_components=2,\n@@ -53,47 +56,52 @@\n     max_iter=3000,\n     eps=1e-12,\n     dissimilarity=\"precomputed\",\n-    random_state=seed,\n+    random_state=42,\n     n_jobs=1,\n     n_init=1,\n )\n-npos = nmds.fit_transform(similarities, init=pos)\n+X_nmds = nmds.fit_transform(distances)\n \n # Rescale the data\n-pos *= np.sqrt((X_true**2).sum()) / np.sqrt((pos**2).sum())\n-npos *= np.sqrt((X_true**2).sum()) / np.sqrt((npos**2).sum())\n+X_mds *= np.sqrt((X_true**2).sum()) / np.sqrt((X_mds**2).sum())\n+X_nmds *= np.sqrt((X_true**2).sum()) / np.sqrt((X_nmds**2).sum())\n \n # Rotate the data\n-clf = PCA(n_components=2)\n-X_true = clf.fit_transform(X_true)\n-\n-pos = clf.fit_transform(pos)\n-\n-npos = clf.fit_transform(npos)\n+pca = PCA(n_components=2)\n+X_true = pca.fit_transform(X_true)\n+X_mds = pca.fit_transform(X_mds)\n+X_nmds = pca.fit_transform(X_nmds)\n+\n+# Align the sign of PCs\n+for i in [0, 1]:\n+    if np.corrcoef(X_mds[:, i], X_true[:, i])[0, 1] < 0:\n+        X_mds[:, i] *= -1\n+    if np.corrcoef(X_nmds[:, i], X_true[:, i])[0, 1] < 0:\n+        X_nmds[:, i] *= -1\n \n fig = plt.figure(1)\n ax = plt.axes([0.0, 0.0, 1.0, 1.0])\n \n s = 100\n plt.scatter(X_true[:, 0], X_true[:, 1], color=\"navy\", s=s, lw=0, label=\"True Position\")\n-plt.scatter(pos[:, 0], pos[:, 1], color=\"turquoise\", s=s, lw=0, label=\"MDS\")\n-plt.scatter(npos[:, 0], npos[:, 1], color=\"darkorange\", s=s, lw=0, label=\"NMDS\")\n+plt.scatter(X_mds[:, 0], X_mds[:, 1], color=\"turquoise\", s=s, lw=0, label=\"MDS\")\n+plt.scatter(X_nmds[:, 0], X_nmds[:, 1], color=\"darkorange\", s=s, lw=0, label=\"NMDS\")\n plt.legend(scatterpoints=1, loc=\"best\", shadow=False)\n \n-similarities = similarities.max() / (similarities + EPSILON) * 100\n-np.fill_diagonal(similarities, 0)\n # Plot the edges\n-start_idx, end_idx = np.where(pos)\n+start_idx, end_idx = np.where(X_mds)\n # a sequence of (*line0*, *line1*, *line2*), where::\n #            linen = (x0, y0), (x1, y1), ... (xm, ym)\n segments = [\n-    [X_true[i, :], X_true[j, :]] for i in range(len(pos)) for j in range(len(pos))\n+    [X_true[i, :], X_true[j, :]] for i in range(len(X_true)) for j in range(len(X_true))\n ]\n-values = np.abs(similarities)\n+edges = distances.max() / (distances + EPSILON) * 100\n+np.fill_diagonal(edges, 0)\n+edges = np.abs(edges)\n lc = LineCollection(\n-    segments, zorder=0, cmap=plt.cm.Blues, norm=plt.Normalize(0, values.max())\n+    segments, zorder=0, cmap=plt.cm.Blues, norm=plt.Normalize(0, edges.max())\n )\n-lc.set_array(similarities.flatten())\n+lc.set_array(edges.flatten())\n lc.set_linewidths(np.full(len(segments), 0.5))\n ax.add_collection(lc)\n \ndiff --git a/sklearn/manifold/_mds.py b/sklearn/manifold/_mds.py\nindex dc9f88b502da5..07d492bdcd34d 100644\n--- a/sklearn/manifold/_mds.py\n+++ b/sklearn/manifold/_mds.py\n@@ -70,12 +70,14 @@ def _smacof_single(\n         See :term:`Glossary <random_state>`.\n \n     normalized_stress : bool, default=False\n-        Whether use and return normed stress value (Stress-1) instead of raw\n-        stress calculated by default. Only supported in non-metric MDS. The\n-        caller must ensure that if `normalized_stress=True` then `metric=False`\n+        Whether use and return normalized stress value (Stress-1) instead of raw\n+        stress.\n \n         .. versionadded:: 1.2\n \n+        .. versionchanged:: 1.7\n+           Normalized stress is now supported for metric MDS as well.\n+\n     Returns\n     -------\n     X : ndarray of shape (n_samples, n_components)\n@@ -84,7 +86,7 @@ def _smacof_single(\n     stress : float\n         The final value of the stress (sum of squared distance of the\n         disparities and the distances for all constrained points).\n-        If `normalized_stress=True`, and `metric=False` returns Stress-1.\n+        If `normalized_stress=True`, returns Stress-1.\n         A value of 0 indicates \"perfect\" fit, 0.025 excellent, 0.05 good,\n         0.1 fair, and 0.2 poor [1]_.\n \n@@ -107,8 +109,8 @@ def _smacof_single(\n     n_samples = dissimilarities.shape[0]\n     random_state = check_random_state(random_state)\n \n-    sim_flat = ((1 - np.tri(n_samples)) * dissimilarities).ravel()\n-    sim_flat_w = sim_flat[sim_flat != 0]\n+    dissimilarities_flat = ((1 - np.tri(n_samples)) * dissimilarities).ravel()\n+    dissimilarities_flat_w = dissimilarities_flat[dissimilarities_flat != 0]\n     if init is None:\n         # Randomly choose initial configuration\n         X = random_state.uniform(size=n_samples * n_components)\n@@ -121,49 +123,63 @@ def _smacof_single(\n                 \"init matrix should be of shape (%d, %d)\" % (n_samples, n_components)\n             )\n         X = init\n+    distances = euclidean_distances(X)\n+\n+    # Out of bounds condition cannot happen because we are transforming\n+    # the training set here, but does sometimes get triggered in\n+    # practice due to machine precision issues. Hence \"clip\".\n+    ir = IsotonicRegression(out_of_bounds=\"clip\")\n \n     old_stress = None\n-    ir = IsotonicRegression()\n     for it in range(max_iter):\n         # Compute distance and monotonic regression\n-        dis = euclidean_distances(X)\n-\n         if metric:\n             disparities = dissimilarities\n         else:\n-            dis_flat = dis.ravel()\n+            distances_flat = distances.ravel()\n             # dissimilarities with 0 are considered as missing values\n-            dis_flat_w = dis_flat[sim_flat != 0]\n-\n-            # Compute the disparities using a monotonic regression\n-            disparities_flat = ir.fit_transform(sim_flat_w, dis_flat_w)\n-            disparities = dis_flat.copy()\n-            disparities[sim_flat != 0] = disparities_flat\n+            distances_flat_w = distances_flat[dissimilarities_flat != 0]\n+\n+            # Compute the disparities using isotonic regression.\n+            # For the first SMACOF iteration, use scaled original dissimilarities.\n+            # (This choice follows the R implementation described in this paper:\n+            # https://www.jstatsoft.org/article/view/v102i10)\n+            if it < 1:\n+                disparities_flat = dissimilarities_flat_w\n+            else:\n+                disparities_flat = ir.fit_transform(\n+                    dissimilarities_flat_w, distances_flat_w\n+                )\n+            disparities = np.zeros_like(distances_flat)\n+            disparities[dissimilarities_flat != 0] = disparities_flat\n             disparities = disparities.reshape((n_samples, n_samples))\n             disparities *= np.sqrt(\n                 (n_samples * (n_samples - 1) / 2) / (disparities**2).sum()\n             )\n+            disparities = disparities + disparities.T\n \n-        # Compute stress\n-        stress = ((dis.ravel() - disparities.ravel()) ** 2).sum() / 2\n-        if normalized_stress:\n-            stress = np.sqrt(stress / ((disparities.ravel() ** 2).sum() / 2))\n         # Update X using the Guttman transform\n-        dis[dis == 0] = 1e-5\n-        ratio = disparities / dis\n+        distances[distances == 0] = 1e-5\n+        ratio = disparities / distances\n         B = -ratio\n         B[np.arange(len(B)), np.arange(len(B))] += ratio.sum(axis=1)\n         X = 1.0 / n_samples * np.dot(B, X)\n \n-        dis = np.sqrt((X**2).sum(axis=1)).sum()\n-        if verbose >= 2:\n-            print(\"it: %d, stress %s\" % (it, stress))\n+        # Compute stress\n+        distances = euclidean_distances(X)\n+        stress = ((distances.ravel() - disparities.ravel()) ** 2).sum() / 2\n+        if normalized_stress:\n+            stress = np.sqrt(stress / ((disparities.ravel() ** 2).sum() / 2))\n+\n+        normalization = np.sqrt((X**2).sum(axis=1)).sum()\n+        if verbose >= 2:  # pragma: no cover\n+            print(f\"Iteration {it}, stress {stress:.4f}\")\n         if old_stress is not None:\n-            if (old_stress - stress / dis) < eps:\n-                if verbose:\n-                    print(\"breaking at iteration %d with stress %s\" % (it, stress))\n+            if (old_stress - stress / normalization) < eps:\n+                if verbose:  # pragma: no cover\n+                    print(\"Convergence criterion reached.\")\n                 break\n-        old_stress = stress / dis\n+        old_stress = stress / normalization\n \n     return X, stress, it + 1\n \n@@ -275,14 +291,18 @@ def smacof(\n         Whether or not to return the number of iterations.\n \n     normalized_stress : bool or \"auto\" default=\"auto\"\n-        Whether use and return normed stress value (Stress-1) instead of raw\n-        stress calculated by default. Only supported in non-metric MDS.\n+        Whether to return normalized stress value (Stress-1) instead of raw\n+        stress. By default, metric MDS returns raw stress while non-metric MDS\n+        returns normalized stress.\n \n         .. versionadded:: 1.2\n \n         .. versionchanged:: 1.4\n            The default value changed from `False` to `\"auto\"` in version 1.4.\n \n+        .. versionchanged:: 1.7\n+           Normalized stress is now supported for metric MDS as well.\n+\n     Returns\n     -------\n     X : ndarray of shape (n_samples, n_components)\n@@ -291,7 +311,7 @@ def smacof(\n     stress : float\n         The final value of the stress (sum of squared distance of the\n         disparities and the distances for all constrained points).\n-        If `normalized_stress=True`, and `metric=False` returns Stress-1.\n+        If `normalized_stress=True`, returns Stress-1.\n         A value of 0 indicates \"perfect\" fit, 0.025 excellent, 0.05 good,\n         0.1 fair, and 0.2 poor [1]_.\n \n@@ -318,12 +338,12 @@ def smacof(\n     >>> X = np.array([[0, 1, 2], [1, 0, 3],[2, 3, 0]])\n     >>> dissimilarities = euclidean_distances(X)\n     >>> mds_result, stress = smacof(dissimilarities, n_components=2, random_state=42)\n-    >>> mds_result\n-    array([[ 0.05... -1.07... ],\n-           [ 1.74..., -0.75...],\n-           [-1.79...,  1.83...]])\n-    >>> stress\n-    np.float64(0.0012...)\n+    >>> np.round(mds_result, 5)\n+    array([[ 0.05352, -1.07253],\n+           [ 1.74231, -0.75675],\n+           [-1.79583,  1.82928]])\n+    >>> np.round(stress, 5).item()\n+    0.00128\n     \"\"\"\n \n     dissimilarities = check_array(dissimilarities)\n@@ -332,11 +352,6 @@ def smacof(\n     if normalized_stress == \"auto\":\n         normalized_stress = not metric\n \n-    if normalized_stress and metric:\n-        raise ValueError(\n-            \"Normalized stress is not supported for metric MDS. Either set\"\n-            \" `normalized_stress=False` or use `metric=False`.\"\n-        )\n     if hasattr(init, \"__array__\"):\n         init = np.asarray(init).copy()\n         if not n_init == 1:\n@@ -449,14 +464,18 @@ class MDS(BaseEstimator):\n             ``fit_transform``.\n \n     normalized_stress : bool or \"auto\" default=\"auto\"\n-        Whether use and return normed stress value (Stress-1) instead of raw\n-        stress calculated by default. Only supported in non-metric MDS.\n+        Whether use and return normalized stress value (Stress-1) instead of raw\n+        stress. By default, metric MDS uses raw stress while non-metric MDS uses\n+        normalized stress.\n \n         .. versionadded:: 1.2\n \n         .. versionchanged:: 1.4\n            The default value changed from `False` to `\"auto\"` in version 1.4.\n \n+        .. versionchanged:: 1.7\n+           Normalized stress is now supported for metric MDS as well.\n+\n     Attributes\n     ----------\n     embedding_ : ndarray of shape (n_samples, n_components)\n@@ -465,7 +484,7 @@ class MDS(BaseEstimator):\n     stress_ : float\n         The final value of the stress (sum of squared distance of the\n         disparities and the distances for all constrained points).\n-        If `normalized_stress=True`, and `metric=False` returns Stress-1.\n+        If `normalized_stress=True`, returns Stress-1.\n         A value of 0 indicates \"perfect\" fit, 0.025 excellent, 0.05 good,\n         0.1 fair, and 0.2 poor [1]_.\n \ndiff --git a/sklearn/manifold/tests/test_mds.py b/sklearn/manifold/tests/test_mds.py\nindex 2d286ef0942bf..b34f030b79895 100644\n--- a/sklearn/manifold/tests/test_mds.py\n+++ b/sklearn/manifold/tests/test_mds.py\n@@ -4,6 +4,7 @@\n import pytest\n from numpy.testing import assert_allclose, assert_array_almost_equal\n \n+from sklearn.datasets import load_digits\n from sklearn.manifold import _mds as mds\n from sklearn.metrics import euclidean_distances\n \n@@ -20,6 +21,74 @@ def test_smacof():\n     assert_array_almost_equal(X, X_true, decimal=3)\n \n \n+def test_nonmetric_lower_normalized_stress():\n+    # Testing that nonmetric MDS results in lower normalized stess compared\n+    # compared to metric MDS (non-regression test for issue 27028)\n+    sim = np.array([[0, 5, 3, 4], [5, 0, 2, 2], [3, 2, 0, 1], [4, 2, 1, 0]])\n+    Z = np.array([[-0.266, -0.539], [0.451, 0.252], [0.016, -0.238], [-0.200, 0.524]])\n+\n+    _, stress1 = mds.smacof(\n+        sim, init=Z, n_components=2, max_iter=1000, n_init=1, normalized_stress=True\n+    )\n+\n+    _, stress2 = mds.smacof(\n+        sim,\n+        init=Z,\n+        n_components=2,\n+        max_iter=1000,\n+        n_init=1,\n+        normalized_stress=True,\n+        metric=False,\n+    )\n+    assert stress1 > stress2\n+\n+\n+def test_nonmetric_mds_optimization():\n+    # Test that stress is decreasing during nonmetric MDS optimization\n+    # (non-regression test for issue 27028)\n+    X, _ = load_digits(return_X_y=True)\n+    rng = np.random.default_rng(seed=42)\n+    ind_subset = rng.choice(len(X), size=200, replace=False)\n+    X = X[ind_subset]\n+\n+    mds_est = mds.MDS(\n+        n_components=2,\n+        n_init=1,\n+        eps=1e-15,\n+        max_iter=2,\n+        metric=False,\n+        random_state=42,\n+    ).fit(X)\n+    stress_after_2_iter = mds_est.stress_\n+\n+    mds_est = mds.MDS(\n+        n_components=2,\n+        n_init=1,\n+        eps=1e-15,\n+        max_iter=3,\n+        metric=False,\n+        random_state=42,\n+    ).fit(X)\n+    stress_after_3_iter = mds_est.stress_\n+\n+    assert stress_after_2_iter > stress_after_3_iter\n+\n+\n+@pytest.mark.parametrize(\"metric\", [True, False])\n+def test_mds_recovers_true_data(metric):\n+    X = np.array([[1, 1], [1, 4], [1, 5], [3, 3]])\n+    mds_est = mds.MDS(\n+        n_components=2,\n+        n_init=1,\n+        eps=1e-15,\n+        max_iter=1000,\n+        metric=metric,\n+        random_state=42,\n+    ).fit(X)\n+    stress = mds_est.stress_\n+    assert_allclose(stress, 0, atol=1e-10)\n+\n+\n def test_smacof_error():\n     # Not symmetric similarity matrix:\n     sim = np.array([[0, 5, 9, 4], [5, 0, 2, 2], [3, 2, 0, 1], [4, 2, 1, 0]])\n@@ -59,17 +128,6 @@ def test_normed_stress(k):\n     assert_allclose(X1, X2, rtol=1e-5)\n \n \n-def test_normalize_metric_warning():\n-    \"\"\"\n-    Test that a UserWarning is emitted when using normalized stress with\n-    metric-MDS.\n-    \"\"\"\n-    msg = \"Normalized stress is not supported\"\n-    sim = np.array([[0, 5, 3, 4], [5, 0, 2, 2], [3, 2, 0, 1], [4, 2, 1, 0]])\n-    with pytest.raises(ValueError, match=msg):\n-        mds.smacof(sim, metric=True, normalized_stress=True)\n-\n-\n @pytest.mark.parametrize(\"metric\", [True, False])\n def test_normalized_stress_auto(metric, monkeypatch):\n     rng = np.random.RandomState(0)\n@@ -85,3 +143,39 @@ def test_normalized_stress_auto(metric, monkeypatch):\n \n     mds.smacof(dist, metric=metric, normalized_stress=\"auto\", random_state=rng)\n     assert mock.call_args[1][\"normalized_stress\"] != metric\n+\n+\n+def test_isotonic_outofbounds():\n+    # This particular configuration can trigger out of bounds error\n+    # in the isotonic regression (non-regression test for issue 26999)\n+    dis = np.array(\n+        [\n+            [0.0, 1.732050807568877, 1.7320508075688772],\n+            [1.732050807568877, 0.0, 6.661338147750939e-16],\n+            [1.7320508075688772, 6.661338147750939e-16, 0.0],\n+        ]\n+    )\n+    init = np.array(\n+        [\n+            [0.08665881585055124, 0.7939114643387546],\n+            [0.9959834154297658, 0.7555546025640025],\n+            [0.8766008278401566, 0.4227358815811242],\n+        ]\n+    )\n+    mds.smacof(dis, init=init, metric=False, n_init=1)\n+\n+\n+def test_returned_stress():\n+    # Test that the final stress corresponds to the final embedding\n+    # (non-regression test for issue 16846)\n+    X = np.array([[1, 1], [1, 4], [1, 5], [3, 3]])\n+    D = euclidean_distances(X)\n+\n+    mds_est = mds.MDS(n_components=2, random_state=42).fit(X)\n+    Z = mds_est.embedding_\n+    stress = mds_est.stress_\n+\n+    D_mds = euclidean_distances(Z)\n+    stress_Z = ((D_mds.ravel() - D.ravel()) ** 2).sum() / 2\n+\n+    assert_allclose(stress, stress_Z)\n",
  "fail_to_pass": [
    "test_nonmetric_lower_normalized_stress",
    "test_nonmetric_mds_optimization",
    "test_mds_recovers_true_data",
    "test_isotonic_outofbounds",
    "test_returned_stress"
  ],
  "pass_to_pass": [],
  "relevant_files": [
    "examples/manifold/plot_mds.py",
    "sklearn/manifold/_mds.py",
    "sklearn/manifold/tests/test_mds.py"
  ],
  "difficulty": "hard",
  "created_at": "2024-12-20T11:37:58Z",
  "pr_url": "https://github.com/scikit-learn/scikit-learn/pull/30514",
  "issue_url": "https://github.com/scikit-learn/scikit-learn/issues/16846"
}