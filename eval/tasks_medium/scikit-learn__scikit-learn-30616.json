{
  "id": "scikit-learn__scikit-learn-30616",
  "repo": "scikit-learn/scikit-learn",
  "base_commit": "eec4449e2b36f051baabfb6d20c097fc9e83bf65",
  "issue_number": 30467,
  "issue_title": "API Deprecate n_alphas in LinearModelCV",
  "issue_body": "In LassoCV, ElasticNetCV, ... we have two parameters, `alphas` and `n_alphas`, that have the same purpose, i.e. determine the alpha values to test.\r\n\r\nI'd be in favor of deprecating `n_alphas` and make `alphas` accept either an int or an array-like, filling both roles.\r\n\r\nI chose to keep `alphas` and not the other because `RidgeCV` has `alphas` and no `n_alphas` (although `alphas` can't be an int there, maybe an enhancement to make ?), and the most recent param of this kind, `threshold` in `TunedThresholdClassifierCV`, follows this naming pattern and fills both roles.",
  "pr_number": 30616,
  "pr_title": "Fixes API Deprecate n_alphas in LinearModelCV",
  "gold_patch": "diff --git a/doc/whats_new/upcoming_changes/sklearn.linear_model/30616.api.rst b/doc/whats_new/upcoming_changes/sklearn.linear_model/30616.api.rst\nnew file mode 100644\nindex 0000000000000..8d0a032fd284f\n--- /dev/null\n+++ b/doc/whats_new/upcoming_changes/sklearn.linear_model/30616.api.rst\n@@ -0,0 +1,9 @@\n+The parameter `n_alphas` has been deprecated in the following classes:\n+:class:`linear_model.ElasticNetCV` and :class:`linear_model.LassoCV`\n+and :class:`linear_model.MultiTaskElasticNetCV` \n+and :class:`linear_model.MultiTaskLassoCV`, and will be removed in 1.9. The parameter\n+`alphas` now supports both integers and array-likes, removing the need for `n_alphas`.\n+From now on, only `alphas` should be set to either indicate the number of alphas to\n+automatically generate (int) or to provide a list of alphas (array-like) to test along\n+the regularization path.\n+By :user:`Siddharth Bansal <KANNAHWORLD >`.\ndiff --git a/sklearn/linear_model/_coordinate_descent.py b/sklearn/linear_model/_coordinate_descent.py\nindex 0d196ee2d23eb..4c12a73ead300 100644\n--- a/sklearn/linear_model/_coordinate_descent.py\n+++ b/sklearn/linear_model/_coordinate_descent.py\n@@ -23,7 +23,7 @@\n     _raise_for_params,\n     get_routing_for_object,\n )\n-from ..utils._param_validation import Interval, StrOptions, validate_params\n+from ..utils._param_validation import Hidden, Interval, StrOptions, validate_params\n from ..utils.extmath import safe_sparse_dot\n from ..utils.metadata_routing import (\n     _routing_enabled,\n@@ -1493,8 +1493,17 @@ class LinearModelCV(MultiOutputMixin, LinearModel, ABC):\n \n     _parameter_constraints: dict = {\n         \"eps\": [Interval(Real, 0, None, closed=\"neither\")],\n-        \"n_alphas\": [Interval(Integral, 1, None, closed=\"left\")],\n-        \"alphas\": [\"array-like\", None],\n+        \"n_alphas\": [\n+            Interval(Integral, 1, None, closed=\"left\"),\n+            Hidden(StrOptions({\"deprecated\"})),\n+        ],\n+        # TODO(1.9): remove \"warn\" and None options.\n+        \"alphas\": [\n+            Interval(Integral, 1, None, closed=\"left\"),\n+            \"array-like\",\n+            None,\n+            Hidden(StrOptions({\"warn\"})),\n+        ],\n         \"fit_intercept\": [\"boolean\"],\n         \"precompute\": [StrOptions({\"auto\"}), \"array-like\", \"boolean\"],\n         \"max_iter\": [Interval(Integral, 1, None, closed=\"left\")],\n@@ -1512,8 +1521,8 @@ class LinearModelCV(MultiOutputMixin, LinearModel, ABC):\n     def __init__(\n         self,\n         eps=1e-3,\n-        n_alphas=100,\n-        alphas=None,\n+        n_alphas=\"deprecated\",\n+        alphas=\"warn\",\n         fit_intercept=True,\n         precompute=\"auto\",\n         max_iter=1000,\n@@ -1595,6 +1604,40 @@ def fit(self, X, y, sample_weight=None, **params):\n         \"\"\"\n         _raise_for_params(params, self, \"fit\")\n \n+        # TODO(1.9): remove n_alphas and alphas={\"warn\", None}; set alphas=100 by\n+        # default. Remove these deprecations messages and use self.alphas directly\n+        # instead of self._alphas.\n+        if self.n_alphas == \"deprecated\":\n+            self._alphas = 100\n+        else:\n+            warnings.warn(\n+                \"'n_alphas' was deprecated in 1.7 and will be removed in 1.9. \"\n+                \"'alphas' now accepts an integer value which removes the need to pass \"\n+                \"'n_alphas'. The default value of 'alphas' will change from None to \"\n+                \"100 in 1.9. Pass an explicit value to 'alphas' and leave 'n_alphas' \"\n+                \"to its default value to silence this warning.\",\n+                FutureWarning,\n+            )\n+            self._alphas = self.n_alphas\n+\n+        if isinstance(self.alphas, str) and self.alphas == \"warn\":\n+            # - If self.n_alphas == \"deprecated\", both are left to their default values\n+            #   so we don't warn since the future default behavior will be the same as\n+            #   the current default behavior.\n+            # - If self.n_alphas != \"deprecated\", then we already warned about it\n+            #   and the warning message mentions the future self.alphas default, so\n+            #   no need to warn a second time.\n+            pass\n+        elif self.alphas is None:\n+            warnings.warn(\n+                \"'alphas=None' is deprecated and will be removed in 1.9, at which \"\n+                \"point the default value will be set to 100. Set 'alphas=100' \"\n+                \"to silence this warning.\",\n+                FutureWarning,\n+            )\n+        else:\n+            self._alphas = self.alphas\n+\n         # This makes sure that there is no duplication in memory.\n         # Dealing right with copy_X is important in the following:\n         # Multiple functions touch X and subsamples of X and can induce a\n@@ -1692,7 +1735,6 @@ def fit(self, X, y, sample_weight=None, **params):\n         path_params.pop(\"cv\", None)\n         path_params.pop(\"n_jobs\", None)\n \n-        alphas = self.alphas\n         n_l1_ratio = len(l1_ratios)\n \n         check_scalar_alpha = partial(\n@@ -1702,7 +1744,7 @@ def fit(self, X, y, sample_weight=None, **params):\n             include_boundaries=\"left\",\n         )\n \n-        if alphas is None:\n+        if isinstance(self._alphas, Integral):\n             alphas = [\n                 _alpha_grid(\n                     X,\n@@ -1710,7 +1752,7 @@ def fit(self, X, y, sample_weight=None, **params):\n                     l1_ratio=l1_ratio,\n                     fit_intercept=self.fit_intercept,\n                     eps=self.eps,\n-                    n_alphas=self.n_alphas,\n+                    n_alphas=self._alphas,\n                     copy_X=self.copy_X,\n                     sample_weight=sample_weight,\n                 )\n@@ -1718,10 +1760,10 @@ def fit(self, X, y, sample_weight=None, **params):\n             ]\n         else:\n             # Making sure alphas entries are scalars.\n-            for index, alpha in enumerate(alphas):\n+            for index, alpha in enumerate(self._alphas):\n                 check_scalar_alpha(alpha, f\"alphas[{index}]\")\n             # Making sure alphas is properly ordered.\n-            alphas = np.tile(np.sort(alphas)[::-1], (n_l1_ratio, 1))\n+            alphas = np.tile(np.sort(self._alphas)[::-1], (n_l1_ratio, 1))\n \n         # We want n_alphas to be the number of alphas used for each l1_ratio.\n         n_alphas = len(alphas[0])\n@@ -1807,7 +1849,7 @@ def fit(self, X, y, sample_weight=None, **params):\n \n         self.l1_ratio_ = best_l1_ratio\n         self.alpha_ = best_alpha\n-        if self.alphas is None:\n+        if isinstance(self._alphas, Integral):\n             self.alphas_ = np.asarray(alphas)\n             if n_l1_ratio == 1:\n                 self.alphas_ = self.alphas_[0]\n@@ -1897,9 +1939,22 @@ class LassoCV(RegressorMixin, LinearModelCV):\n     n_alphas : int, default=100\n         Number of alphas along the regularization path.\n \n-    alphas : array-like, default=None\n-        List of alphas where to compute the models.\n-        If ``None`` alphas are set automatically.\n+        .. deprecated:: 1.7\n+            `n_alphas` was deprecated in 1.7 and will be removed in 1.9. Use `alphas`\n+            instead.\n+\n+    alphas : array-like or int, default=None\n+        Values of alphas to test along the regularization path.\n+        If int, `alphas` values are generated automatically.\n+        If array-like, list of alpha values to use.\n+\n+        .. versionchanged:: 1.7\n+            `alphas` accepts an integer value which removes the need to pass\n+            `n_alphas`.\n+\n+        .. deprecated:: 1.7\n+            `alphas=None` was deprecated in 1.7 and will be removed in 1.9, at which\n+            point the default value will be set to 100.\n \n     fit_intercept : bool, default=True\n         Whether to calculate the intercept for this model. If set\n@@ -2049,8 +2104,8 @@ def __init__(\n         self,\n         *,\n         eps=1e-3,\n-        n_alphas=100,\n-        alphas=None,\n+        n_alphas=\"deprecated\",\n+        alphas=\"warn\",\n         fit_intercept=True,\n         precompute=\"auto\",\n         max_iter=1000,\n@@ -2155,9 +2210,22 @@ class ElasticNetCV(RegressorMixin, LinearModelCV):\n     n_alphas : int, default=100\n         Number of alphas along the regularization path, used for each l1_ratio.\n \n-    alphas : array-like, default=None\n-        List of alphas where to compute the models.\n-        If None alphas are set automatically.\n+        .. deprecated:: 1.7\n+            `n_alphas` was deprecated in 1.7 and will be removed in 1.9. Use `alphas`\n+            instead.\n+\n+    alphas : array-like or int, default=None\n+        Values of alphas to test along the regularization path, used for each l1_ratio.\n+        If int, `alphas` values are generated automatically.\n+        If array-like, list of alpha values to use.\n+\n+        .. versionchanged:: 1.7\n+            `alphas` accepts an integer value which removes the need to pass\n+            `n_alphas`.\n+\n+        .. deprecated:: 1.7\n+            `alphas=None` was deprecated in 1.7 and will be removed in 1.9, at which\n+            point the default value will be set to 100.\n \n     fit_intercept : bool, default=True\n         Whether to calculate the intercept for this model. If set\n@@ -2326,8 +2394,8 @@ def __init__(\n         *,\n         l1_ratio=0.5,\n         eps=1e-3,\n-        n_alphas=100,\n-        alphas=None,\n+        n_alphas=\"deprecated\",\n+        alphas=\"warn\",\n         fit_intercept=True,\n         precompute=\"auto\",\n         max_iter=1000,\n@@ -2845,9 +2913,22 @@ class MultiTaskElasticNetCV(RegressorMixin, LinearModelCV):\n     n_alphas : int, default=100\n         Number of alphas along the regularization path.\n \n-    alphas : array-like, default=None\n-        List of alphas where to compute the models.\n-        If not provided, set automatically.\n+        .. deprecated:: 1.7\n+            `n_alphas` was deprecated in 1.7 and will be removed in 1.9. Use `alphas`\n+            instead.\n+\n+    alphas : array-like or int, default=None\n+        Values of alphas to test along the regularization path, used for each l1_ratio.\n+        If int, `alphas` values are generated automatically.\n+        If array-like, list of alpha values to use.\n+\n+        .. versionchanged:: 1.7\n+            `alphas` accepts an integer value which removes the need to pass\n+            `n_alphas`.\n+\n+        .. deprecated:: 1.7\n+            `alphas=None` was deprecated in 1.7 and will be removed in 1.9, at which\n+            point the default value will be set to 100.\n \n     fit_intercept : bool, default=True\n         Whether to calculate the intercept for this model. If set\n@@ -2991,8 +3072,8 @@ def __init__(\n         *,\n         l1_ratio=0.5,\n         eps=1e-3,\n-        n_alphas=100,\n-        alphas=None,\n+        n_alphas=\"deprecated\",\n+        alphas=\"warn\",\n         fit_intercept=True,\n         max_iter=1000,\n         tol=1e-4,\n@@ -3088,9 +3169,22 @@ class MultiTaskLassoCV(RegressorMixin, LinearModelCV):\n     n_alphas : int, default=100\n         Number of alphas along the regularization path.\n \n-    alphas : array-like, default=None\n-        List of alphas where to compute the models.\n-        If not provided, set automatically.\n+        .. deprecated:: 1.7\n+            `n_alphas` was deprecated in 1.7 and will be removed in 1.9. Use `alphas`\n+            instead.\n+\n+    alphas : array-like or int, default=None\n+        Values of alphas to test along the regularization path.\n+        If int, `alphas` values are generated automatically.\n+        If array-like, list of alpha values to use.\n+\n+        .. versionchanged:: 1.7\n+            `alphas` accepts an integer value which removes the need to pass\n+            `n_alphas`.\n+\n+        .. deprecated:: 1.7\n+            `alphas=None` was deprecated in 1.7 and will be removed in 1.9, at which\n+            point the default value will be set to 100.\n \n     fit_intercept : bool, default=True\n         Whether to calculate the intercept for this model. If set\n@@ -3230,8 +3324,8 @@ def __init__(\n         self,\n         *,\n         eps=1e-3,\n-        n_alphas=100,\n-        alphas=None,\n+        n_alphas=\"deprecated\",\n+        alphas=\"warn\",\n         fit_intercept=True,\n         max_iter=1000,\n         tol=1e-4,\ndiff --git a/sklearn/linear_model/tests/test_coordinate_descent.py b/sklearn/linear_model/tests/test_coordinate_descent.py\nindex 2eefe45e068d3..70226210c010d 100644\n--- a/sklearn/linear_model/tests/test_coordinate_descent.py\n+++ b/sklearn/linear_model/tests/test_coordinate_descent.py\n@@ -244,10 +244,10 @@ def build_dataset(n_samples=50, n_features=200, n_informative_features=10, n_tar\n def test_lasso_cv():\n     X, y, X_test, y_test = build_dataset()\n     max_iter = 150\n-    clf = LassoCV(n_alphas=10, eps=1e-3, max_iter=max_iter, cv=3).fit(X, y)\n+    clf = LassoCV(alphas=10, eps=1e-3, max_iter=max_iter, cv=3).fit(X, y)\n     assert_almost_equal(clf.alpha_, 0.056, 2)\n \n-    clf = LassoCV(n_alphas=10, eps=1e-3, max_iter=max_iter, precompute=True, cv=3)\n+    clf = LassoCV(alphas=10, eps=1e-3, max_iter=max_iter, precompute=True, cv=3)\n     clf.fit(X, y)\n     assert_almost_equal(clf.alpha_, 0.056, 2)\n \n@@ -288,13 +288,13 @@ def test_lasso_cv_positive_constraint():\n     max_iter = 500\n \n     # Ensure the unconstrained fit has a negative coefficient\n-    clf_unconstrained = LassoCV(n_alphas=3, eps=1e-1, max_iter=max_iter, cv=2, n_jobs=1)\n+    clf_unconstrained = LassoCV(alphas=3, eps=1e-1, max_iter=max_iter, cv=2, n_jobs=1)\n     clf_unconstrained.fit(X, y)\n     assert min(clf_unconstrained.coef_) < 0\n \n     # On same data, constrained fit has non-negative coefficients\n     clf_constrained = LassoCV(\n-        n_alphas=3, eps=1e-1, max_iter=max_iter, positive=True, cv=2, n_jobs=1\n+        alphas=3, eps=1e-1, max_iter=max_iter, positive=True, cv=2, n_jobs=1\n     )\n     clf_constrained.fit(X, y)\n     assert min(clf_constrained.coef_) >= 0\n@@ -480,7 +480,7 @@ def test_enet_path():\n     # Multi-output/target case\n     X, y, X_test, y_test = build_dataset(n_features=10, n_targets=3)\n     clf = MultiTaskElasticNetCV(\n-        n_alphas=5, eps=2e-3, l1_ratio=[0.5, 0.7], cv=3, max_iter=max_iter\n+        alphas=5, eps=2e-3, l1_ratio=[0.5, 0.7], cv=3, max_iter=max_iter\n     )\n     ignore_warnings(clf.fit)(X, y)\n     # We are in well-conditioned settings with low noise: we should\n@@ -491,9 +491,9 @@ def test_enet_path():\n     # Mono-output should have same cross-validated alpha_ and l1_ratio_\n     # in both cases.\n     X, y, _, _ = build_dataset(n_features=10)\n-    clf1 = ElasticNetCV(n_alphas=5, eps=2e-3, l1_ratio=[0.5, 0.7])\n+    clf1 = ElasticNetCV(alphas=5, eps=2e-3, l1_ratio=[0.5, 0.7])\n     clf1.fit(X, y)\n-    clf2 = MultiTaskElasticNetCV(n_alphas=5, eps=2e-3, l1_ratio=[0.5, 0.7])\n+    clf2 = MultiTaskElasticNetCV(alphas=5, eps=2e-3, l1_ratio=[0.5, 0.7])\n     clf2.fit(X, y[:, np.newaxis])\n     assert_almost_equal(clf1.l1_ratio_, clf2.l1_ratio_)\n     assert_almost_equal(clf1.alpha_, clf2.alpha_)\n@@ -503,10 +503,10 @@ def test_path_parameters():\n     X, y, _, _ = build_dataset()\n     max_iter = 100\n \n-    clf = ElasticNetCV(n_alphas=50, eps=1e-3, max_iter=max_iter, l1_ratio=0.5, tol=1e-3)\n+    clf = ElasticNetCV(alphas=50, eps=1e-3, max_iter=max_iter, l1_ratio=0.5, tol=1e-3)\n     clf.fit(X, y)  # new params\n     assert_almost_equal(0.5, clf.l1_ratio)\n-    assert 50 == clf.n_alphas\n+    assert 50 == clf._alphas\n     assert 50 == len(clf.alphas_)\n \n \n@@ -563,24 +563,24 @@ def test_enet_cv_positive_constraint():\n \n     # Ensure the unconstrained fit has a negative coefficient\n     enetcv_unconstrained = ElasticNetCV(\n-        n_alphas=3, eps=1e-1, max_iter=max_iter, cv=2, n_jobs=1\n+        alphas=3, eps=1e-1, max_iter=max_iter, cv=2, n_jobs=1\n     )\n     enetcv_unconstrained.fit(X, y)\n     assert min(enetcv_unconstrained.coef_) < 0\n \n     # On same data, constrained fit has non-negative coefficients\n     enetcv_constrained = ElasticNetCV(\n-        n_alphas=3, eps=1e-1, max_iter=max_iter, cv=2, positive=True, n_jobs=1\n+        alphas=3, eps=1e-1, max_iter=max_iter, cv=2, positive=True, n_jobs=1\n     )\n     enetcv_constrained.fit(X, y)\n     assert min(enetcv_constrained.coef_) >= 0\n \n \n def test_uniform_targets():\n-    enet = ElasticNetCV(n_alphas=3)\n-    m_enet = MultiTaskElasticNetCV(n_alphas=3)\n-    lasso = LassoCV(n_alphas=3)\n-    m_lasso = MultiTaskLassoCV(n_alphas=3)\n+    enet = ElasticNetCV(alphas=3)\n+    m_enet = MultiTaskElasticNetCV(alphas=3)\n+    lasso = LassoCV(alphas=3)\n+    m_lasso = MultiTaskLassoCV(alphas=3)\n \n     models_single_task = (enet, lasso)\n     models_multi_task = (m_enet, m_lasso)\n@@ -691,7 +691,7 @@ def test_multitask_enet_and_lasso_cv():\n \n     X, y, _, _ = build_dataset(n_targets=3)\n     clf = MultiTaskElasticNetCV(\n-        n_alphas=10, eps=1e-3, max_iter=200, l1_ratio=[0.3, 0.5], tol=1e-3, cv=3\n+        alphas=10, eps=1e-3, max_iter=200, l1_ratio=[0.3, 0.5], tol=1e-3, cv=3\n     )\n     clf.fit(X, y)\n     assert 0.5 == clf.l1_ratio_\n@@ -701,7 +701,7 @@ def test_multitask_enet_and_lasso_cv():\n     assert (2, 10) == clf.alphas_.shape\n \n     X, y, _, _ = build_dataset(n_targets=3)\n-    clf = MultiTaskLassoCV(n_alphas=10, eps=1e-3, max_iter=500, tol=1e-3, cv=3)\n+    clf = MultiTaskLassoCV(alphas=10, eps=1e-3, max_iter=500, tol=1e-3, cv=3)\n     clf.fit(X, y)\n     assert (3, X.shape[1]) == clf.coef_.shape\n     assert (3,) == clf.intercept_.shape\n@@ -712,9 +712,9 @@ def test_multitask_enet_and_lasso_cv():\n def test_1d_multioutput_enet_and_multitask_enet_cv():\n     X, y, _, _ = build_dataset(n_features=10)\n     y = y[:, np.newaxis]\n-    clf = ElasticNetCV(n_alphas=5, eps=2e-3, l1_ratio=[0.5, 0.7])\n+    clf = ElasticNetCV(alphas=5, eps=2e-3, l1_ratio=[0.5, 0.7])\n     clf.fit(X, y[:, 0])\n-    clf1 = MultiTaskElasticNetCV(n_alphas=5, eps=2e-3, l1_ratio=[0.5, 0.7])\n+    clf1 = MultiTaskElasticNetCV(alphas=5, eps=2e-3, l1_ratio=[0.5, 0.7])\n     clf1.fit(X, y)\n     assert_almost_equal(clf.l1_ratio_, clf1.l1_ratio_)\n     assert_almost_equal(clf.alpha_, clf1.alpha_)\n@@ -725,9 +725,9 @@ def test_1d_multioutput_enet_and_multitask_enet_cv():\n def test_1d_multioutput_lasso_and_multitask_lasso_cv():\n     X, y, _, _ = build_dataset(n_features=10)\n     y = y[:, np.newaxis]\n-    clf = LassoCV(n_alphas=5, eps=2e-3)\n+    clf = LassoCV(alphas=5, eps=2e-3)\n     clf.fit(X, y[:, 0])\n-    clf1 = MultiTaskLassoCV(n_alphas=5, eps=2e-3)\n+    clf1 = MultiTaskLassoCV(alphas=5, eps=2e-3)\n     clf1.fit(X, y)\n     assert_almost_equal(clf.alpha_, clf1.alpha_)\n     assert_almost_equal(clf.coef_, clf1.coef_[0])\n@@ -737,16 +737,16 @@ def test_1d_multioutput_lasso_and_multitask_lasso_cv():\n @pytest.mark.parametrize(\"csr_container\", CSR_CONTAINERS)\n def test_sparse_input_dtype_enet_and_lassocv(csr_container):\n     X, y, _, _ = build_dataset(n_features=10)\n-    clf = ElasticNetCV(n_alphas=5)\n+    clf = ElasticNetCV(alphas=5)\n     clf.fit(csr_container(X), y)\n-    clf1 = ElasticNetCV(n_alphas=5)\n+    clf1 = ElasticNetCV(alphas=5)\n     clf1.fit(csr_container(X, dtype=np.float32), y)\n     assert_almost_equal(clf.alpha_, clf1.alpha_, decimal=6)\n     assert_almost_equal(clf.coef_, clf1.coef_, decimal=6)\n \n-    clf = LassoCV(n_alphas=5)\n+    clf = LassoCV(alphas=5)\n     clf.fit(csr_container(X), y)\n-    clf1 = LassoCV(n_alphas=5)\n+    clf1 = LassoCV(alphas=5)\n     clf1.fit(csr_container(X, dtype=np.float32), y)\n     assert_almost_equal(clf.alpha_, clf1.alpha_, decimal=6)\n     assert_almost_equal(clf.coef_, clf1.coef_, decimal=6)\n@@ -1210,7 +1210,7 @@ def test_multi_task_lasso_cv_dtype():\n     X = rng.binomial(1, 0.5, size=(n_samples, n_features))\n     X = X.astype(int)  # make it explicit that X is int\n     y = X[:, [0, 0]].copy()\n-    est = MultiTaskLassoCV(n_alphas=5, fit_intercept=True).fit(X, y)\n+    est = MultiTaskLassoCV(alphas=5, fit_intercept=True).fit(X, y)\n     assert_array_almost_equal(est.coef_, [[1, 0, 0]] * 2, decimal=3)\n \n \n@@ -1478,7 +1478,7 @@ def test_enet_alpha_max_sample_weight(X_is_sparse, fit_intercept, sample_weight)\n     if X_is_sparse:\n         X = sparse.csc_matrix(X)\n     # Test alpha_max makes coefs zero.\n-    reg = ElasticNetCV(n_alphas=1, cv=2, eps=1, fit_intercept=fit_intercept)\n+    reg = ElasticNetCV(alphas=1, cv=2, eps=1, fit_intercept=fit_intercept)\n     reg.fit(X, y, sample_weight=sample_weight)\n     assert_allclose(reg.coef_, 0, atol=1e-5)\n     alpha_max = reg.alpha_\n@@ -1680,3 +1680,126 @@ def split(self, X, y=None, groups=None, sample_weight=None):\n     )\n     estimator = MultiTaskEstimatorCV(cv=splitter)\n     estimator.fit(X, y, sample_weight=sample_weight)\n+\n+\n+# TODO(1.9): remove\n+@pytest.mark.parametrize(\n+    \"Estimator\", [LassoCV, ElasticNetCV, MultiTaskLassoCV, MultiTaskElasticNetCV]\n+)\n+def test_linear_model_cv_deprecated_n_alphas(Estimator):\n+    \"\"\"Check the deprecation of n_alphas in favor of alphas.\"\"\"\n+    X, y = make_regression(n_targets=2, random_state=42)\n+\n+    # Asses warning message raised by LinearModelCV when n_alphas is used\n+    with pytest.warns(\n+        FutureWarning,\n+        match=\"'n_alphas' was deprecated in 1.7 and will be removed in 1.9\",\n+    ):\n+        clf = Estimator(n_alphas=5)\n+        if clf._is_multitask():\n+            clf = clf.fit(X, y)\n+        else:\n+            clf = clf.fit(X, y[:, 0])\n+\n+    # Asses no warning message raised when n_alphas is not used\n+    with warnings.catch_warnings():\n+        warnings.simplefilter(\"error\")\n+        clf = Estimator(alphas=5)\n+        if clf._is_multitask():\n+            clf = clf.fit(X, y)\n+        else:\n+            clf = clf.fit(X, y[:, 0])\n+\n+\n+# TODO(1.9): remove\n+@pytest.mark.parametrize(\n+    \"Estimator\", [ElasticNetCV, LassoCV, MultiTaskLassoCV, MultiTaskElasticNetCV]\n+)\n+def test_linear_model_cv_deprecated_alphas_none(Estimator):\n+    \"\"\"Check the deprecation of alphas=None.\"\"\"\n+    X, y = make_regression(n_targets=2, random_state=42)\n+\n+    with pytest.warns(\n+        FutureWarning, match=\"'alphas=None' is deprecated and will be removed in 1.9\"\n+    ):\n+        clf = Estimator(alphas=None)\n+        if clf._is_multitask():\n+            clf.fit(X, y)\n+        else:\n+            clf.fit(X, y[:, 0])\n+\n+\n+# TODO(1.9): remove\n+@pytest.mark.parametrize(\n+    \"Estimator\", [ElasticNetCV, LassoCV, MultiTaskLassoCV, MultiTaskElasticNetCV]\n+)\n+def test_linear_model_cv_alphas_n_alphas_unset(Estimator):\n+    \"\"\"Check that no warning is raised when both n_alphas and alphas are unset.\"\"\"\n+    X, y = make_regression(n_targets=2, random_state=42)\n+\n+    # Asses no warning message raised when n_alphas is not used\n+    with warnings.catch_warnings():\n+        warnings.simplefilter(\"error\")\n+        clf = Estimator()\n+        if clf._is_multitask():\n+            clf = clf.fit(X, y)\n+        else:\n+            clf = clf.fit(X, y[:, 0])\n+\n+\n+# TODO(1.9): remove\n+@pytest.mark.filterwarnings(\"ignore:'n_alphas' was deprecated in 1.7\")\n+@pytest.mark.parametrize(\n+    \"Estimator\", [ElasticNetCV, LassoCV, MultiTaskLassoCV, MultiTaskElasticNetCV]\n+)\n+def test_linear_model_cv_alphas(Estimator):\n+    \"\"\"Check that the behavior of alphas is consistent with n_alphas.\"\"\"\n+    X, y = make_regression(n_targets=2, random_state=42)\n+\n+    # n_alphas is set, alphas is not => n_alphas is used\n+    clf = Estimator(n_alphas=5)\n+    if clf._is_multitask():\n+        clf.fit(X, y)\n+    else:\n+        clf.fit(X, y[:, 0])\n+    assert len(clf.alphas_) == 5\n+\n+    # n_alphas is set, alphas is set => alphas has priority\n+    clf = Estimator(n_alphas=5, alphas=10)\n+    if clf._is_multitask():\n+        clf.fit(X, y)\n+    else:\n+        clf.fit(X, y[:, 0])\n+    assert len(clf.alphas_) == 10\n+\n+    # same with alphas array-like\n+    clf = Estimator(n_alphas=5, alphas=np.arange(10))\n+    if clf._is_multitask():\n+        clf.fit(X, y)\n+    else:\n+        clf.fit(X, y[:, 0])\n+    assert len(clf.alphas_) == 10\n+\n+    # n_alphas is not set, alphas is set => alphas is used\n+    clf = Estimator(alphas=10)\n+    if clf._is_multitask():\n+        clf.fit(X, y)\n+    else:\n+        clf.fit(X, y[:, 0])\n+    assert len(clf.alphas_) == 10\n+\n+    # same with alphas array-like\n+    clf = Estimator(alphas=np.arange(10))\n+    if clf._is_multitask():\n+        clf.fit(X, y)\n+    else:\n+        clf.fit(X, y[:, 0])\n+    assert len(clf.alphas_) == 10\n+\n+    # both are not set => default = 100\n+    clf = Estimator()\n+    if clf._is_multitask():\n+        clf.fit(X, y)\n+    else:\n+        clf.fit(X, y[:, 0])\n+    assert len(clf.alphas_) == 100\n",
  "fail_to_pass": [
    "test_linear_model_cv_deprecated_n_alphas",
    "test_linear_model_cv_deprecated_alphas_none",
    "test_linear_model_cv_alphas_n_alphas_unset",
    "test_linear_model_cv_alphas"
  ],
  "pass_to_pass": [],
  "relevant_files": [
    "sklearn/linear_model/_coordinate_descent.py",
    "sklearn/linear_model/tests/test_coordinate_descent.py"
  ],
  "difficulty": "hard",
  "created_at": "2025-01-09T17:48:13Z",
  "pr_url": "https://github.com/scikit-learn/scikit-learn/pull/30616",
  "issue_url": "https://github.com/scikit-learn/scikit-learn/issues/30467"
}