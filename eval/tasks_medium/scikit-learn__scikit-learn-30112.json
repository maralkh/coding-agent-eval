{
  "id": "scikit-learn__scikit-learn-30112",
  "repo": "scikit-learn/scikit-learn",
  "base_commit": "16effb9da664fbadcdbfc28ad0c1e6beb7317c32",
  "issue_number": 22827,
  "issue_title": "Improve tests by using global_random_seed fixture to make them less seed-sensitive",
  "issue_body": "## Context: the new `global_random_seed` fixture\n\n#22749 introduces a new `global_random_seed` fixture to make it possible to run the same test with any seed between 0 and 99 included. By default, when `SKLEARN_TESTS_GLOBAL_RANDOM_SEED` is not set, this fixture is deterministically returning 42 to keep test runs deterministic by default and avoid any unnecessary disruption. However different CI builds set this seed to other arbitrary values (still deterministic) and nightly schedule builds on Azure now use `SKLEARN_TESTS_GLOBAL_RANDOM_SEED=\"any\"` to progressively explore any seed on the 0-99 range.\n\n## Motivation\n\nThe aim of this new fixture is to make sure that we avoid writing tests that artificially depend on a specific value of the random seed and therefore hiding a real mathematical problem in our code unknowingly (see e.g. https://github.com/scikit-learn/scikit-learn/pull/21701#discussion_r823847947). At the same time we still want to keep the test deterministic and independent of the execution order by default to avoid introducing unnecessary maintenance overhead.\n\nIn addition to making the tests insensitive, randomizing those tests with different seeds has the side benefit of making the assertions of those tests robust to small numerical variations that could otherwise stem from other sources such as platform-specific / dependency-specific numerical rounding variations that we do not cover in our existing CI infrastructure.\n\nMore details about the fixture in the online dev doc for the `SKLEARN_TESTS_GLOBAL_RANDOM_SEED` env variable:\n\nhttps://scikit-learn.org/dev/computing/parallelism.html#environment-variables\n\n## Guidelines to convert existing tests\n\n- We probably do not need to convert all scikit-learn tests to use this fixture. We should instead focus our efforts on tests that actually check for **important mathematical properties** of our estimators or model evaluation tools. For instance, there is no need to check for the seed-insensitivity of tests that checks for the exception messages raised when passing invalid inputs.\n\n- To avoid having to review huge PRs that impact many files at once and can lead to conflicts, let's open PRs that edit at most one test file at a time. For instance use a title such as:\n\n> TST use global_random_seed in sklearn/_loss/tests/test_glm_distribution.py\n\n- Please reference `#22827` in the description of the PR and put the full filename of the test file you edit in the title of the PR.\n\n- To convert an existing test with a fixed seed, the general pattern is to rewrite a function such as:\n\n```python\ndef test_some_function():\n    rng = np.random.RandomState(0)\n    ...\n```\n\nto:\n\n```python\ndef test_some_function(global_random_seed):\n    rng = np.random.RandomState(global_random_seed)\n    ...\n```\n\nand then check that the test function is actually seed-insensitive by running with all seeds between 0 and 99 locally (can be slow! only run for one specific test at a time!):\n\n```\nSKLEARN_TESTS_GLOBAL_RANDOM_SEED=\"all\" pytest sklearn/some_module/test/test_some_module.py -k test_some_function\n```\n\nIf this is not the case, the test will probably need to be reworked to find a more stable to way to check the interesting mathematical properties.\n\n- if the failing assertions are related to the generalization performance of a model, maybe the training set size should be slightly bigger (while keeping the test runtime as fast as possible), or with fewer noisy features or the training should be done with stronger regularization. Or more simply we can relax the tolerance threshold while ensuring it does not become trivial (e.g. by comparing to a trivial baseline);\n\n- if the failing assertions depend on some regularities of a synthetically generated dataset, making decreasing the noise level of the datasets;\n\n- some tests might also fail when encountering data that trigger edge cases such as (near-)tied distances between datapoints that make the outcome of computation unstable. Changing the data generation code to significantly decrease the likelihood of those edge case (e.g. by adding more noise to the input features) can help in those cases.\n\n- **Note**: in most cases, tweaking the tolerances of the assertions is **not** the appropriate way to make the tests pass. The first thing to do is try to understand what the test is checking, if the test is correct, if the expectations of the test are realistic. Then if the test seems correct and *should* pass for all random seed but doesn't, investigate if the estimator or function is bugged. As a last resort, tolerances can be loosened if the test is considered valid but aims to check a statistical property that is highly sensitive to the random seed.\n\nIn some cases, it might be very hard to write a seed-insensitive test that tolerate all seeds between 0 and 99 while still running in less than 1s. In those (hopefully rare) cases, I think it's fine to reduce the range of admissible seeds with the following pattern:\n\n```python\ndef test_some_function(global_random_seed):\n    # Making this test seed-insensitive for the 0-99 range would\n    # be too costly. Restricting to the 0-9 range is necessary to\n    # use small enough datasets that avoid increasing the run time\n    # too much.\n    rng = np.random.RandomState(global_random_seed % 10)\n    ...\n```\n\n- Run the CI for tests that take a `global_random_seed` by pushing a commit message with the following structure:\n\n```\n<title> [all random seeds]\n<test_name_1>\n<test_name_2>\n...\n```\n\nNote, running `git commit --allow-empty` allows you to have a commit message without any changes.\n\nSee the following issue for more details on why testing on the CI is necessary:\n\n- #28959\n\n## List of test modules to upgrade\n\n```\nfind sklearn -name \"test_*.py\"\n```\n\n- [x] sklearn/_loss/tests/test_glm_distribution.py\n- [x] sklearn/_loss/tests/test_link.py\n- [x] sklearn/_loss/tests/test_loss.py  #22847\n- [x] sklearn/cluster/tests/test_affinity_propagation.py\n- [x] sklearn/cluster/tests/test_bicluster.py\n- [x] sklearn/cluster/tests/test_birch.py\n- [x] sklearn/cluster/tests/test_dbscan.py\n- [x] sklearn/cluster/tests/test_feature_agglomeration.py #23700\n- [x] sklearn/cluster/tests/test_hierarchical.py\n- [x] sklearn/cluster/tests/test_k_means.py\n- [x] sklearn/cluster/tests/test_mean_shift.py #30517\n- [x] sklearn/cluster/tests/test_optics.py https://github.com/scikit-learn/scikit-learn/pull/30844\n- [x] sklearn/cluster/tests/test_spectral.py https://github.com/scikit-learn/scikit-learn/pull/24802\n- [x] sklearn/compose/tests/test_column_transformer.py\n- [x] sklearn/compose/tests/test_target.py\n- [x] sklearn/covariance/tests/test_covariance.py\n- [x] sklearn/covariance/tests/test_elliptic_envelope.py\n- [x] sklearn/covariance/tests/test_graphical_lasso.py\n- [x] sklearn/covariance/tests/test_robust_covariance.py\n- [x] sklearn/cross_decomposition/tests/test_pls.py\n- [x] sklearn/datasets/tests/test_20news.py\n- [x] sklearn/datasets/tests/test_base.py\n- [x] sklearn/datasets/tests/test_california_housing.py\n- [x] sklearn/datasets/tests/test_common.py\n- [x] sklearn/datasets/tests/test_covtype.py\n- [x] sklearn/datasets/tests/test_kddcup99.py\n- [x] sklearn/datasets/tests/test_lfw.py\n- [x] sklearn/datasets/tests/test_olivetti_faces.py\n- [x] sklearn/datasets/tests/test_openml.py\n- [x] sklearn/datasets/tests/test_rcv1.py\n- [x] sklearn/datasets/tests/test_samples_generator.py\n- [x] sklearn/datasets/tests/test_svmlight_format.py\n- [ ] sklearn/decomposition/tests/test_dict_learning.py\n- [x] sklearn/decomposition/tests/test_factor_analysis.py\n- [x] sklearn/decomposition/tests/test_fastica.py\n- [ ] sklearn/decomposition/tests/test_incremental_pca.py\n- [x] sklearn/decomposition/tests/test_kernel_pca.py #30518\n- [ ] sklearn/decomposition/tests/test_nmf.py\n- [ ] sklearn/decomposition/tests/test_online_lda.py\n- [ ] sklearn/decomposition/tests/test_pca.py https://github.com/scikit-learn/scikit-learn/pull/26403\n- [x] sklearn/decomposition/tests/test_sparse_pca.py\n- [x] sklearn/decomposition/tests/test_truncated_svd.py\n- [ ] sklearn/ensemble/_hist_gradient_boosting/tests/test_binning.py\n- [ ] sklearn/ensemble/_hist_gradient_boosting/tests/test_bitset.py\n- [ ] sklearn/ensemble/_hist_gradient_boosting/tests/test_compare_lightgbm.py\n- [ ] sklearn/ensemble/_hist_gradient_boosting/tests/test_gradient_boosting.py\n- [ ] sklearn/ensemble/_hist_gradient_boosting/tests/test_grower.py\n- [ ] sklearn/ensemble/_hist_gradient_boosting/tests/test_histogram.py\n- [ ] sklearn/ensemble/_hist_gradient_boosting/tests/test_monotonic_contraints.py\n- [ ] sklearn/ensemble/_hist_gradient_boosting/tests/test_predictor.py\n- [ ] sklearn/ensemble/_hist_gradient_boosting/tests/test_splitting.py\n- [ ] sklearn/ensemble/_hist_gradient_boosting/tests/test_warm_start.py\n- [x] sklearn/ensemble/tests/test_bagging.py\n- [x] sklearn/ensemble/tests/test_base.py\n- [ ] sklearn/ensemble/tests/test_common.py\n- [ ] sklearn/ensemble/tests/test_forest.py\n- [x] sklearn/ensemble/tests/test_gradient_boosting_loss_functions.py\n- [x] sklearn/ensemble/tests/test_gradient_boosting.py\n- [x] sklearn/ensemble/tests/test_iforest.py #22901\n- [ ] sklearn/ensemble/tests/test_stacking.py\n- [x] sklearn/ensemble/tests/test_voting.py\n- [ ] sklearn/ensemble/tests/test_weight_boosting.py\n- [ ] sklearn/experimental/tests/test_enable_hist_gradient_boosting.py\n- [ ] sklearn/experimental/tests/test_enable_iterative_imputer.py\n- [ ] sklearn/experimental/tests/test_enable_successive_halving.py\n- [x] sklearn/feature_extraction/tests/test_dict_vectorizer.py\n- [ ] sklearn/feature_extraction/tests/test_feature_hasher.py\n- [ ] sklearn/feature_extraction/tests/test_image.py\n- [ ] sklearn/feature_extraction/tests/test_text.py\n- [ ] sklearn/feature_selection/tests/test_base.py\n- [ ] sklearn/feature_selection/tests/test_chi2.py\n- [ ] sklearn/feature_selection/tests/test_feature_select.py\n- [ ] sklearn/feature_selection/tests/test_from_model.py\n- [ ] sklearn/feature_selection/tests/test_mutual_info.py\n- [x] sklearn/feature_selection/tests/test_rfe.py\n- [ ] sklearn/feature_selection/tests/test_sequential.py\n- [ ] sklearn/feature_selection/tests/test_variance_threshold.py\n- [x] sklearn/gaussian_process/tests/test_gpc.py\n- [ ] sklearn/gaussian_process/tests/test_gpr.py\n- [ ] sklearn/gaussian_process/tests/test_kernels.py\n- [ ] sklearn/impute/tests/test_base.py\n- [ ] sklearn/impute/tests/test_common.py\n- [ ] sklearn/impute/tests/test_impute.py https://github.com/scikit-learn/scikit-learn/pull/25894\n- [ ] sklearn/impute/tests/test_knn.py\n- [ ] sklearn/inspection/_plot/tests/test_plot_partial_dependence.py\n- [ ] sklearn/inspection/tests/test_partial_dependence.py\n- [ ] sklearn/inspection/tests/test_permutation_importance.py\n- [ ] sklearn/linear_model/_glm/tests/test_glm.py\n- [ ] sklearn/linear_model/_glm/tests/test_link.py\n- [x] sklearn/linear_model/tests/test_base.py\n- [ ] sklearn/linear_model/tests/test_bayes.py\n- [ ] sklearn/linear_model/tests/test_common.py\n- [ ] sklearn/linear_model/tests/test_coordinate_descent.py\n- [ ] sklearn/linear_model/tests/test_huber.py https://github.com/scikit-learn/scikit-learn/pull/30912\n- [ ] sklearn/linear_model/tests/test_least_angle.py\n- [ ] sklearn/linear_model/tests/test_linear_loss.py\n- [x] sklearn/linear_model/tests/test_logistic.py\n- [ ] sklearn/linear_model/tests/test_omp.py\n- [ ] sklearn/linear_model/tests/test_passive_aggressive.py\n- [ ] sklearn/linear_model/tests/test_perceptron.py\n- [ ] sklearn/linear_model/tests/test_quantile.py\n- [ ] sklearn/linear_model/tests/test_ransac.py\n- [ ] sklearn/linear_model/tests/test_ridge.py\n- [ ] sklearn/linear_model/tests/test_sag.py\n- [ ] sklearn/linear_model/tests/test_sgd.py\n- [ ] sklearn/linear_model/tests/test_sparse_coordinate_descent.py\n- [ ] sklearn/linear_model/tests/test_theil_sen.py\n- [ ] sklearn/manifold/tests/test_isomap.py\n- [ ] sklearn/manifold/tests/test_locally_linear.py\n- [ ] sklearn/manifold/tests/test_mds.py\n- [ ] sklearn/manifold/tests/test_spectral_embedding.py\n- [ ] sklearn/manifold/tests/test_t_sne.py\n- [ ] sklearn/metrics/_plot/tests/test_base.py\n- [ ] sklearn/metrics/_plot/tests/test_common_curve_display.py\n- [ ] sklearn/metrics/_plot/tests/test_confusion_matrix_display.py\n- [ ] sklearn/metrics/_plot/tests/test_det_curve_display.py\n- [ ] sklearn/metrics/_plot/tests/test_plot_confusion_matrix.py\n- [ ] sklearn/metrics/_plot/tests/test_plot_curve_common.py\n- [ ] sklearn/metrics/_plot/tests/test_plot_det_curve.py\n- [ ] sklearn/metrics/_plot/tests/test_plot_precision_recall.py\n- [ ] sklearn/metrics/_plot/tests/test_plot_roc_curve.py\n- [ ] sklearn/metrics/_plot/tests/test_precision_recall_display.py\n- [ ] sklearn/metrics/_plot/tests/test_roc_curve_display.py\n- [ ] sklearn/metrics/cluster/tests/test_bicluster.py\n- [ ] sklearn/metrics/cluster/tests/test_common.py\n- [ ] sklearn/metrics/cluster/tests/test_supervised.py\n- [ ] sklearn/metrics/cluster/tests/test_unsupervised.py\n- [ ] sklearn/metrics/tests/test_classification.py\n- [ ] sklearn/metrics/tests/test_common.py\n- [ ] sklearn/metrics/tests/test_dist_metrics.py\n- [x] sklearn/metrics/tests/test_pairwise_distances_reduction.py https://github.com/scikit-learn/scikit-learn/pull/22862\n- [ ] sklearn/metrics/tests/test_pairwise.py\n- [ ] sklearn/metrics/tests/test_ranking.py\n- [x] sklearn/metrics/tests/test_regression.py https://github.com/scikit-learn/scikit-learn/pull/30865\n- [ ] sklearn/metrics/tests/test_score_objects.py\n- [ ] sklearn/mixture/tests/test_bayesian_mixture.py\n- [ ] sklearn/mixture/tests/test_gaussian_mixture.py\n- [x] sklearn/mixture/tests/test_mixture.py\n- [ ] sklearn/model_selection/tests/test_search.py\n- [ ] sklearn/model_selection/tests/test_split.py\n- [ ] sklearn/model_selection/tests/test_successive_halving.py\n- [ ] sklearn/model_selection/tests/test_validation.py\n- [ ] sklearn/neighbors/tests/test_ball_tree.py\n- [ ] sklearn/neighbors/tests/test_graph.py\n- [ ] sklearn/neighbors/tests/test_kd_tree.py\n- [ ] sklearn/neighbors/tests/test_kde.py\n- [ ] sklearn/neighbors/tests/test_lof.py\n- [ ] sklearn/neighbors/tests/test_nca.py\n- [ ] sklearn/neighbors/tests/test_nearest_centroid.py\n- [ ] sklearn/neighbors/tests/test_neighbors_pipeline.py\n- [ ] sklearn/neighbors/tests/test_neighbors_tree.py\n- [ ] sklearn/neighbors/tests/test_neighbors.py\n- [ ] sklearn/neighbors/tests/test_quad_tree.py\n- [ ] sklearn/neural_network/tests/test_base.py\n- [ ] sklearn/neural_network/tests/test_mlp.py\n- [ ] sklearn/neural_network/tests/test_rbm.py\n- [ ] sklearn/neural_network/tests/test_stochastic_optimizers.py\n- [ ] sklearn/preprocessing/tests/test_common.py\n- [ ] sklearn/preprocessing/tests/test_data.py\n- [ ] sklearn/preprocessing/tests/test_discretization.py\n- [ ] sklearn/preprocessing/tests/test_encoders.py\n- [ ] sklearn/preprocessing/tests/test_function_transformer.py\n- [ ] sklearn/preprocessing/tests/test_label.py\n- [ ] sklearn/preprocessing/tests/test_polynomial.py\n- [ ] sklearn/semi_supervised/tests/test_label_propagation.py\n- [ ] sklearn/semi_supervised/tests/test_self_training.py\n- [ ] sklearn/svm/tests/test_bounds.py\n- [ ] sklearn/svm/tests/test_sparse.py\n- [ ] sklearn/svm/tests/test_svm.py https://github.com/scikit-learn/scikit-learn/pull/25891\n- [ ] sklearn/tests/test_base.py\n- [ ] sklearn/tests/test_build.py\n- [ ] sklearn/tests/test_calibration.py\n- [ ] sklearn/tests/test_check_build.py\n- [ ] sklearn/tests/test_common.py\n- [ ] sklearn/tests/test_config.py\n- [ ] sklearn/tests/test_discriminant_analysis.py\n- [ ] sklearn/tests/test_docstring_parameters.py\n- [ ] sklearn/tests/test_docstrings.py\n- [x] sklearn/tests/test_dummy.py\n- [ ] sklearn/tests/test_init.py\n- [ ] sklearn/tests/test_isotonic.py\n- [ ] sklearn/tests/test_kernel_approximation.py\n- [ ] sklearn/tests/test_kernel_ridge.py\n- [ ] sklearn/tests/test_metaestimators.py\n- [ ] sklearn/tests/test_min_dependencies_readme.py\n- [ ] sklearn/tests/test_multiclass.py\n- [ ] sklearn/tests/test_multioutput.py\n- [ ] sklearn/tests/test_naive_bayes.py\n- [ ] sklearn/tests/test_pipeline.py\n- [ ] sklearn/tests/test_random_projection.py\n- [ ] sklearn/tree/tests/test_export.py\n- [ ] sklearn/tree/tests/test_reingold_tilford.py\n- [ ] sklearn/tree/tests/test_tree.py\n- [ ] sklearn/utils/tests/test_arpack.py\n- [ ] sklearn/utils/tests/test_arrayfuncs.py\n- [ ] sklearn/utils/tests/test_class_weight.py\n- [ ] sklearn/utils/tests/test_cython_blas.py\n- [x] sklearn/utils/tests/test_cython_templating.py\n- [x] sklearn/utils/tests/test_deprecation.py\n- [x] sklearn/utils/tests/test_encode.py\n- [ ] sklearn/utils/tests/test_estimator_checks.py\n- [ ] sklearn/utils/tests/test_estimator_html_repr.py\n- [ ] sklearn/utils/tests/test_extmath.py\n- [ ] sklearn/utils/tests/test_fast_dict.py\n- [x] sklearn/utils/tests/test_fixes.py\n- [x] sklearn/utils/tests/test_graph.py\n- [x] sklearn/utils/tests/test_metaestimators.py\n- [x] sklearn/utils/tests/test_mocking.py\n- [ ] sklearn/utils/tests/test_multiclass.py\n- [ ] sklearn/utils/tests/test_murmurhash.py\n- [x] sklearn/utils/tests/test_optimize.py https://github.com/scikit-learn/scikit-learn/pull/30112\n- [x] sklearn/utils/tests/test_parallel.py\n- [x] sklearn/utils/tests/test_pprint.py\n- [ ] sklearn/utils/tests/test_random.py\n- [ ] sklearn/utils/tests/test_readonly_wrapper.py\n- [ ] sklearn/utils/tests/test_seq_dataset.py\n- [ ] sklearn/utils/tests/test_shortest_path.py\n- [x] sklearn/utils/tests/test_show_versions.py\n- [ ] sklearn/utils/tests/test_sparsefuncs.py\n- [x] sklearn/utils/tests/test_stats.py https://github.com/scikit-learn/scikit-learn/pull/30857\n- [x] sklearn/utils/tests/test_tags.py\n- [ ] sklearn/utils/tests/test_testing.py\n- [ ] sklearn/utils/tests/test_utils.py\n- [ ] sklearn/utils/tests/test_validation.py\n- [ ] sklearn/utils/tests/test_weight_vector.py\n\nNote that some of those files might not have any test to update.\n",
  "pr_number": 30112,
  "pr_title": "TST use global_random_seed in sklearn/utils/tests/test_optimize.py",
  "gold_patch": "diff --git a/sklearn/utils/tests/test_optimize.py b/sklearn/utils/tests/test_optimize.py\nindex 5975fe4f9c191..775da5791b9a6 100644\n--- a/sklearn/utils/tests/test_optimize.py\n+++ b/sklearn/utils/tests/test_optimize.py\n@@ -3,14 +3,14 @@\n from scipy.optimize import fmin_ncg\n \n from sklearn.exceptions import ConvergenceWarning\n-from sklearn.utils._testing import assert_array_almost_equal\n+from sklearn.utils._testing import assert_allclose\n from sklearn.utils.optimize import _newton_cg\n \n \n-def test_newton_cg():\n+def test_newton_cg(global_random_seed):\n     # Test that newton_cg gives same result as scipy's fmin_ncg\n \n-    rng = np.random.RandomState(0)\n+    rng = np.random.RandomState(global_random_seed)\n     A = rng.normal(size=(10, 10))\n     x0 = np.ones(10)\n \n@@ -27,9 +27,13 @@ def hess(x, p):\n     def grad_hess(x):\n         return grad(x), lambda x: A.T.dot(A.dot(x))\n \n-    assert_array_almost_equal(\n-        _newton_cg(grad_hess, func, grad, x0, tol=1e-10)[0],\n+    # func is a definite positive quadratic form, so the minimum is at x = 0\n+    # hence the use of absolute tolerance.\n+    assert np.all(np.abs(_newton_cg(grad_hess, func, grad, x0, tol=1e-10)[0]) <= 1e-7)\n+    assert_allclose(\n+        _newton_cg(grad_hess, func, grad, x0, tol=1e-7)[0],\n         fmin_ncg(f=func, x0=x0, fprime=grad, fhess_p=hess),\n+        atol=1e-5,\n     )\n \n \n",
  "fail_to_pass": [
    "test_newton_cg"
  ],
  "pass_to_pass": [],
  "relevant_files": [
    "sklearn/utils/tests/test_optimize.py"
  ],
  "difficulty": "easy",
  "created_at": "2024-10-19T13:59:24Z",
  "pr_url": "https://github.com/scikit-learn/scikit-learn/pull/30112",
  "issue_url": "https://github.com/scikit-learn/scikit-learn/issues/22827"
}