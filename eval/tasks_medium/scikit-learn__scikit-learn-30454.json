{
  "id": "scikit-learn__scikit-learn-30454",
  "repo": "scikit-learn/scikit-learn",
  "base_commit": "6c3001574a88b1d5a026b81148e6492666cdd211",
  "issue_number": 29107,
  "issue_title": "Incorrect invalid device error introduced in #25956",
  "issue_body": "### Describe the bug\r\n\r\n#25956 introduced a new `sklearn.utils._array_api._check_device_cpu` function to test whether a tensor is on CPU. However, the implementation of the test, which is `device not in {\"cpu\", None}`, is incorrect -- the device will actually not be a string, but `device(type='cpu')`. Therefore, you should attempt to get the `type` attr, and use that if available.\r\n\r\n### Steps/Code to Reproduce\r\n\r\nYou can view a sample error here:\r\nhttps://github.com/fastai/fastai/actions/runs/9232979440/job/25404873935\r\n\r\n### Expected Results\r\n\r\n`ValueError: Unsupported device for NumPy: device(type='cpu')`  should not be thrown.\r\n\r\n### Actual Results\r\n\r\n```\r\nFile /opt/hostedtoolcache/Python/3.10.14/x64/lib/python3.10/site-packages/sklearn/utils/_array_api.py:308, in _check_device_cpu(device)\r\n    306 def _check_device_cpu(device):  # noqa\r\n    307     if device not in {\"cpu\", None}:\r\n--> 308         raise ValueError(f\"Unsupported device for NumPy: {device!r}\")\r\n\r\nValueError: Unsupported device for NumPy: device(type='cpu')\r\n```\r\n\r\n### Versions\r\n\r\n```shell\r\nI've seen this on multiple Linux and Mac versions. My current Mac version:\r\n\r\n\r\nSystem:\r\n    python: 3.11.8 (main, Feb 26 2024, 15:36:12) [Clang 14.0.6 ]\r\nexecutable: /Users/jhoward/miniconda3/bin/python\r\n   machine: macOS-14.3.1-arm64-arm-64bit\r\n\r\nPython dependencies:\r\n      sklearn: 1.4.2\r\n          pip: 23.3.1\r\n   setuptools: 68.2.2\r\n        numpy: 1.26.4\r\n        scipy: 1.13.0\r\n       Cython: None\r\n       pandas: 2.2.1\r\n   matplotlib: 3.8.4\r\n       joblib: 1.4.0\r\nthreadpoolctl: 2.2.0\r\n\r\nBuilt with OpenMP: True\r\n\r\nthreadpoolctl info:\r\n       filepath: /Users/jhoward/miniconda3/lib/libopenblasp-r0.3.21.dylib\r\n         prefix: libopenblas\r\n       user_api: blas\r\n   internal_api: openblas\r\n        version: 0.3.21\r\n    num_threads: 8\r\nthreading_layer: pthreads\r\n   architecture: armv8\r\n\r\n       filepath: /Users/jhoward/miniconda3/lib/libomp.dylib\r\n         prefix: libomp\r\n       user_api: openmp\r\n   internal_api: openmp\r\n        version: None\r\n    num_threads: 8\r\n```\r\n```\r\n",
  "pr_number": 30454,
  "pr_title": "FIX Fix device detection when array API dispatch is disabled",
  "gold_patch": "diff --git a/doc/whats_new/upcoming_changes/sklearn.metrics/30454.fix.rst b/doc/whats_new/upcoming_changes/sklearn.metrics/30454.fix.rst\nnew file mode 100644\nindex 0000000000000..a53850e324e90\n--- /dev/null\n+++ b/doc/whats_new/upcoming_changes/sklearn.metrics/30454.fix.rst\n@@ -0,0 +1,3 @@\n+- Fix regression when scikit-learn metric called on PyTorch CPU tensors would\n+  raise an error (with array API dispatch disabled which is the default).\n+  By :user:`Lo\u00efc Est\u00e8ve <lesteve>`\ndiff --git a/sklearn/metrics/tests/test_common.py b/sklearn/metrics/tests/test_common.py\nindex 0b7a47b0f12da..ef8e6ebb2ac2a 100644\n--- a/sklearn/metrics/tests/test_common.py\n+++ b/sklearn/metrics/tests/test_common.py\n@@ -1817,6 +1817,40 @@ def check_array_api_metric(\n     if isinstance(multioutput, np.ndarray):\n         metric_kwargs[\"multioutput\"] = xp.asarray(multioutput, device=device)\n \n+    # When array API dispatch is disabled, and np.asarray works (for example PyTorch\n+    # with CPU device), calling the metric function with such numpy compatible inputs\n+    # should work (albeit by implicitly converting to numpy arrays instead of\n+    # dispatching to the array library).\n+    try:\n+        np.asarray(a_xp)\n+        np.asarray(b_xp)\n+        numpy_as_array_works = True\n+    except TypeError:\n+        # PyTorch with CUDA device and CuPy raise TypeError consistently.\n+        # Exception type may need to be updated in the future for other\n+        # libraries.\n+        numpy_as_array_works = False\n+\n+    if numpy_as_array_works:\n+        metric_xp = metric(a_xp, b_xp, **metric_kwargs)\n+        assert_allclose(\n+            metric_xp,\n+            metric_np,\n+            atol=_atol_for_type(dtype_name),\n+        )\n+        metric_xp_mixed_1 = metric(a_np, b_xp, **metric_kwargs)\n+        assert_allclose(\n+            metric_xp_mixed_1,\n+            metric_np,\n+            atol=_atol_for_type(dtype_name),\n+        )\n+        metric_xp_mixed_2 = metric(a_xp, b_np, **metric_kwargs)\n+        assert_allclose(\n+            metric_xp_mixed_2,\n+            metric_np,\n+            atol=_atol_for_type(dtype_name),\n+        )\n+\n     with config_context(array_api_dispatch=True):\n         metric_xp = metric(a_xp, b_xp, **metric_kwargs)\n \ndiff --git a/sklearn/utils/_array_api.py b/sklearn/utils/_array_api.py\nindex b2b4f88fa218f..65503a0674a70 100644\n--- a/sklearn/utils/_array_api.py\n+++ b/sklearn/utils/_array_api.py\n@@ -130,10 +130,17 @@ def _check_array_api_dispatch(array_api_dispatch):\n \n def _single_array_device(array):\n     \"\"\"Hardware device where the array data resides on.\"\"\"\n-    if isinstance(array, (numpy.ndarray, numpy.generic)) or not hasattr(\n-        array, \"device\"\n+    if (\n+        isinstance(array, (numpy.ndarray, numpy.generic))\n+        or not hasattr(array, \"device\")\n+        # When array API dispatch is disabled, we expect the scikit-learn code\n+        # to use np.asarray so that the resulting NumPy array will implicitly use the\n+        # CPU. In this case, scikit-learn should stay as device neutral as possible,\n+        # hence the use of `device=None` which is accepted by all libraries, before\n+        # and after the expected conversion to NumPy via np.asarray.\n+        or not get_config()[\"array_api_dispatch\"]\n     ):\n-        return \"cpu\"\n+        return None\n     else:\n         return array.device\n \ndiff --git a/sklearn/utils/estimator_checks.py b/sklearn/utils/estimator_checks.py\nindex 7416216dda520..f68fd8d091119 100644\n--- a/sklearn/utils/estimator_checks.py\n+++ b/sklearn/utils/estimator_checks.py\n@@ -1113,6 +1113,40 @@ def check_array_api_input(\n         \"transform\",\n     )\n \n+    try:\n+        np.asarray(X_xp)\n+        np.asarray(y_xp)\n+        # TODO There are a few errors in SearchCV with array-api-strict because\n+        # we end up doing X[train_indices] where X is an array-api-strict array\n+        # and train_indices is a numpy array. array-api-strict insists\n+        # train_indices should be an array-api-strict array. On the other hand,\n+        # all the array API libraries (PyTorch, jax, CuPy) accept indexing with a\n+        # numpy array. This is probably not worth doing anything about for\n+        # now since array-api-strict seems a bit too strict ...\n+        numpy_asarray_works = xp.__name__ != \"array_api_strict\"\n+\n+    except TypeError:\n+        # PyTorch with CUDA device and CuPy raise TypeError consistently.\n+        # Exception type may need to be updated in the future for other\n+        # libraries.\n+        numpy_asarray_works = False\n+\n+    if numpy_asarray_works:\n+        # In this case, array_api_dispatch is disabled and we rely on np.asarray\n+        # being called to convert the non-NumPy inputs to NumPy arrays when needed.\n+        est_fitted_with_as_array = clone(est).fit(X_xp, y_xp)\n+        # We only do a smoke test for now, in order to avoid complicating the\n+        # test function even further.\n+        for method_name in methods:\n+            method = getattr(est_fitted_with_as_array, method_name, None)\n+            if method is None:\n+                continue\n+\n+            if method_name == \"score\":\n+                method(X_xp, y_xp)\n+            else:\n+                method(X_xp)\n+\n     for method_name in methods:\n         method = getattr(est, method_name, None)\n         if method is None:\ndiff --git a/sklearn/utils/tests/test_array_api.py b/sklearn/utils/tests/test_array_api.py\nindex 82b6a7df557e5..d76ef4838e37e 100644\n--- a/sklearn/utils/tests/test_array_api.py\n+++ b/sklearn/utils/tests/test_array_api.py\n@@ -248,6 +248,7 @@ def test_device_none_if_no_input():\n     assert device(None, \"name\") is None\n \n \n+@skip_if_array_api_compat_not_configured\n def test_device_inspection():\n     class Device:\n         def __init__(self, name):\n@@ -273,18 +274,26 @@ def __init__(self, device_name):\n     with pytest.raises(TypeError):\n         hash(Array(\"device\").device)\n \n-    # Test raise if on different devices\n+    # If array API dispatch is disabled the device should be ignored. Erroring\n+    # early for different devices would prevent the np.asarray conversion to\n+    # happen. For example, `r2_score(np.ones(5), torch.ones(5))` should work\n+    # fine with array API disabled.\n+    assert device(Array(\"cpu\"), Array(\"mygpu\")) is None\n+\n+    # Test that ValueError is raised if on different devices and array API dispatch is\n+    # enabled.\n     err_msg = \"Input arrays use different devices: cpu, mygpu\"\n-    with pytest.raises(ValueError, match=err_msg):\n-        device(Array(\"cpu\"), Array(\"mygpu\"))\n+    with config_context(array_api_dispatch=True):\n+        with pytest.raises(ValueError, match=err_msg):\n+            device(Array(\"cpu\"), Array(\"mygpu\"))\n \n-    # Test expected value is returned otherwise\n-    array1 = Array(\"device\")\n-    array2 = Array(\"device\")\n+        # Test expected value is returned otherwise\n+        array1 = Array(\"device\")\n+        array2 = Array(\"device\")\n \n-    assert array1.device == device(array1)\n-    assert array1.device == device(array1, array2)\n-    assert array1.device == device(array1, array1, array2)\n+        assert array1.device == device(array1)\n+        assert array1.device == device(array1, array2)\n+        assert array1.device == device(array1, array1, array2)\n \n \n # TODO: add cupy to the list of libraries once the the following upstream issue\n@@ -553,7 +562,7 @@ def test_get_namespace_and_device():\n     namespace, is_array_api, device = get_namespace_and_device(some_torch_tensor)\n     assert namespace is get_namespace(some_numpy_array)[0]\n     assert not is_array_api\n-    assert device.type == \"cpu\"\n+    assert device is None\n \n     # Otherwise, expose the torch namespace and device via array API compat\n     # wrapper.\n@@ -621,8 +630,8 @@ def test_sparse_device(csr_container, dispatch):\n     try:\n         with config_context(array_api_dispatch=dispatch):\n             assert device(a, b) is None\n-            assert device(a, numpy.array([1])) == \"cpu\"\n+            assert device(a, numpy.array([1])) is None\n             assert get_namespace_and_device(a, b)[2] is None\n-            assert get_namespace_and_device(a, numpy.array([1]))[2] == \"cpu\"\n+            assert get_namespace_and_device(a, numpy.array([1]))[2] is None\n     except ImportError:\n         raise SkipTest(\"array_api_compat is not installed\")\n",
  "fail_to_pass": [],
  "pass_to_pass": [],
  "relevant_files": [
    "sklearn/metrics/tests/test_common.py",
    "sklearn/utils/_array_api.py",
    "sklearn/utils/estimator_checks.py",
    "sklearn/utils/tests/test_array_api.py"
  ],
  "difficulty": "hard",
  "created_at": "2024-12-10T16:05:08Z",
  "pr_url": "https://github.com/scikit-learn/scikit-learn/pull/30454",
  "issue_url": "https://github.com/scikit-learn/scikit-learn/issues/29107"
}