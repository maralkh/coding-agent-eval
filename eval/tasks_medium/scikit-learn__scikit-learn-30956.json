{
  "id": "scikit-learn__scikit-learn-30956",
  "repo": "scikit-learn/scikit-learn",
  "base_commit": "368a200ca2c08021f49c1126e5431042c2b5238f",
  "issue_number": 30934,
  "issue_title": "DOC Missing doc string in tests present in sklearn/linear_model/_glm/tests/test_glm.py",
  "issue_body": "### Describe the issue related to documentation\nThe file `sklearn/linear_model/_glm/tests/test_glm.py` has the following tests without any doc string to describe what these functions aim to test.\n\n- test_glm_wrong_y_range\n- test_warm_start\n- test_tags\n- test_linalg_warning_with_newton_solver\n\n### Suggested fix/improvement\nAdd doc strings to these tests similar to ones present in other tests with doc strings in the same file.\n\nfor example: \n\n```\ndef test_linalg_warning_with_newton_solver(global_random_seed):\n    \"\"\"Test PoissonRegressor's behavior with the Newton solver under collinearity.\"\"\"\n```\n\n### Additional Comments\nI would like to work on this for my first documentation related work on this project.",
  "pr_number": 30956,
  "pr_title": "Fix DOC Missing doc string in tests present in `sklearn/linear_model/_glm/tests/test_glm.py`",
  "gold_patch": "diff --git a/sklearn/linear_model/_glm/tests/test_glm.py b/sklearn/linear_model/_glm/tests/test_glm.py\nindex cb052860dd756..fbcc4d61a8e1c 100644\n--- a/sklearn/linear_model/_glm/tests/test_glm.py\n+++ b/sklearn/linear_model/_glm/tests/test_glm.py\n@@ -607,6 +607,15 @@ def test_sample_weights_validation():\n     ],\n )\n def test_glm_wrong_y_range(glm):\n+    \"\"\"\n+    Test that fitting a GLM model raises a ValueError when `y` contains\n+    values outside the valid range for the given distribution.\n+\n+    Generalized Linear Models (GLMs) with certain distributions, such as\n+    Poisson, Gamma, and Tweedie (with power > 1), require `y` to be\n+    non-negative. This test ensures that passing a `y` array containing\n+    negative values triggers the expected ValueError with the correct message.\n+    \"\"\"\n     y = np.array([-1, 2])\n     X = np.array([[1], [1]])\n     msg = r\"Some value\\(s\\) of y are out of the valid range of the loss\"\n@@ -719,6 +728,16 @@ def test_glm_log_regression(solver, fit_intercept, estimator):\n @pytest.mark.parametrize(\"solver\", SOLVERS)\n @pytest.mark.parametrize(\"fit_intercept\", [True, False])\n def test_warm_start(solver, fit_intercept, global_random_seed):\n+    \"\"\"\n+    Test that `warm_start=True` enables incremental fitting in PoissonRegressor.\n+\n+    This test verifies that when using `warm_start=True`, the model continues\n+    optimizing from previous coefficients instead of restarting from scratch.\n+    It ensures that after an initial fit with `max_iter=1`, the model has a\n+    higher objective function value (indicating incomplete optimization).\n+    The test then checks whether allowing additional iterations enables\n+    convergence to a solution comparable to a fresh training run (`warm_start=False`).\n+    \"\"\"\n     n_samples, n_features = 100, 10\n     X, y = make_regression(\n         n_samples=n_samples,\n@@ -923,10 +942,23 @@ def test_tweedie_score(regression_data, power, link):\n     ],\n )\n def test_tags(estimator, value):\n+    \"\"\"Test that `positive_only` tag is correctly set for different estimators.\"\"\"\n     assert estimator.__sklearn_tags__().target_tags.positive_only is value\n \n \n def test_linalg_warning_with_newton_solver(global_random_seed):\n+    \"\"\"\n+    Test that the Newton solver raises a warning and falls back to LBFGS when\n+    encountering a singular or ill-conditioned Hessian matrix.\n+\n+    This test assess the behavior of `PoissonRegressor` with the \"newton-cholesky\"\n+    solver.\n+    It verifies the following:-\n+    - The model significantly improves upon the constant baseline deviance.\n+    - LBFGS remains robust on collinear data.\n+    - The Newton solver raises a `LinAlgWarning` on collinear data and falls\n+      back to LBFGS.\n+    \"\"\"\n     newton_solver = \"newton-cholesky\"\n     rng = np.random.RandomState(global_random_seed)\n     # Use at least 20 samples to reduce the likelihood of getting a degenerate\n",
  "fail_to_pass": [],
  "pass_to_pass": [],
  "relevant_files": [
    "sklearn/linear_model/_glm/tests/test_glm.py"
  ],
  "difficulty": "easy",
  "created_at": "2025-03-07T17:14:23Z",
  "pr_url": "https://github.com/scikit-learn/scikit-learn/pull/30956",
  "issue_url": "https://github.com/scikit-learn/scikit-learn/issues/30934"
}